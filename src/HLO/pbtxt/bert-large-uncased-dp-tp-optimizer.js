const text = `
    HloModule SyncTensorsGraph.2268, input_output_alias={ {0}: (40, {}, must-alias), {1}: (41, {}, must-alias), {2}: (42, {}, must-alias), {3}: (43, {}, must-alias), {4}: (44, {}, must-alias), {5}: (45, {}, must-alias), {6}: (46, {}, must-alias), {7}: (47, {}, must-alias), {8}: (48, {}, must-alias), {9}: (49, {}, must-alias), {10}: (50, {}, must-alias), {11}: (51, {}, must-alias), {12}: (52, {}, must-alias), {13}: (53, {}, must-alias), {14}: (54, {}, must-alias), {15}: (55, {}, must-alias), {16}: (56, {}, must-alias), {17}: (57, {}, must-alias), {18}: (58, {}, must-alias), {19}: (59, {}, must-alias), {20}: (60, {}, must-alias), {21}: (61, {}, must-alias), {22}: (62, {}, must-alias), {23}: (63, {}, must-alias), {24}: (64, {}, must-alias), {25}: (65, {}, must-alias), {26}: (66, {}, must-alias), {27}: (67, {}, must-alias), {28}: (68, {}, must-alias), {29}: (69, {}, must-alias), {30}: (3, {}, must-alias) }

%AddComputation.28 (x.29: f32[], y.30: f32[]) -> f32[] {
  %x.29 = f32[] parameter(0)
  %y.30 = f32[] parameter(1)
  ROOT %add.31 = f32[] add(f32[] %x.29, f32[] %y.30)
}

%AddComputation.97 (x.98: f32[], y.99: f32[]) -> f32[] {
  %x.98 = f32[] parameter(0)
  %y.99 = f32[] parameter(1)
  ROOT %add.100 = f32[] add(f32[] %x.98, f32[] %y.99)
}

%AddComputation.236 (x.237: f32[], y.238: f32[]) -> f32[] {
  %x.237 = f32[] parameter(0)
  %y.238 = f32[] parameter(1)
  ROOT %add.239 = f32[] add(f32[] %x.237, f32[] %y.238)
}

%AddComputation.249 (x.250: f32[], y.251: f32[]) -> f32[] {
  %x.250 = f32[] parameter(0)
  %y.251 = f32[] parameter(1)
  ROOT %add.252 = f32[] add(f32[] %x.250, f32[] %y.251)
}

%AddComputation.262 (x.263: f32[], y.264: f32[]) -> f32[] {
  %x.263 = f32[] parameter(0)
  %y.264 = f32[] parameter(1)
  ROOT %add.265 = f32[] add(f32[] %x.263, f32[] %y.264)
}

%AddComputation.275 (x.276: f32[], y.277: f32[]) -> f32[] {
  %x.276 = f32[] parameter(0)
  %y.277 = f32[] parameter(1)
  ROOT %add.278 = f32[] add(f32[] %x.276, f32[] %y.277)
}

%AddComputation.288 (x.289: f32[], y.290: f32[]) -> f32[] {
  %x.289 = f32[] parameter(0)
  %y.290 = f32[] parameter(1)
  ROOT %add.291 = f32[] add(f32[] %x.289, f32[] %y.290)
}

%AddComputation.301 (x.302: f32[], y.303: f32[]) -> f32[] {
  %x.302 = f32[] parameter(0)
  %y.303 = f32[] parameter(1)
  ROOT %add.304 = f32[] add(f32[] %x.302, f32[] %y.303)
}

%AddComputation.314 (x.315: f32[], y.316: f32[]) -> f32[] {
  %x.315 = f32[] parameter(0)
  %y.316 = f32[] parameter(1)
  ROOT %add.317 = f32[] add(f32[] %x.315, f32[] %y.316)
}

%AddComputation.327 (x.328: f32[], y.329: f32[]) -> f32[] {
  %x.328 = f32[] parameter(0)
  %y.329 = f32[] parameter(1)
  ROOT %add.330 = f32[] add(f32[] %x.328, f32[] %y.329)
}

%AddComputation.340 (x.341: f32[], y.342: f32[]) -> f32[] {
  %x.341 = f32[] parameter(0)
  %y.342 = f32[] parameter(1)
  ROOT %add.343 = f32[] add(f32[] %x.341, f32[] %y.342)
}

%AddComputation.353 (x.354: f32[], y.355: f32[]) -> f32[] {
  %x.354 = f32[] parameter(0)
  %y.355 = f32[] parameter(1)
  ROOT %add.356 = f32[] add(f32[] %x.354, f32[] %y.355)
}

%AddComputation.366 (x.367: f32[], y.368: f32[]) -> f32[] {
  %x.367 = f32[] parameter(0)
  %y.368 = f32[] parameter(1)
  ROOT %add.369 = f32[] add(f32[] %x.367, f32[] %y.368)
}

%AddComputation.379 (x.380: f32[], y.381: f32[]) -> f32[] {
  %x.380 = f32[] parameter(0)
  %y.381 = f32[] parameter(1)
  ROOT %add.382 = f32[] add(f32[] %x.380, f32[] %y.381)
}

%AddComputation.392 (x.393: f32[], y.394: f32[]) -> f32[] {
  %x.393 = f32[] parameter(0)
  %y.394 = f32[] parameter(1)
  ROOT %add.395 = f32[] add(f32[] %x.393, f32[] %y.394)
}

%AddComputation.405 (x.406: f32[], y.407: f32[]) -> f32[] {
  %x.406 = f32[] parameter(0)
  %y.407 = f32[] parameter(1)
  ROOT %add.408 = f32[] add(f32[] %x.406, f32[] %y.407)
}

%AddComputation.418 (x.419: f32[], y.420: f32[]) -> f32[] {
  %x.419 = f32[] parameter(0)
  %y.420 = f32[] parameter(1)
  ROOT %add.421 = f32[] add(f32[] %x.419, f32[] %y.420)
}

%AddComputation.431 (x.432: f32[], y.433: f32[]) -> f32[] {
  %x.432 = f32[] parameter(0)
  %y.433 = f32[] parameter(1)
  ROOT %add.434 = f32[] add(f32[] %x.432, f32[] %y.433)
}

%AddComputation.444 (x.445: f32[], y.446: f32[]) -> f32[] {
  %x.445 = f32[] parameter(0)
  %y.446 = f32[] parameter(1)
  ROOT %add.447 = f32[] add(f32[] %x.445, f32[] %y.446)
}

%AddComputation.457 (x.458: f32[], y.459: f32[]) -> f32[] {
  %x.458 = f32[] parameter(0)
  %y.459 = f32[] parameter(1)
  ROOT %add.460 = f32[] add(f32[] %x.458, f32[] %y.459)
}

%AddComputation.470 (x.471: f32[], y.472: f32[]) -> f32[] {
  %x.471 = f32[] parameter(0)
  %y.472 = f32[] parameter(1)
  ROOT %add.473 = f32[] add(f32[] %x.471, f32[] %y.472)
}

%AddComputation.483 (x.484: f32[], y.485: f32[]) -> f32[] {
  %x.484 = f32[] parameter(0)
  %y.485 = f32[] parameter(1)
  ROOT %add.486 = f32[] add(f32[] %x.484, f32[] %y.485)
}

%AddComputation.496 (x.497: f32[], y.498: f32[]) -> f32[] {
  %x.497 = f32[] parameter(0)
  %y.498 = f32[] parameter(1)
  ROOT %add.499 = f32[] add(f32[] %x.497, f32[] %y.498)
}

%AddComputation.509 (x.510: f32[], y.511: f32[]) -> f32[] {
  %x.510 = f32[] parameter(0)
  %y.511 = f32[] parameter(1)
  ROOT %add.512 = f32[] add(f32[] %x.510, f32[] %y.511)
}

%AddComputation.522 (x.523: f32[], y.524: f32[]) -> f32[] {
  %x.523 = f32[] parameter(0)
  %y.524 = f32[] parameter(1)
  ROOT %add.525 = f32[] add(f32[] %x.523, f32[] %y.524)
}

%AddComputation.535 (x.536: f32[], y.537: f32[]) -> f32[] {
  %x.536 = f32[] parameter(0)
  %y.537 = f32[] parameter(1)
  ROOT %add.538 = f32[] add(f32[] %x.536, f32[] %y.537)
}

%AddComputation.548 (x.549: f32[], y.550: f32[]) -> f32[] {
  %x.549 = f32[] parameter(0)
  %y.550 = f32[] parameter(1)
  ROOT %add.551 = f32[] add(f32[] %x.549, f32[] %y.550)
}

%AddComputation.561 (x.562: f32[], y.563: f32[]) -> f32[] {
  %x.562 = f32[] parameter(0)
  %y.563 = f32[] parameter(1)
  ROOT %add.564 = f32[] add(f32[] %x.562, f32[] %y.563)
}

%AddComputation.574 (x.575: f32[], y.576: f32[]) -> f32[] {
  %x.575 = f32[] parameter(0)
  %y.576 = f32[] parameter(1)
  ROOT %add.577 = f32[] add(f32[] %x.575, f32[] %y.576)
}

%AddComputation.587 (x.588: f32[], y.589: f32[]) -> f32[] {
  %x.588 = f32[] parameter(0)
  %y.589 = f32[] parameter(1)
  ROOT %add.590 = f32[] add(f32[] %x.588, f32[] %y.589)
}

%AddComputation.600 (x.601: f32[], y.602: f32[]) -> f32[] {
  %x.601 = f32[] parameter(0)
  %y.602 = f32[] parameter(1)
  ROOT %add.603 = f32[] add(f32[] %x.601, f32[] %y.602)
}

%AddComputation.613 (x.614: f32[], y.615: f32[]) -> f32[] {
  %x.614 = f32[] parameter(0)
  %y.615 = f32[] parameter(1)
  ROOT %add.616 = f32[] add(f32[] %x.614, f32[] %y.615)
}

%AddComputation.688 (x.689: f32[], y.690: f32[]) -> f32[] {
  %x.689 = f32[] parameter(0)
  %y.690 = f32[] parameter(1)
  ROOT %add.691 = f32[] add(f32[] %x.689, f32[] %y.690)
}

ENTRY %SyncTensorsGraph.2268 (p0.8: f32[], p1.10: f32[], p2.20: f32[], p3.22: f32[1], p4.35: f32[30522,16], p5.36: f32[512,16], p6.37: f32[2,16], p7.38: f32[8,16], p8.39: f32[8,16], p9.40: f32[8,16], p10.41: f32[16,8], p11.42: f32[4096,16], p12.43: f32[16,4096], p13.44: f32[16,16], p14.45: f32[16,16], p15.46: f32[2,16], p16.47: f32[16], p17.48: f32[16], p18.49: f32[8], p19.50: f32[8], p20.51: f32[8], p21.52: f32[16], p22.53: f32[16], p23.54: f32[16], p24.55: f32[4096], p25.56: f32[16], p26.57: f32[16], p27.58: f32[16], p28.59: f32[16], p29.60: f32[30522], p30.61: f32[16], p31.62: f32[16], p32.63: f32[16], p33.64: f32[2], p34.226: f32[], p35.227: f32[1], p36.621: f32[1], p37.715: f32[], p38.730: f32[], p39.736: f32[], p40.745: f32[30522,16], p41.802: f32[512,16], p42.859: f32[2,16], p43.910: f32[16], p44.959: f32[16], p45.1014: f32[8,16], p46.1065: f32[8], p47.1120: f32[8,16], p48.1171: f32[8], p49.1226: f32[8,16], p50.1277: f32[8], p51.1332: f32[16,8], p52.1383: f32[16], p53.1432: f32[16], p54.1481: f32[16], p55.1536: f32[4096,16], p56.1587: f32[4096], p57.1642: f32[16,4096], p58.1693: f32[16], p59.1742: f32[16], p60.1791: f32[16], p61.1846: f32[16,16], p62.1897: f32[16], p63.1952: f32[16,16], p64.2003: f32[16], p65.2052: f32[16], p66.2101: f32[16], p67.2150: f32[30522], p68.2205: f32[2,16], p69.2256: f32[2]) -> (f32[30522,16], f32[512,16], f32[2,16], f32[16], f32[16], /*index=5*/f32[8,16], f32[8], f32[8,16], f32[8], f32[8,16], /*index=10*/f32[8], f32[16,8], f32[16], f32[16], f32[16], /*index=15*/f32[4096,16], f32[4096], f32[16,4096], f32[16], f32[16], /*index=20*/f32[16], f32[16,16], f32[16], f32[16,16], f32[16], /*index=25*/f32[16], f32[16], f32[30522], f32[2,16], f32[2], /*index=30*/f32[1], f32[1], f32[1], f32[30522,16], f32[30522,16], /*index=35*/f32[512,16], f32[512,16], f32[2,16], f32[2,16], f32[8,16], /*index=40*/f32[8,16], f32[8,16], f32[8,16], f32[8,16], f32[8,16], /*index=45*/f32[16,8], f32[16,8], f32[4096,16], f32[4096,16], f32[16,4096], /*index=50*/f32[16,4096], f32[16,16], f32[16,16], f32[16,16], f32[16,16], /*index=55*/f32[2,16], f32[2,16], f32[16], f32[16], f32[16], /*index=60*/f32[16], f32[8], f32[8], f32[8], f32[8], /*index=65*/f32[8], f32[8], f32[16], f32[16], f32[16], /*index=70*/f32[16], f32[16], f32[16], f32[4096], f32[4096], /*index=75*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=80*/f32[16], f32[16], f32[16], f32[30522], f32[30522], /*index=85*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=90*/f32[16], f32[2], f32[2], f32[1]) {
  %p40.745 = f32[30522,16]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.3 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %p39.736 = f32[] parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.32 = f32[] multiply(f32[] %constant.3, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.2 = f32[30522,16]{1,0} broadcast(f32[] %multiply.32), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %p33.64 = f32[2]{0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p32.63 = f32[16]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p31.62 = f32[16]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p30.61 = f32[16]{0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p29.60 = f32[30522]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p28.59 = f32[16]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p27.58 = f32[16]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p26.57 = f32[16]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p25.56 = f32[16]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p24.55 = f32[4096]{0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p23.54 = f32[16]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p22.53 = f32[16]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p21.52 = f32[16]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p20.51 = f32[8]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p19.50 = f32[8]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p18.49 = f32[8]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p17.48 = f32[16]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p16.47 = f32[16]{0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p15.46 = f32[2,16]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p14.45 = f32[16,16]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p13.44 = f32[16,16]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p12.43 = f32[16,4096]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p11.42 = f32[4096,16]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p10.41 = f32[16,8]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p9.40 = f32[8,16]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p8.39 = f32[8,16]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p7.38 = f32[8,16]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p6.37 = f32[2,16]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p5.36 = f32[512,16]{1,0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p4.35 = f32[30522,16]{1,0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p3.22 = f32[1]{0} parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=511}
  %p2.20 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %all-reduce.32 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %p3.22, f32[] %p2.20), replica_groups={{0},{1}}, constrain_layout=true, to_apply=%AddComputation.28, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %get-tuple-element.96 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.32), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %all-reduce.101 = (f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) all-reduce(f32[2]{0} %p33.64, f32[16]{0} %p32.63, f32[16]{0} %p31.62, f32[16]{0} %p30.61, f32[30522]{0} %p29.60, /*index=5*/f32[16]{0} %p28.59, f32[16]{0} %p27.58, f32[16]{0} %p26.57, f32[16]{0} %p25.56, f32[4096]{0} %p24.55, /*index=10*/f32[16]{0} %p23.54, f32[16]{0} %p22.53, f32[16]{0} %p21.52, f32[8]{0} %p20.51, f32[8]{0} %p19.50, /*index=15*/f32[8]{0} %p18.49, f32[16]{0} %p17.48, f32[16]{0} %p16.47, f32[2,16]{1,0} %p15.46, f32[16,16]{1,0} %p14.45, /*index=20*/f32[16,16]{1,0} %p13.44, f32[16,4096]{1,0} %p12.43, f32[4096,16]{1,0} %p11.42, f32[16,8]{1,0} %p10.41, f32[8,16]{1,0} %p9.40, /*index=25*/f32[8,16]{1,0} %p8.39, f32[8,16]{1,0} %p7.38, f32[2,16]{1,0} %p6.37, f32[512,16]{1,0} %p5.36, f32[30522,16]{1,0} %p4.35, /*index=30*/f32[] %get-tuple-element.96), replica_groups={{0},{1}}, constrain_layout=true, to_apply=%AddComputation.97, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.218 = f32[30522,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=29, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.4 = f32[1]{0} constant({1}), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=913}
  %p36.621 = f32[1]{0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=144}
  %constant.219 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.220 = f32[30522,16]{1,0} broadcast(f32[] %constant.219), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.221 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %get-tuple-element.218, f32[30522,16]{1,0} %broadcast.220), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.610 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.221, f32[30522,16]{1,0} %multiply.221), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.611 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.617 = f32[] reduce(f32[30522,16]{1,0} %multiply.610, f32[] %constant.611), dimensions={0,1}, to_apply=%AddComputation.613, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.618 = f32[] sqrt(f32[] %reduce.617), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.620 = f32[] multiply(f32[] %sqrt.618, f32[] %sqrt.618), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.1 = f32[1]{0} reshape(f32[] %multiply.620), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.623 = f32[1]{0} add(f32[1]{0} %p36.621, f32[1]{0} %reshape.1), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.214 = f32[512,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=28, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.215 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.216 = f32[512,16]{1,0} broadcast(f32[] %constant.215), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.217 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %get-tuple-element.214, f32[512,16]{1,0} %broadcast.216), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.597 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.217, f32[512,16]{1,0} %multiply.217), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.598 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.604 = f32[] reduce(f32[512,16]{1,0} %multiply.597, f32[] %constant.598), dimensions={0,1}, to_apply=%AddComputation.600, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.605 = f32[] sqrt(f32[] %reduce.604), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.607 = f32[] multiply(f32[] %sqrt.605, f32[] %sqrt.605), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.3 = f32[1]{0} reshape(f32[] %multiply.607), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.625 = f32[1]{0} add(f32[1]{0} %add.623, f32[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.210 = f32[2,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=27, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.211 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.212 = f32[2,16]{1,0} broadcast(f32[] %constant.211), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.213 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.210, f32[2,16]{1,0} %broadcast.212), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.584 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.213, f32[2,16]{1,0} %multiply.213), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.585 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.591 = f32[] reduce(f32[2,16]{1,0} %multiply.584, f32[] %constant.585), dimensions={0,1}, to_apply=%AddComputation.587, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.592 = f32[] sqrt(f32[] %reduce.591), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.594 = f32[] multiply(f32[] %sqrt.592, f32[] %sqrt.592), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.5 = f32[1]{0} reshape(f32[] %multiply.594), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.627 = f32[1]{0} add(f32[1]{0} %add.625, f32[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.170 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=17, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.171 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.172 = f32[16]{0} broadcast(f32[] %constant.171), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.173 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.170, f32[16]{0} %broadcast.172), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.571 = f32[16]{0} multiply(f32[16]{0} %multiply.173, f32[16]{0} %multiply.173), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.572 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.578 = f32[] reduce(f32[16]{0} %multiply.571, f32[] %constant.572), dimensions={0}, to_apply=%AddComputation.574, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.579 = f32[] sqrt(f32[] %reduce.578), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.581 = f32[] multiply(f32[] %sqrt.579, f32[] %sqrt.579), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.6 = f32[1]{0} reshape(f32[] %multiply.581), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.629 = f32[1]{0} add(f32[1]{0} %add.627, f32[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.166 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=16, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.167 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.168 = f32[16]{0} broadcast(f32[] %constant.167), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.169 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.166, f32[16]{0} %broadcast.168), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.558 = f32[16]{0} multiply(f32[16]{0} %multiply.169, f32[16]{0} %multiply.169), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.559 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.565 = f32[] reduce(f32[16]{0} %multiply.558, f32[] %constant.559), dimensions={0}, to_apply=%AddComputation.561, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.566 = f32[] sqrt(f32[] %reduce.565), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.568 = f32[] multiply(f32[] %sqrt.566, f32[] %sqrt.566), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.7 = f32[1]{0} reshape(f32[] %multiply.568), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.631 = f32[1]{0} add(f32[1]{0} %add.629, f32[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.150 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=12, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.151 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.152 = f32[16]{0} broadcast(f32[] %constant.151), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.153 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.150, f32[16]{0} %broadcast.152), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.545 = f32[16]{0} multiply(f32[16]{0} %multiply.153, f32[16]{0} %multiply.153), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.546 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.552 = f32[] reduce(f32[16]{0} %multiply.545, f32[] %constant.546), dimensions={0}, to_apply=%AddComputation.548, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.553 = f32[] sqrt(f32[] %reduce.552), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.555 = f32[] multiply(f32[] %sqrt.553, f32[] %sqrt.553), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.8 = f32[1]{0} reshape(f32[] %multiply.555), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.633 = f32[1]{0} add(f32[1]{0} %add.631, f32[1]{0} %reshape.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.146 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=11, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.147 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.148 = f32[16]{0} broadcast(f32[] %constant.147), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.149 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.146, f32[16]{0} %broadcast.148), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.532 = f32[16]{0} multiply(f32[16]{0} %multiply.149, f32[16]{0} %multiply.149), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.533 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.539 = f32[] reduce(f32[16]{0} %multiply.532, f32[] %constant.533), dimensions={0}, to_apply=%AddComputation.535, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.540 = f32[] sqrt(f32[] %reduce.539), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.542 = f32[] multiply(f32[] %sqrt.540, f32[] %sqrt.540), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.9 = f32[1]{0} reshape(f32[] %multiply.542), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.635 = f32[1]{0} add(f32[1]{0} %add.633, f32[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.142 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.143 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.144 = f32[16]{0} broadcast(f32[] %constant.143), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.145 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.142, f32[16]{0} %broadcast.144), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.519 = f32[16]{0} multiply(f32[16]{0} %multiply.145, f32[16]{0} %multiply.145), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.520 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.526 = f32[] reduce(f32[16]{0} %multiply.519, f32[] %constant.520), dimensions={0}, to_apply=%AddComputation.522, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.527 = f32[] sqrt(f32[] %reduce.526), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.529 = f32[] multiply(f32[] %sqrt.527, f32[] %sqrt.527), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.10 = f32[1]{0} reshape(f32[] %multiply.529), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.637 = f32[1]{0} add(f32[1]{0} %add.635, f32[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.190 = f32[4096,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=22, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.191 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.192 = f32[4096,16]{1,0} broadcast(f32[] %constant.191), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.193 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %get-tuple-element.190, f32[4096,16]{1,0} %broadcast.192), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.506 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.193, f32[4096,16]{1,0} %multiply.193), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.507 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.513 = f32[] reduce(f32[4096,16]{1,0} %multiply.506, f32[] %constant.507), dimensions={0,1}, to_apply=%AddComputation.509, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.514 = f32[] sqrt(f32[] %reduce.513), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.516 = f32[] multiply(f32[] %sqrt.514, f32[] %sqrt.514), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.11 = f32[1]{0} reshape(f32[] %multiply.516), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.639 = f32[1]{0} add(f32[1]{0} %add.637, f32[1]{0} %reshape.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.138 = f32[4096]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=9, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.139 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.140 = f32[4096]{0} broadcast(f32[] %constant.139), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.141 = f32[4096]{0} multiply(f32[4096]{0} %get-tuple-element.138, f32[4096]{0} %broadcast.140), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.493 = f32[4096]{0} multiply(f32[4096]{0} %multiply.141, f32[4096]{0} %multiply.141), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.494 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.500 = f32[] reduce(f32[4096]{0} %multiply.493, f32[] %constant.494), dimensions={0}, to_apply=%AddComputation.496, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.501 = f32[] sqrt(f32[] %reduce.500), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.503 = f32[] multiply(f32[] %sqrt.501, f32[] %sqrt.501), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.13 = f32[1]{0} reshape(f32[] %multiply.503), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.641 = f32[1]{0} add(f32[1]{0} %add.639, f32[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.186 = f32[16,4096]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=21, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.187 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.188 = f32[16,4096]{1,0} broadcast(f32[] %constant.187), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.189 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %get-tuple-element.186, f32[16,4096]{1,0} %broadcast.188), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.480 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.189, f32[16,4096]{1,0} %multiply.189), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.481 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.487 = f32[] reduce(f32[16,4096]{1,0} %multiply.480, f32[] %constant.481), dimensions={0,1}, to_apply=%AddComputation.483, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.488 = f32[] sqrt(f32[] %reduce.487), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.490 = f32[] multiply(f32[] %sqrt.488, f32[] %sqrt.488), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.14 = f32[1]{0} reshape(f32[] %multiply.490), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.643 = f32[1]{0} add(f32[1]{0} %add.641, f32[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.134 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=8, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.135 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.136 = f32[16]{0} broadcast(f32[] %constant.135), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.137 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.134, f32[16]{0} %broadcast.136), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.467 = f32[16]{0} multiply(f32[16]{0} %multiply.137, f32[16]{0} %multiply.137), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.468 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.474 = f32[] reduce(f32[16]{0} %multiply.467, f32[] %constant.468), dimensions={0}, to_apply=%AddComputation.470, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.475 = f32[] sqrt(f32[] %reduce.474), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.477 = f32[] multiply(f32[] %sqrt.475, f32[] %sqrt.475), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.15 = f32[1]{0} reshape(f32[] %multiply.477), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.645 = f32[1]{0} add(f32[1]{0} %add.643, f32[1]{0} %reshape.15), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.130 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=7, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.131 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.132 = f32[16]{0} broadcast(f32[] %constant.131), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.133 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.130, f32[16]{0} %broadcast.132), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.454 = f32[16]{0} multiply(f32[16]{0} %multiply.133, f32[16]{0} %multiply.133), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.455 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.461 = f32[] reduce(f32[16]{0} %multiply.454, f32[] %constant.455), dimensions={0}, to_apply=%AddComputation.457, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.462 = f32[] sqrt(f32[] %reduce.461), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.464 = f32[] multiply(f32[] %sqrt.462, f32[] %sqrt.462), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.16 = f32[1]{0} reshape(f32[] %multiply.464), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.647 = f32[1]{0} add(f32[1]{0} %add.645, f32[1]{0} %reshape.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.126 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=6, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.127 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.128 = f32[16]{0} broadcast(f32[] %constant.127), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.129 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.126, f32[16]{0} %broadcast.128), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.441 = f32[16]{0} multiply(f32[16]{0} %multiply.129, f32[16]{0} %multiply.129), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.442 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.448 = f32[] reduce(f32[16]{0} %multiply.441, f32[] %constant.442), dimensions={0}, to_apply=%AddComputation.444, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.449 = f32[] sqrt(f32[] %reduce.448), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.451 = f32[] multiply(f32[] %sqrt.449, f32[] %sqrt.449), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.17 = f32[1]{0} reshape(f32[] %multiply.451), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.649 = f32[1]{0} add(f32[1]{0} %add.647, f32[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.182 = f32[16,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=20, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.183 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.184 = f32[16,16]{1,0} broadcast(f32[] %constant.183), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.185 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.182, f32[16,16]{1,0} %broadcast.184), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.428 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.185, f32[16,16]{1,0} %multiply.185), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.429 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.435 = f32[] reduce(f32[16,16]{1,0} %multiply.428, f32[] %constant.429), dimensions={0,1}, to_apply=%AddComputation.431, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.436 = f32[] sqrt(f32[] %reduce.435), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.438 = f32[] multiply(f32[] %sqrt.436, f32[] %sqrt.436), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.19 = f32[1]{0} reshape(f32[] %multiply.438), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.651 = f32[1]{0} add(f32[1]{0} %add.649, f32[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.122 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=5, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.123 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.124 = f32[16]{0} broadcast(f32[] %constant.123), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.125 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.122, f32[16]{0} %broadcast.124), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.415 = f32[16]{0} multiply(f32[16]{0} %multiply.125, f32[16]{0} %multiply.125), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.416 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.422 = f32[] reduce(f32[16]{0} %multiply.415, f32[] %constant.416), dimensions={0}, to_apply=%AddComputation.418, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.423 = f32[] sqrt(f32[] %reduce.422), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.425 = f32[] multiply(f32[] %sqrt.423, f32[] %sqrt.423), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.20 = f32[1]{0} reshape(f32[] %multiply.425), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.653 = f32[1]{0} add(f32[1]{0} %add.651, f32[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.118 = f32[30522]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=4, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.119 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.120 = f32[30522]{0} broadcast(f32[] %constant.119), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.121 = f32[30522]{0} multiply(f32[30522]{0} %get-tuple-element.118, f32[30522]{0} %broadcast.120), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.402 = f32[30522]{0} multiply(f32[30522]{0} %multiply.121, f32[30522]{0} %multiply.121), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.403 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.409 = f32[] reduce(f32[30522]{0} %multiply.402, f32[] %constant.403), dimensions={0}, to_apply=%AddComputation.405, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.410 = f32[] sqrt(f32[] %reduce.409), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.412 = f32[] multiply(f32[] %sqrt.410, f32[] %sqrt.410), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.21 = f32[1]{0} reshape(f32[] %multiply.412), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.655 = f32[1]{0} add(f32[1]{0} %add.653, f32[1]{0} %reshape.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.178 = f32[16,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=19, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.179 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.180 = f32[16,16]{1,0} broadcast(f32[] %constant.179), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.181 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.178, f32[16,16]{1,0} %broadcast.180), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.389 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.181, f32[16,16]{1,0} %multiply.181), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.390 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.396 = f32[] reduce(f32[16,16]{1,0} %multiply.389, f32[] %constant.390), dimensions={0,1}, to_apply=%AddComputation.392, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.397 = f32[] sqrt(f32[] %reduce.396), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.399 = f32[] multiply(f32[] %sqrt.397, f32[] %sqrt.397), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.22 = f32[1]{0} reshape(f32[] %multiply.399), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.657 = f32[1]{0} add(f32[1]{0} %add.655, f32[1]{0} %reshape.22), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.114 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=3, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.115 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.116 = f32[16]{0} broadcast(f32[] %constant.115), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.117 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.114, f32[16]{0} %broadcast.116), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.376 = f32[16]{0} multiply(f32[16]{0} %multiply.117, f32[16]{0} %multiply.117), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.377 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.383 = f32[] reduce(f32[16]{0} %multiply.376, f32[] %constant.377), dimensions={0}, to_apply=%AddComputation.379, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.384 = f32[] sqrt(f32[] %reduce.383), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.386 = f32[] multiply(f32[] %sqrt.384, f32[] %sqrt.384), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.23 = f32[1]{0} reshape(f32[] %multiply.386), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.659 = f32[1]{0} add(f32[1]{0} %add.657, f32[1]{0} %reshape.23), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.110 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.111 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.112 = f32[16]{0} broadcast(f32[] %constant.111), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.113 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.110, f32[16]{0} %broadcast.112), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.363 = f32[16]{0} multiply(f32[16]{0} %multiply.113, f32[16]{0} %multiply.113), metadata={op_type="aten__mul" op_name="aten__norm.20/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.364 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.370 = f32[] reduce(f32[16]{0} %multiply.363, f32[] %constant.364), dimensions={0}, to_apply=%AddComputation.366, metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.371 = f32[] sqrt(f32[] %reduce.370), metadata={op_type="aten__sqrt" op_name="aten__norm.20/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.373 = f32[] multiply(f32[] %sqrt.371, f32[] %sqrt.371), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.24 = f32[1]{0} reshape(f32[] %multiply.373), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.661 = f32[1]{0} add(f32[1]{0} %add.659, f32[1]{0} %reshape.24), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.106 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.107 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.108 = f32[16]{0} broadcast(f32[] %constant.107), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.109 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.106, f32[16]{0} %broadcast.108), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.350 = f32[16]{0} multiply(f32[16]{0} %multiply.109, f32[16]{0} %multiply.109), metadata={op_type="aten__mul" op_name="aten__norm.21/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.351 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.357 = f32[] reduce(f32[16]{0} %multiply.350, f32[] %constant.351), dimensions={0}, to_apply=%AddComputation.353, metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.358 = f32[] sqrt(f32[] %reduce.357), metadata={op_type="aten__sqrt" op_name="aten__norm.21/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.360 = f32[] multiply(f32[] %sqrt.358, f32[] %sqrt.358), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.25 = f32[1]{0} reshape(f32[] %multiply.360), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.663 = f32[1]{0} add(f32[1]{0} %add.661, f32[1]{0} %reshape.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.174 = f32[2,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=18, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.175 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.176 = f32[2,16]{1,0} broadcast(f32[] %constant.175), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.177 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.174, f32[2,16]{1,0} %broadcast.176), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.337 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.177, f32[2,16]{1,0} %multiply.177), metadata={op_type="aten__mul" op_name="aten__norm.22/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.338 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.344 = f32[] reduce(f32[2,16]{1,0} %multiply.337, f32[] %constant.338), dimensions={0,1}, to_apply=%AddComputation.340, metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.345 = f32[] sqrt(f32[] %reduce.344), metadata={op_type="aten__sqrt" op_name="aten__norm.22/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.347 = f32[] multiply(f32[] %sqrt.345, f32[] %sqrt.345), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.26 = f32[1]{0} reshape(f32[] %multiply.347), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.665 = f32[1]{0} add(f32[1]{0} %add.663, f32[1]{0} %reshape.26), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %get-tuple-element.102 = f32[2]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.103 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.104 = f32[2]{0} broadcast(f32[] %constant.103), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.105 = f32[2]{0} multiply(f32[2]{0} %get-tuple-element.102, f32[2]{0} %broadcast.104), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.324 = f32[2]{0} multiply(f32[2]{0} %multiply.105, f32[2]{0} %multiply.105), metadata={op_type="aten__mul" op_name="aten__norm.23/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.325 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.331 = f32[] reduce(f32[2]{0} %multiply.324, f32[] %constant.325), dimensions={0}, to_apply=%AddComputation.327, metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.332 = f32[] sqrt(f32[] %reduce.331), metadata={op_type="aten__sqrt" op_name="aten__norm.23/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.334 = f32[] multiply(f32[] %sqrt.332, f32[] %sqrt.332), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.27 = f32[1]{0} reshape(f32[] %multiply.334), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %add.667 = f32[1]{0} add(f32[1]{0} %add.665, f32[1]{0} %reshape.27), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=163}
  %p34.226 = f32[] parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=165}
  %reshape.28 = f32[1]{0} reshape(f32[] %p34.226), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=164}
  %divide.669 = f32[1]{0} divide(f32[1]{0} %add.667, f32[1]{0} %reshape.28), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=164}
  %get-tuple-element.206 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=26, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.207 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.208 = f32[8,16]{1,0} broadcast(f32[] %constant.207), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.209 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.206, f32[8,16]{1,0} %broadcast.208), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.311 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.209, f32[8,16]{1,0} %multiply.209), metadata={op_type="aten__mul" op_name="aten__norm.24/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.312 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.318 = f32[] reduce(f32[8,16]{1,0} %multiply.311, f32[] %constant.312), dimensions={0,1}, to_apply=%AddComputation.314, metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.319 = f32[] sqrt(f32[] %reduce.318), metadata={op_type="aten__sqrt" op_name="aten__norm.24/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.321 = f32[] multiply(f32[] %sqrt.319, f32[] %sqrt.319), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.29 = f32[1]{0} reshape(f32[] %multiply.321), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.671 = f32[1]{0} add(f32[1]{0} %divide.669, f32[1]{0} %reshape.29), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.162 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=15, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.163 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.164 = f32[8]{0} broadcast(f32[] %constant.163), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.165 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.162, f32[8]{0} %broadcast.164), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.298 = f32[8]{0} multiply(f32[8]{0} %multiply.165, f32[8]{0} %multiply.165), metadata={op_type="aten__mul" op_name="aten__norm.25/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.299 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.305 = f32[] reduce(f32[8]{0} %multiply.298, f32[] %constant.299), dimensions={0}, to_apply=%AddComputation.301, metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.306 = f32[] sqrt(f32[] %reduce.305), metadata={op_type="aten__sqrt" op_name="aten__norm.25/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.308 = f32[] multiply(f32[] %sqrt.306, f32[] %sqrt.306), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.30 = f32[1]{0} reshape(f32[] %multiply.308), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.673 = f32[1]{0} add(f32[1]{0} %add.671, f32[1]{0} %reshape.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.202 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.203 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.204 = f32[8,16]{1,0} broadcast(f32[] %constant.203), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.205 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.202, f32[8,16]{1,0} %broadcast.204), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.285 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.205, f32[8,16]{1,0} %multiply.205), metadata={op_type="aten__mul" op_name="aten__norm.26/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.286 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.292 = f32[] reduce(f32[8,16]{1,0} %multiply.285, f32[] %constant.286), dimensions={0,1}, to_apply=%AddComputation.288, metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.293 = f32[] sqrt(f32[] %reduce.292), metadata={op_type="aten__sqrt" op_name="aten__norm.26/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.295 = f32[] multiply(f32[] %sqrt.293, f32[] %sqrt.293), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.31 = f32[1]{0} reshape(f32[] %multiply.295), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.675 = f32[1]{0} add(f32[1]{0} %add.673, f32[1]{0} %reshape.31), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.158 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=14, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.159 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.160 = f32[8]{0} broadcast(f32[] %constant.159), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.161 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.158, f32[8]{0} %broadcast.160), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.272 = f32[8]{0} multiply(f32[8]{0} %multiply.161, f32[8]{0} %multiply.161), metadata={op_type="aten__mul" op_name="aten__norm.27/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.273 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.279 = f32[] reduce(f32[8]{0} %multiply.272, f32[] %constant.273), dimensions={0}, to_apply=%AddComputation.275, metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.280 = f32[] sqrt(f32[] %reduce.279), metadata={op_type="aten__sqrt" op_name="aten__norm.27/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.282 = f32[] multiply(f32[] %sqrt.280, f32[] %sqrt.280), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.32 = f32[1]{0} reshape(f32[] %multiply.282), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.677 = f32[1]{0} add(f32[1]{0} %add.675, f32[1]{0} %reshape.32), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.198 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=24, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.199 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.200 = f32[8,16]{1,0} broadcast(f32[] %constant.199), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.201 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.198, f32[8,16]{1,0} %broadcast.200), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.259 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.201, f32[8,16]{1,0} %multiply.201), metadata={op_type="aten__mul" op_name="aten__norm.28/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.260 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.266 = f32[] reduce(f32[8,16]{1,0} %multiply.259, f32[] %constant.260), dimensions={0,1}, to_apply=%AddComputation.262, metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.267 = f32[] sqrt(f32[] %reduce.266), metadata={op_type="aten__sqrt" op_name="aten__norm.28/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.269 = f32[] multiply(f32[] %sqrt.267, f32[] %sqrt.267), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.33 = f32[1]{0} reshape(f32[] %multiply.269), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.679 = f32[1]{0} add(f32[1]{0} %add.677, f32[1]{0} %reshape.33), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.154 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=13, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.155 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.156 = f32[8]{0} broadcast(f32[] %constant.155), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.157 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.154, f32[8]{0} %broadcast.156), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.246 = f32[8]{0} multiply(f32[8]{0} %multiply.157, f32[8]{0} %multiply.157), metadata={op_type="aten__mul" op_name="aten__norm.29/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.247 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.253 = f32[] reduce(f32[8]{0} %multiply.246, f32[] %constant.247), dimensions={0}, to_apply=%AddComputation.249, metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.254 = f32[] sqrt(f32[] %reduce.253), metadata={op_type="aten__sqrt" op_name="aten__norm.29/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.256 = f32[] multiply(f32[] %sqrt.254, f32[] %sqrt.254), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.34 = f32[1]{0} reshape(f32[] %multiply.256), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.681 = f32[1]{0} add(f32[1]{0} %add.679, f32[1]{0} %reshape.34), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %get-tuple-element.194 = f32[16,8]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=23, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.195 = f32[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.196 = f32[16,8]{1,0} broadcast(f32[] %constant.195), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.197 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %get-tuple-element.194, f32[16,8]{1,0} %broadcast.196), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.233 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.197, f32[16,8]{1,0} %multiply.197), metadata={op_type="aten__mul" op_name="aten__norm.30/aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.234 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.240 = f32[] reduce(f32[16,8]{1,0} %multiply.233, f32[] %constant.234), dimensions={0,1}, to_apply=%AddComputation.236, metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.241 = f32[] sqrt(f32[] %reduce.240), metadata={op_type="aten__sqrt" op_name="aten__norm.30/aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.243 = f32[] multiply(f32[] %sqrt.241, f32[] %sqrt.241), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.35 = f32[1]{0} reshape(f32[] %multiply.243), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %add.683 = f32[1]{0} add(f32[1]{0} %add.681, f32[1]{0} %reshape.35), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=172}
  %p35.227 = f32[1]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=145}
  %reshape.36 = f32[1]{0} reshape(f32[] %p34.226), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=165}
  %divide.229 = f32[1]{0} divide(f32[1]{0} %p35.227, f32[1]{0} %reshape.36), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=165}
  %add.684 = f32[1]{0} add(f32[1]{0} %add.683, f32[1]{0} %divide.229), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=85}
  %get-tuple-element.687 = f32[] get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=30, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.692 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %add.684, f32[] %get-tuple-element.687), replica_groups={{0,1}}, to_apply=%AddComputation.688, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.693 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.692), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.5 = f32[1]{0} constant({0.5}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=175}
  %power.695 = f32[1]{0} power(f32[1]{0} %get-tuple-element.693, f32[1]{0} %constant.5), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=175}
  %p0.8 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %reshape.42 = f32[1]{0} reshape(f32[] %p0.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=231}
  %add.697 = f32[1]{0} add(f32[1]{0} %power.695, f32[1]{0} %reshape.42), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=231}
  %divide.700 = f32[1]{0} divide(f32[1]{0} %constant.4, f32[1]{0} %add.697), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=913}
  %constant.10 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.707 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.10), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.12 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.709 = f32[1]{0} select(pred[1]{0} %compare.707, f32[1]{0} %divide.700, f32[1]{0} %constant.12), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.186 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.168 = f32[1]{0} multiply(f32[1]{0} %select.709, f32[1]{0} %constant.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.653 = f32[] reshape(f32[1]{0} %multiply.168), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.6 = f32[30522,16]{1,0} broadcast(f32[] %reshape.653), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.714 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %get-tuple-element.218, f32[30522,16]{1,0} %broadcast.6), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %p38.730 = f32[] parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.734 = f32[30522,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.735 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.714, f32[30522,16]{1,0} %broadcast.734), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.744 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.2, f32[30522,16]{1,0} %multiply.735), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.13 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %p37.715 = f32[] parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.35 = f32[] multiply(f32[] %constant.13, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.9 = f32[30522,16]{1,0} broadcast(f32[] %multiply.35), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.723 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.714, f32[30522,16]{1,0} %multiply.714), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %p1.10 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.724 = f32[30522,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.725 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.723, f32[30522,16]{1,0} %broadcast.724), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.726 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.9, f32[30522,16]{1,0} %multiply.725), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.727 = f32[30522,16]{1,0} sqrt(f32[30522,16]{1,0} %add.726), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.728 = f32[30522,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.729 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %sqrt.727, f32[30522,16]{1,0} %broadcast.728), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.746 = f32[30522,16]{1,0} divide(f32[30522,16]{1,0} %add.744, f32[30522,16]{1,0} %add.729), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.6 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.747 = f32[30522,16]{1,0} broadcast(f32[] %constant.6), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.748 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %divide.746, f32[30522,16]{1,0} %broadcast.747), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.749 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %p40.745, f32[30522,16]{1,0} %multiply.748), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.5 = f32[30522,16]{1,0} broadcast(f32[] %constant.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.750 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %add.749, f32[30522,16]{1,0} %broadcast.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.751 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %add.749, f32[30522,16]{1,0} %multiply.750), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p41.802 = f32[512,16]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.16 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.36 = f32[] multiply(f32[] %constant.16, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.12 = f32[512,16]{1,0} broadcast(f32[] %multiply.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.19 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.767 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.19), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.20 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.769 = f32[1]{0} select(pred[1]{0} %compare.767, f32[1]{0} %divide.700, f32[1]{0} %constant.20), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.188 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.170 = f32[1]{0} multiply(f32[1]{0} %select.769, f32[1]{0} %constant.188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.656 = f32[] reshape(f32[1]{0} %multiply.170), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.15 = f32[512,16]{1,0} broadcast(f32[] %reshape.656), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.774 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %get-tuple-element.214, f32[512,16]{1,0} %broadcast.15), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.792 = f32[512,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.793 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.774, f32[512,16]{1,0} %broadcast.792), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.801 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.12, f32[512,16]{1,0} %multiply.793), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.22 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.39 = f32[] multiply(f32[] %constant.22, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.18 = f32[512,16]{1,0} broadcast(f32[] %multiply.39), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.782 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.774, f32[512,16]{1,0} %multiply.774), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.783 = f32[512,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.784 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.782, f32[512,16]{1,0} %broadcast.783), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.785 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.18, f32[512,16]{1,0} %multiply.784), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.786 = f32[512,16]{1,0} sqrt(f32[512,16]{1,0} %add.785), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.787 = f32[512,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.788 = f32[512,16]{1,0} add(f32[512,16]{1,0} %sqrt.786, f32[512,16]{1,0} %broadcast.787), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.803 = f32[512,16]{1,0} divide(f32[512,16]{1,0} %add.801, f32[512,16]{1,0} %add.788), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.757 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.804 = f32[512,16]{1,0} broadcast(f32[] %constant.757), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.805 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %divide.803, f32[512,16]{1,0} %broadcast.804), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.806 = f32[512,16]{1,0} add(f32[512,16]{1,0} %p41.802, f32[512,16]{1,0} %multiply.805), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.752 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.756 = f32[512,16]{1,0} broadcast(f32[] %constant.752), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.807 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %add.806, f32[512,16]{1,0} %broadcast.756), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.808 = f32[512,16]{1,0} add(f32[512,16]{1,0} %add.806, f32[512,16]{1,0} %multiply.807), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p42.859 = f32[2,16]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.23 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.40 = f32[] multiply(f32[] %constant.23, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.22 = f32[2,16]{1,0} broadcast(f32[] %multiply.40), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.25 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.824 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.26 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.826 = f32[1]{0} select(pred[1]{0} %compare.824, f32[1]{0} %divide.700, f32[1]{0} %constant.26), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.189 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.171 = f32[1]{0} multiply(f32[1]{0} %select.826, f32[1]{0} %constant.189), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.659 = f32[] reshape(f32[1]{0} %multiply.171), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.25 = f32[2,16]{1,0} broadcast(f32[] %reshape.659), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.831 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.210, f32[2,16]{1,0} %broadcast.25), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.849 = f32[2,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.850 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.831, f32[2,16]{1,0} %broadcast.849), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.858 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.22, f32[2,16]{1,0} %multiply.850), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.27 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.43 = f32[] multiply(f32[] %constant.27, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.28 = f32[2,16]{1,0} broadcast(f32[] %multiply.43), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.839 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.831, f32[2,16]{1,0} %multiply.831), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.840 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.841 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.839, f32[2,16]{1,0} %broadcast.840), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.842 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.28, f32[2,16]{1,0} %multiply.841), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.843 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.842), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.844 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.845 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.843, f32[2,16]{1,0} %broadcast.844), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.860 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.858, f32[2,16]{1,0} %add.845), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.814 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.861 = f32[2,16]{1,0} broadcast(f32[] %constant.814), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.862 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.860, f32[2,16]{1,0} %broadcast.861), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.863 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p42.859, f32[2,16]{1,0} %multiply.862), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.809 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.813 = f32[2,16]{1,0} broadcast(f32[] %constant.809), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.864 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.863, f32[2,16]{1,0} %broadcast.813), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.865 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.863, f32[2,16]{1,0} %multiply.864), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p43.910 = f32[16]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.28 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.44 = f32[] multiply(f32[] %constant.28, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.31 = f32[16]{0} broadcast(f32[] %multiply.44), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.30 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.876 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.30), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.31 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.878 = f32[1]{0} select(pred[1]{0} %compare.876, f32[1]{0} %divide.700, f32[1]{0} %constant.31), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.190 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.172 = f32[1]{0} multiply(f32[1]{0} %select.878, f32[1]{0} %constant.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.662 = f32[] reshape(f32[1]{0} %multiply.172), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.32 = f32[16]{0} broadcast(f32[] %reshape.662), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.882 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.170, f32[16]{0} %broadcast.32), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.900 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.901 = f32[16]{0} multiply(f32[16]{0} %multiply.882, f32[16]{0} %broadcast.900), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.909 = f32[16]{0} add(f32[16]{0} %broadcast.31, f32[16]{0} %multiply.901), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.32 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.47 = f32[] multiply(f32[] %constant.32, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.35 = f32[16]{0} broadcast(f32[] %multiply.47), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.890 = f32[16]{0} multiply(f32[16]{0} %multiply.882, f32[16]{0} %multiply.882), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.891 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.892 = f32[16]{0} multiply(f32[16]{0} %multiply.890, f32[16]{0} %broadcast.891), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.893 = f32[16]{0} add(f32[16]{0} %broadcast.35, f32[16]{0} %multiply.892), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.894 = f32[16]{0} sqrt(f32[16]{0} %add.893), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.895 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.896 = f32[16]{0} add(f32[16]{0} %sqrt.894, f32[16]{0} %broadcast.895), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.911 = f32[16]{0} divide(f32[16]{0} %add.909, f32[16]{0} %add.896), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.866 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.912 = f32[16]{0} broadcast(f32[] %constant.866), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.913 = f32[16]{0} multiply(f32[16]{0} %divide.911, f32[16]{0} %broadcast.912), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.914 = f32[16]{0} add(f32[16]{0} %p43.910, f32[16]{0} %multiply.913), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p44.959 = f32[16]{0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.33 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.48 = f32[] multiply(f32[] %constant.33, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.38 = f32[16]{0} broadcast(f32[] %multiply.48), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.35 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.925 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.35), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.36 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.927 = f32[1]{0} select(pred[1]{0} %compare.925, f32[1]{0} %divide.700, f32[1]{0} %constant.36), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.192 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.174 = f32[1]{0} multiply(f32[1]{0} %select.927, f32[1]{0} %constant.192), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.665 = f32[] reshape(f32[1]{0} %multiply.174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.39 = f32[16]{0} broadcast(f32[] %reshape.665), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.931 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.166, f32[16]{0} %broadcast.39), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.949 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.950 = f32[16]{0} multiply(f32[16]{0} %multiply.931, f32[16]{0} %broadcast.949), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.958 = f32[16]{0} add(f32[16]{0} %broadcast.38, f32[16]{0} %multiply.950), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.37 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.51 = f32[] multiply(f32[] %constant.37, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.42 = f32[16]{0} broadcast(f32[] %multiply.51), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.939 = f32[16]{0} multiply(f32[16]{0} %multiply.931, f32[16]{0} %multiply.931), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.940 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.941 = f32[16]{0} multiply(f32[16]{0} %multiply.939, f32[16]{0} %broadcast.940), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.942 = f32[16]{0} add(f32[16]{0} %broadcast.42, f32[16]{0} %multiply.941), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.943 = f32[16]{0} sqrt(f32[16]{0} %add.942), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.944 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.945 = f32[16]{0} add(f32[16]{0} %sqrt.943, f32[16]{0} %broadcast.944), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.960 = f32[16]{0} divide(f32[16]{0} %add.958, f32[16]{0} %add.945), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.915 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.961 = f32[16]{0} broadcast(f32[] %constant.915), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.962 = f32[16]{0} multiply(f32[16]{0} %divide.960, f32[16]{0} %broadcast.961), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.963 = f32[16]{0} add(f32[16]{0} %p44.959, f32[16]{0} %multiply.962), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p45.1014 = f32[8,16]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.38 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.52 = f32[] multiply(f32[] %constant.38, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.45 = f32[8,16]{1,0} broadcast(f32[] %multiply.52), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.40 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.979 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.40), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.41 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.981 = f32[1]{0} select(pred[1]{0} %compare.979, f32[1]{0} %divide.700, f32[1]{0} %constant.41), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.193 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.175 = f32[1]{0} multiply(f32[1]{0} %select.981, f32[1]{0} %constant.193), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.668 = f32[] reshape(f32[1]{0} %multiply.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.47 = f32[8,16]{1,0} broadcast(f32[] %reshape.668), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.986 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.206, f32[8,16]{1,0} %broadcast.47), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1004 = f32[8,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1005 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.986, f32[8,16]{1,0} %broadcast.1004), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1013 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.45, f32[8,16]{1,0} %multiply.1005), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.42 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.55 = f32[] multiply(f32[] %constant.42, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.50 = f32[8,16]{1,0} broadcast(f32[] %multiply.55), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.994 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.986, f32[8,16]{1,0} %multiply.986), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.995 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.996 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.994, f32[8,16]{1,0} %broadcast.995), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.997 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.50, f32[8,16]{1,0} %multiply.996), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.998 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.997), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.999 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1000 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.998, f32[8,16]{1,0} %broadcast.999), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1015 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1013, f32[8,16]{1,0} %add.1000), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.969 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1016 = f32[8,16]{1,0} broadcast(f32[] %constant.969), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1017 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1015, f32[8,16]{1,0} %broadcast.1016), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1018 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p45.1014, f32[8,16]{1,0} %multiply.1017), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.964 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.968 = f32[8,16]{1,0} broadcast(f32[] %constant.964), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1019 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1018, f32[8,16]{1,0} %broadcast.968), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1020 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1018, f32[8,16]{1,0} %multiply.1019), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p46.1065 = f32[8]{0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.43 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.56 = f32[] multiply(f32[] %constant.43, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.53 = f32[8]{0} broadcast(f32[] %multiply.56), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.45 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1031 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.45), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.46 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1033 = f32[1]{0} select(pred[1]{0} %compare.1031, f32[1]{0} %divide.700, f32[1]{0} %constant.46), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.194 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.176 = f32[1]{0} multiply(f32[1]{0} %select.1033, f32[1]{0} %constant.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.671 = f32[] reshape(f32[1]{0} %multiply.176), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.54 = f32[8]{0} broadcast(f32[] %reshape.671), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1037 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.162, f32[8]{0} %broadcast.54), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1055 = f32[8]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1056 = f32[8]{0} multiply(f32[8]{0} %multiply.1037, f32[8]{0} %broadcast.1055), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1064 = f32[8]{0} add(f32[8]{0} %broadcast.53, f32[8]{0} %multiply.1056), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.47 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.59 = f32[] multiply(f32[] %constant.47, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.57 = f32[8]{0} broadcast(f32[] %multiply.59), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1045 = f32[8]{0} multiply(f32[8]{0} %multiply.1037, f32[8]{0} %multiply.1037), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1046 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1047 = f32[8]{0} multiply(f32[8]{0} %multiply.1045, f32[8]{0} %broadcast.1046), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1048 = f32[8]{0} add(f32[8]{0} %broadcast.57, f32[8]{0} %multiply.1047), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1049 = f32[8]{0} sqrt(f32[8]{0} %add.1048), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1050 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1051 = f32[8]{0} add(f32[8]{0} %sqrt.1049, f32[8]{0} %broadcast.1050), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1066 = f32[8]{0} divide(f32[8]{0} %add.1064, f32[8]{0} %add.1051), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1021 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1067 = f32[8]{0} broadcast(f32[] %constant.1021), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1068 = f32[8]{0} multiply(f32[8]{0} %divide.1066, f32[8]{0} %broadcast.1067), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1069 = f32[8]{0} add(f32[8]{0} %p46.1065, f32[8]{0} %multiply.1068), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p47.1120 = f32[8,16]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.48 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.60 = f32[] multiply(f32[] %constant.48, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.60 = f32[8,16]{1,0} broadcast(f32[] %multiply.60), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.50 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1085 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.50), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.51 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1087 = f32[1]{0} select(pred[1]{0} %compare.1085, f32[1]{0} %divide.700, f32[1]{0} %constant.51), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.196 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.178 = f32[1]{0} multiply(f32[1]{0} %select.1087, f32[1]{0} %constant.196), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.674 = f32[] reshape(f32[1]{0} %multiply.178), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.62 = f32[8,16]{1,0} broadcast(f32[] %reshape.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1092 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.202, f32[8,16]{1,0} %broadcast.62), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1110 = f32[8,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1111 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1092, f32[8,16]{1,0} %broadcast.1110), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1119 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.60, f32[8,16]{1,0} %multiply.1111), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.52 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.63 = f32[] multiply(f32[] %constant.52, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.65 = f32[8,16]{1,0} broadcast(f32[] %multiply.63), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1100 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1092, f32[8,16]{1,0} %multiply.1092), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1101 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1102 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1100, f32[8,16]{1,0} %broadcast.1101), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1103 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.65, f32[8,16]{1,0} %multiply.1102), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1104 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.1103), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1105 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1106 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.1104, f32[8,16]{1,0} %broadcast.1105), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1121 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1119, f32[8,16]{1,0} %add.1106), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1075 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1122 = f32[8,16]{1,0} broadcast(f32[] %constant.1075), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1123 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1121, f32[8,16]{1,0} %broadcast.1122), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1124 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p47.1120, f32[8,16]{1,0} %multiply.1123), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1070 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1074 = f32[8,16]{1,0} broadcast(f32[] %constant.1070), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1125 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1124, f32[8,16]{1,0} %broadcast.1074), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1126 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1124, f32[8,16]{1,0} %multiply.1125), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p48.1171 = f32[8]{0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.53 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.64 = f32[] multiply(f32[] %constant.53, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.68 = f32[8]{0} broadcast(f32[] %multiply.64), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.55 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1137 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.55), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.56 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1139 = f32[1]{0} select(pred[1]{0} %compare.1137, f32[1]{0} %divide.700, f32[1]{0} %constant.56), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.197 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.179 = f32[1]{0} multiply(f32[1]{0} %select.1139, f32[1]{0} %constant.197), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.677 = f32[] reshape(f32[1]{0} %multiply.179), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.69 = f32[8]{0} broadcast(f32[] %reshape.677), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1143 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.158, f32[8]{0} %broadcast.69), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1161 = f32[8]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1162 = f32[8]{0} multiply(f32[8]{0} %multiply.1143, f32[8]{0} %broadcast.1161), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1170 = f32[8]{0} add(f32[8]{0} %broadcast.68, f32[8]{0} %multiply.1162), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.57 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.67 = f32[] multiply(f32[] %constant.57, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.72 = f32[8]{0} broadcast(f32[] %multiply.67), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1151 = f32[8]{0} multiply(f32[8]{0} %multiply.1143, f32[8]{0} %multiply.1143), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1152 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1153 = f32[8]{0} multiply(f32[8]{0} %multiply.1151, f32[8]{0} %broadcast.1152), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1154 = f32[8]{0} add(f32[8]{0} %broadcast.72, f32[8]{0} %multiply.1153), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1155 = f32[8]{0} sqrt(f32[8]{0} %add.1154), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1156 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1157 = f32[8]{0} add(f32[8]{0} %sqrt.1155, f32[8]{0} %broadcast.1156), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1172 = f32[8]{0} divide(f32[8]{0} %add.1170, f32[8]{0} %add.1157), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1127 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1173 = f32[8]{0} broadcast(f32[] %constant.1127), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1174 = f32[8]{0} multiply(f32[8]{0} %divide.1172, f32[8]{0} %broadcast.1173), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1175 = f32[8]{0} add(f32[8]{0} %p48.1171, f32[8]{0} %multiply.1174), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p49.1226 = f32[8,16]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.58 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.68 = f32[] multiply(f32[] %constant.58, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.75 = f32[8,16]{1,0} broadcast(f32[] %multiply.68), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.60 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1191 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.60), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.61 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1193 = f32[1]{0} select(pred[1]{0} %compare.1191, f32[1]{0} %divide.700, f32[1]{0} %constant.61), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.198 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.180 = f32[1]{0} multiply(f32[1]{0} %select.1193, f32[1]{0} %constant.198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.680 = f32[] reshape(f32[1]{0} %multiply.180), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.77 = f32[8,16]{1,0} broadcast(f32[] %reshape.680), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1198 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.198, f32[8,16]{1,0} %broadcast.77), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1216 = f32[8,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1217 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1198, f32[8,16]{1,0} %broadcast.1216), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1225 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.75, f32[8,16]{1,0} %multiply.1217), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.62 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.71 = f32[] multiply(f32[] %constant.62, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.80 = f32[8,16]{1,0} broadcast(f32[] %multiply.71), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1206 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1198, f32[8,16]{1,0} %multiply.1198), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1207 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1208 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1206, f32[8,16]{1,0} %broadcast.1207), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1209 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.80, f32[8,16]{1,0} %multiply.1208), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1210 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.1209), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1211 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1212 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.1210, f32[8,16]{1,0} %broadcast.1211), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1227 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1225, f32[8,16]{1,0} %add.1212), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1181 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1228 = f32[8,16]{1,0} broadcast(f32[] %constant.1181), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1229 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1227, f32[8,16]{1,0} %broadcast.1228), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1230 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p49.1226, f32[8,16]{1,0} %multiply.1229), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1176 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1180 = f32[8,16]{1,0} broadcast(f32[] %constant.1176), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1231 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1230, f32[8,16]{1,0} %broadcast.1180), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1232 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1230, f32[8,16]{1,0} %multiply.1231), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p50.1277 = f32[8]{0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.63 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.72 = f32[] multiply(f32[] %constant.63, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.83 = f32[8]{0} broadcast(f32[] %multiply.72), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.65 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1243 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.65), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.66 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1245 = f32[1]{0} select(pred[1]{0} %compare.1243, f32[1]{0} %divide.700, f32[1]{0} %constant.66), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.200 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.182 = f32[1]{0} multiply(f32[1]{0} %select.1245, f32[1]{0} %constant.200), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.683 = f32[] reshape(f32[1]{0} %multiply.182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.84 = f32[8]{0} broadcast(f32[] %reshape.683), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1249 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.154, f32[8]{0} %broadcast.84), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1267 = f32[8]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1268 = f32[8]{0} multiply(f32[8]{0} %multiply.1249, f32[8]{0} %broadcast.1267), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1276 = f32[8]{0} add(f32[8]{0} %broadcast.83, f32[8]{0} %multiply.1268), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.67 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.75 = f32[] multiply(f32[] %constant.67, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.87 = f32[8]{0} broadcast(f32[] %multiply.75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1257 = f32[8]{0} multiply(f32[8]{0} %multiply.1249, f32[8]{0} %multiply.1249), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1258 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1259 = f32[8]{0} multiply(f32[8]{0} %multiply.1257, f32[8]{0} %broadcast.1258), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1260 = f32[8]{0} add(f32[8]{0} %broadcast.87, f32[8]{0} %multiply.1259), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1261 = f32[8]{0} sqrt(f32[8]{0} %add.1260), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1262 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1263 = f32[8]{0} add(f32[8]{0} %sqrt.1261, f32[8]{0} %broadcast.1262), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1278 = f32[8]{0} divide(f32[8]{0} %add.1276, f32[8]{0} %add.1263), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1233 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1279 = f32[8]{0} broadcast(f32[] %constant.1233), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1280 = f32[8]{0} multiply(f32[8]{0} %divide.1278, f32[8]{0} %broadcast.1279), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1281 = f32[8]{0} add(f32[8]{0} %p50.1277, f32[8]{0} %multiply.1280), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p51.1332 = f32[16,8]{1,0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.68 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.76 = f32[] multiply(f32[] %constant.68, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.90 = f32[16,8]{1,0} broadcast(f32[] %multiply.76), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.70 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1297 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.70), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.71 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1299 = f32[1]{0} select(pred[1]{0} %compare.1297, f32[1]{0} %divide.700, f32[1]{0} %constant.71), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.201 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.183 = f32[1]{0} multiply(f32[1]{0} %select.1299, f32[1]{0} %constant.201), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.686 = f32[] reshape(f32[1]{0} %multiply.183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.92 = f32[16,8]{1,0} broadcast(f32[] %reshape.686), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1304 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %get-tuple-element.194, f32[16,8]{1,0} %broadcast.92), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1322 = f32[16,8]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1323 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1304, f32[16,8]{1,0} %broadcast.1322), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1331 = f32[16,8]{1,0} add(f32[16,8]{1,0} %broadcast.90, f32[16,8]{1,0} %multiply.1323), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.72 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.79 = f32[] multiply(f32[] %constant.72, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.95 = f32[16,8]{1,0} broadcast(f32[] %multiply.79), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1312 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1304, f32[16,8]{1,0} %multiply.1304), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1313 = f32[16,8]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1314 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1312, f32[16,8]{1,0} %broadcast.1313), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1315 = f32[16,8]{1,0} add(f32[16,8]{1,0} %broadcast.95, f32[16,8]{1,0} %multiply.1314), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1316 = f32[16,8]{1,0} sqrt(f32[16,8]{1,0} %add.1315), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1317 = f32[16,8]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1318 = f32[16,8]{1,0} add(f32[16,8]{1,0} %sqrt.1316, f32[16,8]{1,0} %broadcast.1317), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1333 = f32[16,8]{1,0} divide(f32[16,8]{1,0} %add.1331, f32[16,8]{1,0} %add.1318), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1287 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1334 = f32[16,8]{1,0} broadcast(f32[] %constant.1287), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1335 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %divide.1333, f32[16,8]{1,0} %broadcast.1334), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1336 = f32[16,8]{1,0} add(f32[16,8]{1,0} %p51.1332, f32[16,8]{1,0} %multiply.1335), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1282 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1286 = f32[16,8]{1,0} broadcast(f32[] %constant.1282), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1337 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %add.1336, f32[16,8]{1,0} %broadcast.1286), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1338 = f32[16,8]{1,0} add(f32[16,8]{1,0} %add.1336, f32[16,8]{1,0} %multiply.1337), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p52.1383 = f32[16]{0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=800}
  %constant.73 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.80 = f32[] multiply(f32[] %constant.73, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.98 = f32[16]{0} broadcast(f32[] %multiply.80), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.75 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1349 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.75), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.76 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1351 = f32[1]{0} select(pred[1]{0} %compare.1349, f32[1]{0} %divide.700, f32[1]{0} %constant.76), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.202 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.184 = f32[1]{0} multiply(f32[1]{0} %select.1351, f32[1]{0} %constant.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.689 = f32[] reshape(f32[1]{0} %multiply.184), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.99 = f32[16]{0} broadcast(f32[] %reshape.689), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1355 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.150, f32[16]{0} %broadcast.99), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1373 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1374 = f32[16]{0} multiply(f32[16]{0} %multiply.1355, f32[16]{0} %broadcast.1373), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1382 = f32[16]{0} add(f32[16]{0} %broadcast.98, f32[16]{0} %multiply.1374), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.77 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.83 = f32[] multiply(f32[] %constant.77, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.102 = f32[16]{0} broadcast(f32[] %multiply.83), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1363 = f32[16]{0} multiply(f32[16]{0} %multiply.1355, f32[16]{0} %multiply.1355), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1364 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1365 = f32[16]{0} multiply(f32[16]{0} %multiply.1363, f32[16]{0} %broadcast.1364), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1366 = f32[16]{0} add(f32[16]{0} %broadcast.102, f32[16]{0} %multiply.1365), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1367 = f32[16]{0} sqrt(f32[16]{0} %add.1366), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1368 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1369 = f32[16]{0} add(f32[16]{0} %sqrt.1367, f32[16]{0} %broadcast.1368), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1384 = f32[16]{0} divide(f32[16]{0} %add.1382, f32[16]{0} %add.1369), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1339 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1385 = f32[16]{0} broadcast(f32[] %constant.1339), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1386 = f32[16]{0} multiply(f32[16]{0} %divide.1384, f32[16]{0} %broadcast.1385), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1387 = f32[16]{0} add(f32[16]{0} %p52.1383, f32[16]{0} %multiply.1386), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p53.1432 = f32[16]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.78 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.84 = f32[] multiply(f32[] %constant.78, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.106 = f32[16]{0} broadcast(f32[] %multiply.84), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.80 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1398 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.80), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.81 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1400 = f32[1]{0} select(pred[1]{0} %compare.1398, f32[1]{0} %divide.700, f32[1]{0} %constant.81), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.204 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.186 = f32[1]{0} multiply(f32[1]{0} %select.1400, f32[1]{0} %constant.204), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.692 = f32[] reshape(f32[1]{0} %multiply.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.107 = f32[16]{0} broadcast(f32[] %reshape.692), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1404 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.146, f32[16]{0} %broadcast.107), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1422 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1423 = f32[16]{0} multiply(f32[16]{0} %multiply.1404, f32[16]{0} %broadcast.1422), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1431 = f32[16]{0} add(f32[16]{0} %broadcast.106, f32[16]{0} %multiply.1423), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.82 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.87 = f32[] multiply(f32[] %constant.82, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.111 = f32[16]{0} broadcast(f32[] %multiply.87), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1412 = f32[16]{0} multiply(f32[16]{0} %multiply.1404, f32[16]{0} %multiply.1404), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1413 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1414 = f32[16]{0} multiply(f32[16]{0} %multiply.1412, f32[16]{0} %broadcast.1413), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1415 = f32[16]{0} add(f32[16]{0} %broadcast.111, f32[16]{0} %multiply.1414), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1416 = f32[16]{0} sqrt(f32[16]{0} %add.1415), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1417 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1418 = f32[16]{0} add(f32[16]{0} %sqrt.1416, f32[16]{0} %broadcast.1417), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1433 = f32[16]{0} divide(f32[16]{0} %add.1431, f32[16]{0} %add.1418), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1388 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1434 = f32[16]{0} broadcast(f32[] %constant.1388), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1435 = f32[16]{0} multiply(f32[16]{0} %divide.1433, f32[16]{0} %broadcast.1434), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1436 = f32[16]{0} add(f32[16]{0} %p53.1432, f32[16]{0} %multiply.1435), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p54.1481 = f32[16]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.83 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.88 = f32[] multiply(f32[] %constant.83, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.115 = f32[16]{0} broadcast(f32[] %multiply.88), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.85 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1447 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.85), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.86 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1449 = f32[1]{0} select(pred[1]{0} %compare.1447, f32[1]{0} %divide.700, f32[1]{0} %constant.86), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.205 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.187 = f32[1]{0} multiply(f32[1]{0} %select.1449, f32[1]{0} %constant.205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.695 = f32[] reshape(f32[1]{0} %multiply.187), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.117 = f32[16]{0} broadcast(f32[] %reshape.695), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1453 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.142, f32[16]{0} %broadcast.117), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1471 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1472 = f32[16]{0} multiply(f32[16]{0} %multiply.1453, f32[16]{0} %broadcast.1471), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1480 = f32[16]{0} add(f32[16]{0} %broadcast.115, f32[16]{0} %multiply.1472), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.87 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.91 = f32[] multiply(f32[] %constant.87, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.121 = f32[16]{0} broadcast(f32[] %multiply.91), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1461 = f32[16]{0} multiply(f32[16]{0} %multiply.1453, f32[16]{0} %multiply.1453), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1462 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1463 = f32[16]{0} multiply(f32[16]{0} %multiply.1461, f32[16]{0} %broadcast.1462), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1464 = f32[16]{0} add(f32[16]{0} %broadcast.121, f32[16]{0} %multiply.1463), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1465 = f32[16]{0} sqrt(f32[16]{0} %add.1464), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1466 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1467 = f32[16]{0} add(f32[16]{0} %sqrt.1465, f32[16]{0} %broadcast.1466), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1482 = f32[16]{0} divide(f32[16]{0} %add.1480, f32[16]{0} %add.1467), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1437 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1483 = f32[16]{0} broadcast(f32[] %constant.1437), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1484 = f32[16]{0} multiply(f32[16]{0} %divide.1482, f32[16]{0} %broadcast.1483), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1485 = f32[16]{0} add(f32[16]{0} %p54.1481, f32[16]{0} %multiply.1484), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p55.1536 = f32[4096,16]{1,0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.88 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.92 = f32[] multiply(f32[] %constant.88, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.125 = f32[4096,16]{1,0} broadcast(f32[] %multiply.92), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.90 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1501 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.90), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.91 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1503 = f32[1]{0} select(pred[1]{0} %compare.1501, f32[1]{0} %divide.700, f32[1]{0} %constant.91), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.206 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.188 = f32[1]{0} multiply(f32[1]{0} %select.1503, f32[1]{0} %constant.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.698 = f32[] reshape(f32[1]{0} %multiply.188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.127 = f32[4096,16]{1,0} broadcast(f32[] %reshape.698), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1508 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %get-tuple-element.190, f32[4096,16]{1,0} %broadcast.127), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1526 = f32[4096,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1527 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1508, f32[4096,16]{1,0} %broadcast.1526), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1535 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.125, f32[4096,16]{1,0} %multiply.1527), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.92 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.95 = f32[] multiply(f32[] %constant.92, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.131 = f32[4096,16]{1,0} broadcast(f32[] %multiply.95), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1516 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1508, f32[4096,16]{1,0} %multiply.1508), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1517 = f32[4096,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1518 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1516, f32[4096,16]{1,0} %broadcast.1517), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1519 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.131, f32[4096,16]{1,0} %multiply.1518), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1520 = f32[4096,16]{1,0} sqrt(f32[4096,16]{1,0} %add.1519), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1521 = f32[4096,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1522 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %sqrt.1520, f32[4096,16]{1,0} %broadcast.1521), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1537 = f32[4096,16]{1,0} divide(f32[4096,16]{1,0} %add.1535, f32[4096,16]{1,0} %add.1522), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1491 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1538 = f32[4096,16]{1,0} broadcast(f32[] %constant.1491), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1539 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %divide.1537, f32[4096,16]{1,0} %broadcast.1538), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1540 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %p55.1536, f32[4096,16]{1,0} %multiply.1539), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1486 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1490 = f32[4096,16]{1,0} broadcast(f32[] %constant.1486), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1541 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %add.1540, f32[4096,16]{1,0} %broadcast.1490), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1542 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %add.1540, f32[4096,16]{1,0} %multiply.1541), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p56.1587 = f32[4096]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.93 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.96 = f32[] multiply(f32[] %constant.93, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.135 = f32[4096]{0} broadcast(f32[] %multiply.96), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.95 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1553 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.95), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.96 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1555 = f32[1]{0} select(pred[1]{0} %compare.1553, f32[1]{0} %divide.700, f32[1]{0} %constant.96), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.208 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.190 = f32[1]{0} multiply(f32[1]{0} %select.1555, f32[1]{0} %constant.208), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.701 = f32[] reshape(f32[1]{0} %multiply.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.137 = f32[4096]{0} broadcast(f32[] %reshape.701), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1559 = f32[4096]{0} multiply(f32[4096]{0} %get-tuple-element.138, f32[4096]{0} %broadcast.137), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1577 = f32[4096]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1578 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1559, f32[4096]{0} %broadcast.1577), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1586 = f32[4096]{0} add(f32[4096]{0} %broadcast.135, f32[4096]{0} %multiply.1578), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.97 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.99 = f32[] multiply(f32[] %constant.97, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.141 = f32[4096]{0} broadcast(f32[] %multiply.99), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1567 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1559, f32[4096]{0} %multiply.1559), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1568 = f32[4096]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1569 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1567, f32[4096]{0} %broadcast.1568), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1570 = f32[4096]{0} add(f32[4096]{0} %broadcast.141, f32[4096]{0} %multiply.1569), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1571 = f32[4096]{0} sqrt(f32[4096]{0} %add.1570), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1572 = f32[4096]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1573 = f32[4096]{0} add(f32[4096]{0} %sqrt.1571, f32[4096]{0} %broadcast.1572), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1588 = f32[4096]{0} divide(f32[4096]{0} %add.1586, f32[4096]{0} %add.1573), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1543 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1589 = f32[4096]{0} broadcast(f32[] %constant.1543), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1590 = f32[4096]{0} multiply(f32[4096]{0} %divide.1588, f32[4096]{0} %broadcast.1589), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1591 = f32[4096]{0} add(f32[4096]{0} %p56.1587, f32[4096]{0} %multiply.1590), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p57.1642 = f32[16,4096]{1,0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.98 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.100 = f32[] multiply(f32[] %constant.98, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.145 = f32[16,4096]{1,0} broadcast(f32[] %multiply.100), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.100 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1607 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.100), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.101 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1609 = f32[1]{0} select(pred[1]{0} %compare.1607, f32[1]{0} %divide.700, f32[1]{0} %constant.101), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.209 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.191 = f32[1]{0} multiply(f32[1]{0} %select.1609, f32[1]{0} %constant.209), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.704 = f32[] reshape(f32[1]{0} %multiply.191), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.147 = f32[16,4096]{1,0} broadcast(f32[] %reshape.704), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1614 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %get-tuple-element.186, f32[16,4096]{1,0} %broadcast.147), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1632 = f32[16,4096]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1633 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1614, f32[16,4096]{1,0} %broadcast.1632), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1641 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.145, f32[16,4096]{1,0} %multiply.1633), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.102 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.103 = f32[] multiply(f32[] %constant.102, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.151 = f32[16,4096]{1,0} broadcast(f32[] %multiply.103), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1622 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1614, f32[16,4096]{1,0} %multiply.1614), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1623 = f32[16,4096]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1624 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1622, f32[16,4096]{1,0} %broadcast.1623), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1625 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.151, f32[16,4096]{1,0} %multiply.1624), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1626 = f32[16,4096]{1,0} sqrt(f32[16,4096]{1,0} %add.1625), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1627 = f32[16,4096]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1628 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %sqrt.1626, f32[16,4096]{1,0} %broadcast.1627), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1643 = f32[16,4096]{1,0} divide(f32[16,4096]{1,0} %add.1641, f32[16,4096]{1,0} %add.1628), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1597 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1644 = f32[16,4096]{1,0} broadcast(f32[] %constant.1597), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1645 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %divide.1643, f32[16,4096]{1,0} %broadcast.1644), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1646 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %p57.1642, f32[16,4096]{1,0} %multiply.1645), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1592 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1596 = f32[16,4096]{1,0} broadcast(f32[] %constant.1592), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1647 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %add.1646, f32[16,4096]{1,0} %broadcast.1596), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1648 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1646, f32[16,4096]{1,0} %multiply.1647), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p58.1693 = f32[16]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.104 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.104 = f32[] multiply(f32[] %constant.104, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.155 = f32[16]{0} broadcast(f32[] %multiply.104), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.106 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1659 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.106), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.108 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1661 = f32[1]{0} select(pred[1]{0} %compare.1659, f32[1]{0} %divide.700, f32[1]{0} %constant.108), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.210 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.192 = f32[1]{0} multiply(f32[1]{0} %select.1661, f32[1]{0} %constant.210), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.707 = f32[] reshape(f32[1]{0} %multiply.192), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.157 = f32[16]{0} broadcast(f32[] %reshape.707), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1665 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.134, f32[16]{0} %broadcast.157), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1683 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1684 = f32[16]{0} multiply(f32[16]{0} %multiply.1665, f32[16]{0} %broadcast.1683), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1692 = f32[16]{0} add(f32[16]{0} %broadcast.155, f32[16]{0} %multiply.1684), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.109 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.108 = f32[] multiply(f32[] %constant.109, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.161 = f32[16]{0} broadcast(f32[] %multiply.108), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1673 = f32[16]{0} multiply(f32[16]{0} %multiply.1665, f32[16]{0} %multiply.1665), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1674 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1675 = f32[16]{0} multiply(f32[16]{0} %multiply.1673, f32[16]{0} %broadcast.1674), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1676 = f32[16]{0} add(f32[16]{0} %broadcast.161, f32[16]{0} %multiply.1675), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1677 = f32[16]{0} sqrt(f32[16]{0} %add.1676), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1678 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1679 = f32[16]{0} add(f32[16]{0} %sqrt.1677, f32[16]{0} %broadcast.1678), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1694 = f32[16]{0} divide(f32[16]{0} %add.1692, f32[16]{0} %add.1679), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1649 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1695 = f32[16]{0} broadcast(f32[] %constant.1649), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1696 = f32[16]{0} multiply(f32[16]{0} %divide.1694, f32[16]{0} %broadcast.1695), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1697 = f32[16]{0} add(f32[16]{0} %p58.1693, f32[16]{0} %multiply.1696), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p59.1742 = f32[16]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.110 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.110 = f32[] multiply(f32[] %constant.110, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.165 = f32[16]{0} broadcast(f32[] %multiply.110), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.113 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1708 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.113), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.114 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1710 = f32[1]{0} select(pred[1]{0} %compare.1708, f32[1]{0} %divide.700, f32[1]{0} %constant.114), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.212 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.194 = f32[1]{0} multiply(f32[1]{0} %select.1710, f32[1]{0} %constant.212), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.710 = f32[] reshape(f32[1]{0} %multiply.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.166 = f32[16]{0} broadcast(f32[] %reshape.710), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1714 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.130, f32[16]{0} %broadcast.166), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1732 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1733 = f32[16]{0} multiply(f32[16]{0} %multiply.1714, f32[16]{0} %broadcast.1732), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1741 = f32[16]{0} add(f32[16]{0} %broadcast.165, f32[16]{0} %multiply.1733), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.116 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.114 = f32[] multiply(f32[] %constant.116, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.170 = f32[16]{0} broadcast(f32[] %multiply.114), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1722 = f32[16]{0} multiply(f32[16]{0} %multiply.1714, f32[16]{0} %multiply.1714), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1723 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1724 = f32[16]{0} multiply(f32[16]{0} %multiply.1722, f32[16]{0} %broadcast.1723), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1725 = f32[16]{0} add(f32[16]{0} %broadcast.170, f32[16]{0} %multiply.1724), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1726 = f32[16]{0} sqrt(f32[16]{0} %add.1725), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1727 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1728 = f32[16]{0} add(f32[16]{0} %sqrt.1726, f32[16]{0} %broadcast.1727), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1743 = f32[16]{0} divide(f32[16]{0} %add.1741, f32[16]{0} %add.1728), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1698 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1744 = f32[16]{0} broadcast(f32[] %constant.1698), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1745 = f32[16]{0} multiply(f32[16]{0} %divide.1743, f32[16]{0} %broadcast.1744), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1746 = f32[16]{0} add(f32[16]{0} %p59.1742, f32[16]{0} %multiply.1745), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p60.1791 = f32[16]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.117 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.115 = f32[] multiply(f32[] %constant.117, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.174 = f32[16]{0} broadcast(f32[] %multiply.115), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.120 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1757 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.120), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.121 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1759 = f32[1]{0} select(pred[1]{0} %compare.1757, f32[1]{0} %divide.700, f32[1]{0} %constant.121), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.213 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.195 = f32[1]{0} multiply(f32[1]{0} %select.1759, f32[1]{0} %constant.213), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.714 = f32[] reshape(f32[1]{0} %multiply.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.175 = f32[16]{0} broadcast(f32[] %reshape.714), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1763 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.126, f32[16]{0} %broadcast.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1781 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1782 = f32[16]{0} multiply(f32[16]{0} %multiply.1763, f32[16]{0} %broadcast.1781), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1790 = f32[16]{0} add(f32[16]{0} %broadcast.174, f32[16]{0} %multiply.1782), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.122 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.119 = f32[] multiply(f32[] %constant.122, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.179 = f32[16]{0} broadcast(f32[] %multiply.119), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1771 = f32[16]{0} multiply(f32[16]{0} %multiply.1763, f32[16]{0} %multiply.1763), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1772 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1773 = f32[16]{0} multiply(f32[16]{0} %multiply.1771, f32[16]{0} %broadcast.1772), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1774 = f32[16]{0} add(f32[16]{0} %broadcast.179, f32[16]{0} %multiply.1773), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1775 = f32[16]{0} sqrt(f32[16]{0} %add.1774), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1776 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1777 = f32[16]{0} add(f32[16]{0} %sqrt.1775, f32[16]{0} %broadcast.1776), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1792 = f32[16]{0} divide(f32[16]{0} %add.1790, f32[16]{0} %add.1777), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1747 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1793 = f32[16]{0} broadcast(f32[] %constant.1747), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1794 = f32[16]{0} multiply(f32[16]{0} %divide.1792, f32[16]{0} %broadcast.1793), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1795 = f32[16]{0} add(f32[16]{0} %p60.1791, f32[16]{0} %multiply.1794), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p61.1846 = f32[16,16]{1,0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.124 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.120 = f32[] multiply(f32[] %constant.124, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.183 = f32[16,16]{1,0} broadcast(f32[] %multiply.120), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.126 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1811 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.126), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.128 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1813 = f32[1]{0} select(pred[1]{0} %compare.1811, f32[1]{0} %divide.700, f32[1]{0} %constant.128), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.214 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.196 = f32[1]{0} multiply(f32[1]{0} %select.1813, f32[1]{0} %constant.214), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.718 = f32[] reshape(f32[1]{0} %multiply.196), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.186 = f32[16,16]{1,0} broadcast(f32[] %reshape.718), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1818 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.182, f32[16,16]{1,0} %broadcast.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1836 = f32[16,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1837 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1818, f32[16,16]{1,0} %broadcast.1836), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1845 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.183, f32[16,16]{1,0} %multiply.1837), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.129 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.124 = f32[] multiply(f32[] %constant.129, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.190 = f32[16,16]{1,0} broadcast(f32[] %multiply.124), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1826 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1818, f32[16,16]{1,0} %multiply.1818), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1827 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1828 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1826, f32[16,16]{1,0} %broadcast.1827), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1829 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.190, f32[16,16]{1,0} %multiply.1828), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1830 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1829), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1831 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1832 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1830, f32[16,16]{1,0} %broadcast.1831), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1847 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1845, f32[16,16]{1,0} %add.1832), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1801 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1848 = f32[16,16]{1,0} broadcast(f32[] %constant.1801), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1849 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1847, f32[16,16]{1,0} %broadcast.1848), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1850 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p61.1846, f32[16,16]{1,0} %multiply.1849), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1796 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1800 = f32[16,16]{1,0} broadcast(f32[] %constant.1796), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1851 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1850, f32[16,16]{1,0} %broadcast.1800), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1852 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1850, f32[16,16]{1,0} %multiply.1851), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p62.1897 = f32[16]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.130 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.126 = f32[] multiply(f32[] %constant.130, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.194 = f32[16]{0} broadcast(f32[] %multiply.126), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.133 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1863 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.133), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.134 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1865 = f32[1]{0} select(pred[1]{0} %compare.1863, f32[1]{0} %divide.700, f32[1]{0} %constant.134), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.216 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.198 = f32[1]{0} multiply(f32[1]{0} %select.1865, f32[1]{0} %constant.216), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.722 = f32[] reshape(f32[1]{0} %multiply.198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.195 = f32[16]{0} broadcast(f32[] %reshape.722), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1869 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.122, f32[16]{0} %broadcast.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1887 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1888 = f32[16]{0} multiply(f32[16]{0} %multiply.1869, f32[16]{0} %broadcast.1887), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1896 = f32[16]{0} add(f32[16]{0} %broadcast.194, f32[16]{0} %multiply.1888), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.136 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.130 = f32[] multiply(f32[] %constant.136, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.199 = f32[16]{0} broadcast(f32[] %multiply.130), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1877 = f32[16]{0} multiply(f32[16]{0} %multiply.1869, f32[16]{0} %multiply.1869), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1878 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1879 = f32[16]{0} multiply(f32[16]{0} %multiply.1877, f32[16]{0} %broadcast.1878), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1880 = f32[16]{0} add(f32[16]{0} %broadcast.199, f32[16]{0} %multiply.1879), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1881 = f32[16]{0} sqrt(f32[16]{0} %add.1880), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1882 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1883 = f32[16]{0} add(f32[16]{0} %sqrt.1881, f32[16]{0} %broadcast.1882), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1898 = f32[16]{0} divide(f32[16]{0} %add.1896, f32[16]{0} %add.1883), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1853 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1899 = f32[16]{0} broadcast(f32[] %constant.1853), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1900 = f32[16]{0} multiply(f32[16]{0} %divide.1898, f32[16]{0} %broadcast.1899), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1901 = f32[16]{0} add(f32[16]{0} %p62.1897, f32[16]{0} %multiply.1900), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p63.1952 = f32[16,16]{1,0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.137 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.131 = f32[] multiply(f32[] %constant.137, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.203 = f32[16,16]{1,0} broadcast(f32[] %multiply.131), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.140 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1917 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.140), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.141 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1919 = f32[1]{0} select(pred[1]{0} %compare.1917, f32[1]{0} %divide.700, f32[1]{0} %constant.141), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.217 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.199 = f32[1]{0} multiply(f32[1]{0} %select.1919, f32[1]{0} %constant.217), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.725 = f32[] reshape(f32[1]{0} %multiply.199), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.206 = f32[16,16]{1,0} broadcast(f32[] %reshape.725), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1924 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.178, f32[16,16]{1,0} %broadcast.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1942 = f32[16,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1943 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1924, f32[16,16]{1,0} %broadcast.1942), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.1951 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.203, f32[16,16]{1,0} %multiply.1943), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.142 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.135 = f32[] multiply(f32[] %constant.142, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.210 = f32[16,16]{1,0} broadcast(f32[] %multiply.135), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1932 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1924, f32[16,16]{1,0} %multiply.1924), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1933 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1934 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1932, f32[16,16]{1,0} %broadcast.1933), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1935 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.210, f32[16,16]{1,0} %multiply.1934), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1936 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1935), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1937 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1938 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1936, f32[16,16]{1,0} %broadcast.1937), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.1953 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1951, f32[16,16]{1,0} %add.1938), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1907 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.1954 = f32[16,16]{1,0} broadcast(f32[] %constant.1907), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.1955 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1953, f32[16,16]{1,0} %broadcast.1954), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.1956 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p63.1952, f32[16,16]{1,0} %multiply.1955), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1902 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.1906 = f32[16,16]{1,0} broadcast(f32[] %constant.1902), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.1957 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1956, f32[16,16]{1,0} %broadcast.1906), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.1958 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1956, f32[16,16]{1,0} %multiply.1957), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p64.2003 = f32[16]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.144 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.136 = f32[] multiply(f32[] %constant.144, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.214 = f32[16]{0} broadcast(f32[] %multiply.136), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.146 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.1969 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.146), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.148 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.1971 = f32[1]{0} select(pred[1]{0} %compare.1969, f32[1]{0} %divide.700, f32[1]{0} %constant.148), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.218 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.200 = f32[1]{0} multiply(f32[1]{0} %select.1971, f32[1]{0} %constant.218), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.728 = f32[] reshape(f32[1]{0} %multiply.200), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.215 = f32[16]{0} broadcast(f32[] %reshape.728), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.1975 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.114, f32[16]{0} %broadcast.215), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.1993 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.1994 = f32[16]{0} multiply(f32[16]{0} %multiply.1975, f32[16]{0} %broadcast.1993), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2002 = f32[16]{0} add(f32[16]{0} %broadcast.214, f32[16]{0} %multiply.1994), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.149 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.140 = f32[] multiply(f32[] %constant.149, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.219 = f32[16]{0} broadcast(f32[] %multiply.140), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.1983 = f32[16]{0} multiply(f32[16]{0} %multiply.1975, f32[16]{0} %multiply.1975), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.1984 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.1985 = f32[16]{0} multiply(f32[16]{0} %multiply.1983, f32[16]{0} %broadcast.1984), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.1986 = f32[16]{0} add(f32[16]{0} %broadcast.219, f32[16]{0} %multiply.1985), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.1987 = f32[16]{0} sqrt(f32[16]{0} %add.1986), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.1988 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.1989 = f32[16]{0} add(f32[16]{0} %sqrt.1987, f32[16]{0} %broadcast.1988), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2004 = f32[16]{0} divide(f32[16]{0} %add.2002, f32[16]{0} %add.1989), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.1959 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2005 = f32[16]{0} broadcast(f32[] %constant.1959), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2006 = f32[16]{0} multiply(f32[16]{0} %divide.2004, f32[16]{0} %broadcast.2005), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2007 = f32[16]{0} add(f32[16]{0} %p64.2003, f32[16]{0} %multiply.2006), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p65.2052 = f32[16]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.150 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.142 = f32[] multiply(f32[] %constant.150, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.223 = f32[16]{0} broadcast(f32[] %multiply.142), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.153 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.2018 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.153), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.154 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.2020 = f32[1]{0} select(pred[1]{0} %compare.2018, f32[1]{0} %divide.700, f32[1]{0} %constant.154), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.220 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.202 = f32[1]{0} multiply(f32[1]{0} %select.2020, f32[1]{0} %constant.220), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.732 = f32[] reshape(f32[1]{0} %multiply.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.224 = f32[16]{0} broadcast(f32[] %reshape.732), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.2024 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.110, f32[16]{0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.2042 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.2043 = f32[16]{0} multiply(f32[16]{0} %multiply.2024, f32[16]{0} %broadcast.2042), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2051 = f32[16]{0} add(f32[16]{0} %broadcast.223, f32[16]{0} %multiply.2043), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.156 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.146 = f32[] multiply(f32[] %constant.156, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.229 = f32[16]{0} broadcast(f32[] %multiply.146), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.2032 = f32[16]{0} multiply(f32[16]{0} %multiply.2024, f32[16]{0} %multiply.2024), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.2033 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.2034 = f32[16]{0} multiply(f32[16]{0} %multiply.2032, f32[16]{0} %broadcast.2033), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.2035 = f32[16]{0} add(f32[16]{0} %broadcast.229, f32[16]{0} %multiply.2034), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.2036 = f32[16]{0} sqrt(f32[16]{0} %add.2035), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.2037 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.2038 = f32[16]{0} add(f32[16]{0} %sqrt.2036, f32[16]{0} %broadcast.2037), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2053 = f32[16]{0} divide(f32[16]{0} %add.2051, f32[16]{0} %add.2038), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2008 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2054 = f32[16]{0} broadcast(f32[] %constant.2008), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2055 = f32[16]{0} multiply(f32[16]{0} %divide.2053, f32[16]{0} %broadcast.2054), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2056 = f32[16]{0} add(f32[16]{0} %p65.2052, f32[16]{0} %multiply.2055), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p66.2101 = f32[16]{0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.157 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.147 = f32[] multiply(f32[] %constant.157, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.232 = f32[16]{0} broadcast(f32[] %multiply.147), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.160 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.2067 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.160), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.161 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.2069 = f32[1]{0} select(pred[1]{0} %compare.2067, f32[1]{0} %divide.700, f32[1]{0} %constant.161), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.221 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.203 = f32[1]{0} multiply(f32[1]{0} %select.2069, f32[1]{0} %constant.221), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.736 = f32[] reshape(f32[1]{0} %multiply.203), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.233 = f32[16]{0} broadcast(f32[] %reshape.736), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.2073 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.106, f32[16]{0} %broadcast.233), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.2091 = f32[16]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.2092 = f32[16]{0} multiply(f32[16]{0} %multiply.2073, f32[16]{0} %broadcast.2091), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2100 = f32[16]{0} add(f32[16]{0} %broadcast.232, f32[16]{0} %multiply.2092), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.162 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.151 = f32[] multiply(f32[] %constant.162, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.236 = f32[16]{0} broadcast(f32[] %multiply.151), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.2081 = f32[16]{0} multiply(f32[16]{0} %multiply.2073, f32[16]{0} %multiply.2073), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.2082 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.2083 = f32[16]{0} multiply(f32[16]{0} %multiply.2081, f32[16]{0} %broadcast.2082), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.2084 = f32[16]{0} add(f32[16]{0} %broadcast.236, f32[16]{0} %multiply.2083), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.2085 = f32[16]{0} sqrt(f32[16]{0} %add.2084), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.2086 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.2087 = f32[16]{0} add(f32[16]{0} %sqrt.2085, f32[16]{0} %broadcast.2086), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2102 = f32[16]{0} divide(f32[16]{0} %add.2100, f32[16]{0} %add.2087), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2057 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2103 = f32[16]{0} broadcast(f32[] %constant.2057), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2104 = f32[16]{0} multiply(f32[16]{0} %divide.2102, f32[16]{0} %broadcast.2103), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2105 = f32[16]{0} add(f32[16]{0} %p66.2101, f32[16]{0} %multiply.2104), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p67.2150 = f32[30522]{0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.164 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.152 = f32[] multiply(f32[] %constant.164, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.239 = f32[30522]{0} broadcast(f32[] %multiply.152), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.166 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.2116 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.166), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.168 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.2118 = f32[1]{0} select(pred[1]{0} %compare.2116, f32[1]{0} %divide.700, f32[1]{0} %constant.168), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.222 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.204 = f32[1]{0} multiply(f32[1]{0} %select.2118, f32[1]{0} %constant.222), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.741 = f32[] reshape(f32[1]{0} %multiply.204), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.240 = f32[30522]{0} broadcast(f32[] %reshape.741), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.2122 = f32[30522]{0} multiply(f32[30522]{0} %get-tuple-element.118, f32[30522]{0} %broadcast.240), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.2140 = f32[30522]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.2141 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2122, f32[30522]{0} %broadcast.2140), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2149 = f32[30522]{0} add(f32[30522]{0} %broadcast.239, f32[30522]{0} %multiply.2141), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.169 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.156 = f32[] multiply(f32[] %constant.169, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.243 = f32[30522]{0} broadcast(f32[] %multiply.156), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.2130 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2122, f32[30522]{0} %multiply.2122), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.2131 = f32[30522]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.2132 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2130, f32[30522]{0} %broadcast.2131), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.2133 = f32[30522]{0} add(f32[30522]{0} %broadcast.243, f32[30522]{0} %multiply.2132), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.2134 = f32[30522]{0} sqrt(f32[30522]{0} %add.2133), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.2135 = f32[30522]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.2136 = f32[30522]{0} add(f32[30522]{0} %sqrt.2134, f32[30522]{0} %broadcast.2135), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2151 = f32[30522]{0} divide(f32[30522]{0} %add.2149, f32[30522]{0} %add.2136), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2106 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2152 = f32[30522]{0} broadcast(f32[] %constant.2106), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2153 = f32[30522]{0} multiply(f32[30522]{0} %divide.2151, f32[30522]{0} %broadcast.2152), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2154 = f32[30522]{0} add(f32[30522]{0} %p67.2150, f32[30522]{0} %multiply.2153), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %p68.2205 = f32[2,16]{1,0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.170 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.158 = f32[] multiply(f32[] %constant.170, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.246 = f32[2,16]{1,0} broadcast(f32[] %multiply.158), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.173 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.2170 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.173), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.174 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.2172 = f32[1]{0} select(pred[1]{0} %compare.2170, f32[1]{0} %divide.700, f32[1]{0} %constant.174), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.224 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.206 = f32[1]{0} multiply(f32[1]{0} %select.2172, f32[1]{0} %constant.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.744 = f32[] reshape(f32[1]{0} %multiply.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.248 = f32[2,16]{1,0} broadcast(f32[] %reshape.744), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.2177 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.174, f32[2,16]{1,0} %broadcast.248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.2195 = f32[2,16]{1,0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.2196 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2177, f32[2,16]{1,0} %broadcast.2195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2204 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.246, f32[2,16]{1,0} %multiply.2196), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.176 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.162 = f32[] multiply(f32[] %constant.176, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.251 = f32[2,16]{1,0} broadcast(f32[] %multiply.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.2185 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2177, f32[2,16]{1,0} %multiply.2177), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.2186 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.2187 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2185, f32[2,16]{1,0} %broadcast.2186), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.2188 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.251, f32[2,16]{1,0} %multiply.2187), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.2189 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.2188), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.2190 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.2191 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.2189, f32[2,16]{1,0} %broadcast.2190), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2206 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.2204, f32[2,16]{1,0} %add.2191), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2160 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2207 = f32[2,16]{1,0} broadcast(f32[] %constant.2160), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2208 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.2206, f32[2,16]{1,0} %broadcast.2207), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2209 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p68.2205, f32[2,16]{1,0} %multiply.2208), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2155 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %broadcast.2159 = f32[2,16]{1,0} broadcast(f32[] %constant.2155), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %multiply.2210 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.2209, f32[2,16]{1,0} %broadcast.2159), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %add.2211 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.2209, f32[2,16]{1,0} %multiply.2210), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=466}
  %p69.2256 = f32[2]{0} parameter(69), frontend_attributes={neff_input_names="input69"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.177 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %multiply.163 = f32[] multiply(f32[] %constant.177, f32[] %p39.736), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %broadcast.254 = f32[2]{0} broadcast(f32[] %multiply.163), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=434}
  %constant.180 = f32[1]{0} constant({1}), metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %compare.2222 = pred[1]{0} compare(f32[1]{0} %divide.700, f32[1]{0} %constant.180), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=235}
  %constant.181 = f32[1]{0} constant({1}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %select.2224 = f32[1]{0} select(pred[1]{0} %compare.2222, f32[1]{0} %divide.700, f32[1]{0} %constant.181), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=234}
  %constant.225 = f32[1]{0} constant({0.5}), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.207 = f32[1]{0} multiply(f32[1]{0} %select.2224, f32[1]{0} %constant.225), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %reshape.747 = f32[] reshape(f32[1]{0} %multiply.207), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.255 = f32[2]{0} broadcast(f32[] %reshape.747), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %multiply.2228 = f32[2]{0} multiply(f32[2]{0} %get-tuple-element.102, f32[2]{0} %broadcast.255), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=233}
  %broadcast.2246 = f32[2]{0} broadcast(f32[] %p38.730), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %multiply.2247 = f32[2]{0} multiply(f32[2]{0} %multiply.2228, f32[2]{0} %broadcast.2246), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %add.2255 = f32[2]{0} add(f32[2]{0} %broadcast.254, f32[2]{0} %multiply.2247), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=445}
  %constant.182 = f32[] constant(0), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.167 = f32[] multiply(f32[] %constant.182, f32[] %p37.715), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.258 = f32[2]{0} broadcast(f32[] %multiply.167), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=436}
  %multiply.2236 = f32[2]{0} multiply(f32[2]{0} %multiply.2228, f32[2]{0} %multiply.2228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %broadcast.2237 = f32[2]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %multiply.2238 = f32[2]{0} multiply(f32[2]{0} %multiply.2236, f32[2]{0} %broadcast.2237), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %add.2239 = f32[2]{0} add(f32[2]{0} %broadcast.258, f32[2]{0} %multiply.2238), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=446}
  %sqrt.2240 = f32[2]{0} sqrt(f32[2]{0} %add.2239), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %broadcast.2241 = f32[2]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %add.2242 = f32[2]{0} add(f32[2]{0} %sqrt.2240, f32[2]{0} %broadcast.2241), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=447}
  %divide.2257 = f32[2]{0} divide(f32[2]{0} %add.2255, f32[2]{0} %add.2242), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.2212 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %broadcast.2258 = f32[2]{0} broadcast(f32[] %constant.2212), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %multiply.2259 = f32[2]{0} multiply(f32[2]{0} %divide.2257, f32[2]{0} %broadcast.2258), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %add.2260 = f32[2]{0} add(f32[2]{0} %p69.2256, f32[2]{0} %multiply.2259), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/optimization.py" source_line=455}
  %constant.184 = f32[1]{0} constant({0}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=518}
  %get-tuple-element.33 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.32), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %constant.185 = f32[1]{0} constant({0}), metadata={op_type="aten__expand" op_name="aten__expand" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=525}
  ROOT %tuple.2267 = (f32[30522,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, /*index=5*/f32[8,16]{1,0}, f32[8]{0}, f32[8,16]{1,0}, f32[8]{0}, f32[8,16]{1,0}, /*index=10*/f32[8]{0}, f32[16,8]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=15*/f32[4096,16]{1,0}, f32[4096]{0}, f32[16,4096]{1,0}, f32[16]{0}, f32[16]{0}, /*index=20*/f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, /*index=25*/f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[2,16]{1,0}, f32[2]{0}, /*index=30*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[30522,16]{1,0}, f32[30522,16]{1,0}, /*index=35*/f32[512,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[2,16]{1,0}, f32[8,16]{1,0}, /*index=40*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, /*index=45*/f32[16,8]{1,0}, f32[16,8]{1,0}, f32[4096,16]{1,0}, f32[4096,16]{1,0}, f32[16,4096]{1,0}, /*index=50*/f32[16,4096]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=55*/f32[2,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=60*/f32[16]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, /*index=65*/f32[8]{0}, f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=70*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, f32[4096]{0}, /*index=75*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=80*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[30522]{0}, /*index=85*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=90*/f32[16]{0}, f32[2]{0}, f32[2]{0}, f32[1]{0}) tuple(f32[30522,16]{1,0} %add.751, f32[512,16]{1,0} %add.808, f32[2,16]{1,0} %add.865, f32[16]{0} %add.914, f32[16]{0} %add.963, /*index=5*/f32[8,16]{1,0} %add.1020, f32[8]{0} %add.1069, f32[8,16]{1,0} %add.1126, f32[8]{0} %add.1175, f32[8,16]{1,0} %add.1232, /*index=10*/f32[8]{0} %add.1281, f32[16,8]{1,0} %add.1338, f32[16]{0} %add.1387, f32[16]{0} %add.1436, f32[16]{0} %add.1485, /*index=15*/f32[4096,16]{1,0} %add.1542, f32[4096]{0} %add.1591, f32[16,4096]{1,0} %add.1648, f32[16]{0} %add.1697, f32[16]{0} %add.1746, /*index=20*/f32[16]{0} %add.1795, f32[16,16]{1,0} %add.1852, f32[16]{0} %add.1901, f32[16,16]{1,0} %add.1958, f32[16]{0} %add.2007, /*index=25*/f32[16]{0} %add.2056, f32[16]{0} %add.2105, f32[30522]{0} %add.2154, f32[2,16]{1,0} %add.2211, f32[2]{0} %add.2260, /*index=30*/f32[1]{0} %constant.184, f32[1]{0} %p3.22, f32[1]{0} %get-tuple-element.33, f32[30522,16]{1,0} %add.744, f32[30522,16]{1,0} %add.726, /*index=35*/f32[512,16]{1,0} %add.801, f32[512,16]{1,0} %add.785, f32[2,16]{1,0} %add.858, f32[2,16]{1,0} %add.842, f32[8,16]{1,0} %add.1013, /*index=40*/f32[8,16]{1,0} %add.997, f32[8,16]{1,0} %add.1119, f32[8,16]{1,0} %add.1103, f32[8,16]{1,0} %add.1225, f32[8,16]{1,0} %add.1209, /*index=45*/f32[16,8]{1,0} %add.1331, f32[16,8]{1,0} %add.1315, f32[4096,16]{1,0} %add.1535, f32[4096,16]{1,0} %add.1519, f32[16,4096]{1,0} %add.1641, /*index=50*/f32[16,4096]{1,0} %add.1625, f32[16,16]{1,0} %add.1845, f32[16,16]{1,0} %add.1829, f32[16,16]{1,0} %add.1951, f32[16,16]{1,0} %add.1935, /*index=55*/f32[2,16]{1,0} %add.2204, f32[2,16]{1,0} %add.2188, f32[16]{0} %add.909, f32[16]{0} %add.893, f32[16]{0} %add.958, /*index=60*/f32[16]{0} %add.942, f32[8]{0} %add.1064, f32[8]{0} %add.1048, f32[8]{0} %add.1170, f32[8]{0} %add.1154, /*index=65*/f32[8]{0} %add.1276, f32[8]{0} %add.1260, f32[16]{0} %add.1382, f32[16]{0} %add.1366, f32[16]{0} %add.1431, /*index=70*/f32[16]{0} %add.1415, f32[16]{0} %add.1480, f32[16]{0} %add.1464, f32[4096]{0} %add.1586, f32[4096]{0} %add.1570, /*index=75*/f32[16]{0} %add.1692, f32[16]{0} %add.1676, f32[16]{0} %add.1741, f32[16]{0} %add.1725, f32[16]{0} %add.1790, /*index=80*/f32[16]{0} %add.1774, f32[16]{0} %add.1896, f32[16]{0} %add.1880, f32[30522]{0} %add.2149, f32[30522]{0} %add.2133, /*index=85*/f32[16]{0} %add.2002, f32[16]{0} %add.1986, f32[16]{0} %add.2051, f32[16]{0} %add.2035, f32[16]{0} %add.2100, /*index=90*/f32[16]{0} %add.2084, f32[2]{0} %add.2255, f32[2]{0} %add.2239, f32[1]{0} %constant.185), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93"}
}
`

export default text;
