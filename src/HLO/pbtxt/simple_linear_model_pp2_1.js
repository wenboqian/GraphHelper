const text = `
    HloModule SyncTensorsGraph.189, input_output_alias={ {0}: (6, {}, must-alias), {1}: (5, {}, must-alias) }

%AddComputation.84 (x.85: f32[], y.86: f32[]) -> f32[] {
  %x.85 = f32[] parameter(0)
  %y.86 = f32[] parameter(1)
  ROOT %add.87 = f32[] add(f32[] %x.85, f32[] %y.86)
}

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.189 (p0.1: f32[], p1.3: f32[], p2.5: f32[], p3.6: f32[], p4.7: f32[], p5.8: f32[3], p6.16: f32[3,4], p7.25: f32[1,4], p8.92: f32[], p9.109: f32[], p10.115: f32[], p11.129: f32[], p12.130: f32[]) -> (f32[3,4], f32[3], f32[3], f32[3,4], f32[3,4], /*index=5*/f32[3,4], f32[3], f32[3]) {
  %p6.16 = f32[3,4]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %p12.130 = f32[] parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.131 = f32[3,4]{1,0} broadcast(f32[] %p12.130), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.132 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %p6.16, f32[3,4]{1,0} %broadcast.131), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p11.129 = f32[] parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.133 = f32[3,4]{1,0} broadcast(f32[] %p11.129), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.135 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %multiply.132, f32[3,4]{1,0} %broadcast.133), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.136 = f32[3,4]{1,0} subtract(f32[3,4]{1,0} %p6.16, f32[3,4]{1,0} %multiply.135), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.1 = f32[] constant(0)
  %p10.115 = f32[] parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.0 = f32[] multiply(f32[] %constant.1, f32[] %p10.115), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2 = f32[3,4]{1,0} broadcast(f32[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=121}
  %constant.36 = f32[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=65}
  %broadcast.40 = f32[1,3]{1,0} broadcast(f32[] %constant.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=65}
  %p7.25 = f32[1,4]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.7 = f32[4]{0} reshape(f32[1,4]{1,0} %p7.25)
  %broadcast.26 = f32[3,4]{1,0} broadcast(f32[4]{0} %reshape.7), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.4 = f32[3,4]{1,0} custom-call(f32[3,4]{1,0} %p6.16), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.10 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %broadcast.26, f32[3,4]{1,0} %custom-call.4)
  %constant = f32[] constant(0)
  %reduce = f32[3]{0} reduce(f32[3,4]{1,0} %multiply.10, f32[] %constant), dimensions={1}, to_apply=%scalar_add_computation, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p5.8 = f32[3]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.5 = f32[3]{0} custom-call(f32[3]{0} %p5.8), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.1 = f32[3]{0} add(f32[3]{0} %reduce, f32[3]{0} %custom-call.5), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.52 = f32[1,3]{1,0} reshape(f32[3]{0} %add.1), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p4.7 = f32[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=430}
  %all-gather.33 = (f32[2,3]{1,0}, f32[]) all-gather(f32[1,3]{1,0} %reshape.52, f32[] %p4.7), replica_groups={{0,1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.43 = f32[] get-tuple-element((f32[2,3]{1,0}, f32[]) %all-gather.33), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.44 = (f32[2,3]{1,0}, f32[]) all-gather(f32[1,3]{1,0} %broadcast.40, f32[] %get-tuple-element.43), replica_groups={{0,1}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.45 = f32[2,3]{1,0} get-tuple-element((f32[2,3]{1,0}, f32[]) %all-gather.44), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.48 = f32[1,3]{1,0} slice(f32[2,3]{1,0} %get-tuple-element.45), slice={[1:2], [0:3]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %reshape.70 = f32[3]{0} reshape(f32[1,3]{1,0} %slice.48), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.6 = f32[3]{0} custom-call(f32[3]{0} %reshape.70), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.15 = f32[3]{0} reshape(f32[1,3]{1,0} %slice.48)
  %broadcast.21 = f32[3,4]{0,1} broadcast(f32[3]{0} %reshape.15), dimensions={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %reshape.14 = f32[4]{0} reshape(f32[1,4]{1,0} %p7.25)
  %broadcast.22 = f32[3,4]{0,1} broadcast(f32[4]{0} %reshape.14), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.8 = f32[3,4]{0,1} multiply(f32[3,4]{0,1} %broadcast.21, f32[3,4]{0,1} %broadcast.22), metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.7 = f32[3,4]{1,0} custom-call(f32[3,4]{0,1} %multiply.8), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %get-tuple-element.83 = f32[] get-tuple-element((f32[2,3]{1,0}, f32[]) %all-gather.44), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-reduce.88 = (f32[3]{0}, f32[3,4]{1,0}, f32[]) all-reduce(f32[3]{0} %custom-call.6, f32[3,4]{1,0} %custom-call.7, f32[] %get-tuple-element.83), replica_groups={{0},{1}}, constrain_layout=true, to_apply=%AddComputation.84, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.90 = f32[3,4]{1,0} get-tuple-element((f32[3]{0}, f32[3,4]{1,0}, f32[]) %all-reduce.88), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p9.109 = f32[] parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.113 = f32[3,4]{1,0} broadcast(f32[] %p9.109), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.114 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %get-tuple-element.90, f32[3,4]{1,0} %broadcast.113), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.123 = f32[3,4]{1,0} add(f32[3,4]{1,0} %broadcast.2, f32[3,4]{1,0} %multiply.114), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.3 = f32[] constant(0)
  %p8.92 = f32[] parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1 = f32[] multiply(f32[] %constant.3, f32[] %p8.92), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.6 = f32[3,4]{1,0} broadcast(f32[] %multiply.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=125}
  %multiply.100 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %get-tuple-element.90, f32[3,4]{1,0} %get-tuple-element.90), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.101 = f32[3,4]{1,0} broadcast(f32[] %p3.6), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.102 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %multiply.100, f32[3,4]{1,0} %broadcast.101), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.103 = f32[3,4]{1,0} add(f32[3,4]{1,0} %broadcast.6, f32[3,4]{1,0} %multiply.102), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.104 = f32[3,4]{1,0} sqrt(f32[3,4]{1,0} %add.103), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.105 = f32[3,4]{1,0} broadcast(f32[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.106 = f32[3,4]{1,0} divide(f32[3,4]{1,0} %sqrt.104, f32[3,4]{1,0} %broadcast.105), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.107 = f32[3,4]{1,0} broadcast(f32[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.108 = f32[3,4]{1,0} add(f32[3,4]{1,0} %divide.106, f32[3,4]{1,0} %broadcast.107), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.137 = f32[3,4]{1,0} divide(f32[3,4]{1,0} %add.123, f32[3,4]{1,0} %add.108), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.138 = f32[3,4]{1,0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.139 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %divide.137, f32[3,4]{1,0} %broadcast.138), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.140 = f32[3,4]{1,0} add(f32[3,4]{1,0} %subtract.136, f32[3,4]{1,0} %multiply.139), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.178 = f32[3]{0} broadcast(f32[] %p12.130), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.179 = f32[3]{0} multiply(f32[3]{0} %p5.8, f32[3]{0} %broadcast.178), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.5 = f32[] constant(0)
  %broadcast.7 = f32[3]{0} broadcast(f32[] %constant.5), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.182 = f32[3]{0} multiply(f32[3]{0} %multiply.179, f32[3]{0} %broadcast.7), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.183 = f32[3]{0} subtract(f32[3]{0} %p5.8, f32[3]{0} %multiply.182), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.6 = f32[] constant(0)
  %multiply.5 = f32[] multiply(f32[] %constant.6, f32[] %p10.115), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.10 = f32[3]{0} broadcast(f32[] %multiply.5), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=121}
  %get-tuple-element.89 = f32[3]{0} get-tuple-element((f32[3]{0}, f32[3,4]{1,0}, f32[]) %all-reduce.88), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.162 = f32[3]{0} broadcast(f32[] %p9.109), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.163 = f32[3]{0} multiply(f32[3]{0} %get-tuple-element.89, f32[3]{0} %broadcast.162), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.171 = f32[3]{0} add(f32[3]{0} %broadcast.10, f32[3]{0} %multiply.163), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.7 = f32[] constant(0)
  %multiply.6 = f32[] multiply(f32[] %constant.7, f32[] %p8.92), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.13 = f32[3]{0} broadcast(f32[] %multiply.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=125}
  %multiply.150 = f32[3]{0} multiply(f32[3]{0} %get-tuple-element.89, f32[3]{0} %get-tuple-element.89), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.151 = f32[3]{0} broadcast(f32[] %p3.6), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.152 = f32[3]{0} multiply(f32[3]{0} %multiply.150, f32[3]{0} %broadcast.151), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.153 = f32[3]{0} add(f32[3]{0} %broadcast.13, f32[3]{0} %multiply.152), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.154 = f32[3]{0} sqrt(f32[3]{0} %add.153), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.155 = f32[3]{0} broadcast(f32[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.156 = f32[3]{0} divide(f32[3]{0} %sqrt.154, f32[3]{0} %broadcast.155), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.157 = f32[3]{0} broadcast(f32[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.158 = f32[3]{0} add(f32[3]{0} %divide.156, f32[3]{0} %broadcast.157), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.184 = f32[3]{0} divide(f32[3]{0} %add.171, f32[3]{0} %add.158), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.185 = f32[3]{0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.186 = f32[3]{0} multiply(f32[3]{0} %divide.184, f32[3]{0} %broadcast.185), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.187 = f32[3]{0} add(f32[3]{0} %subtract.183, f32[3]{0} %multiply.186), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.188 = (f32[3,4]{1,0}, f32[3]{0}, f32[3]{0}, f32[3,4]{1,0}, f32[3,4]{1,0}, /*index=5*/f32[3,4]{1,0}, f32[3]{0}, f32[3]{0}) tuple(f32[3,4]{1,0} %add.140, f32[3]{0} %add.187, f32[3]{0} %get-tuple-element.89, f32[3,4]{1,0} %get-tuple-element.90, f32[3,4]{1,0} %add.123, /*index=5*/f32[3,4]{1,0} %add.103, f32[3]{0} %add.171, f32[3]{0} %add.153), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7"}
}

`;

export default text;
