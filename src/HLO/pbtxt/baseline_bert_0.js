const text = `
ENTRY %SyncTensorsGraph.310 (p0.1: f32[], p1.3: f32[], p2.5: f32[], p3.6: f32[], p4.7: f32[1,3], p5.28: f32[4], p6.40: f32[], p7.57: f32[], p8.63: f32[], p9.77: f32[], p10.78: f32[], p11.79: f32[3,4], p12.134: f32[3], p13.262: f32[1], p14.306: f32[]) -> (f32[3,4], f32[3], f32[1,3], f32[1], f32[4], /*index=5*/f32[], f32[], f32[1], f32[1,3], f32[3], /*index=10*/f32[3,4], f32[3,4], f32[3,4], f32[3], f32[3], /*index=15*/f32[1,3], f32[1,3], f32[1], f32[1]) {

%MaxComputation.1150 (x.1151: bf16[], y.1152: bf16[]) -> bf16[] {
  %x.1151 = bf16[] parameter(0)
  %y.1152 = bf16[] parameter(1)
  ROOT %maximum.1153 = bf16[] maximum(bf16[] %x.1151, bf16[] %y.1152)
}

%AddComputation.1159 (x.1160: bf16[], y.1161: bf16[]) -> bf16[] {
  %x.1160 = bf16[] parameter(0)
  %y.1161 = bf16[] parameter(1)
  ROOT %add.1162 = bf16[] add(bf16[] %x.1160, bf16[] %y.1161)
}

%MaxComputation.1445 (x.1446: bf16[], y.1447: bf16[]) -> bf16[] {
  %x.1446 = bf16[] parameter(0)
  %y.1447 = bf16[] parameter(1)
  ROOT %maximum.1448 = bf16[] maximum(bf16[] %x.1446, bf16[] %y.1447)
}

%AddComputation.1454 (x.1455: bf16[], y.1456: bf16[]) -> bf16[] {
  %x.1455 = bf16[] parameter(0)
  %y.1456 = bf16[] parameter(1)
  ROOT %add.1457 = bf16[] add(bf16[] %x.1455, bf16[] %y.1456)
}

%MaxComputation.1740 (x.1741: bf16[], y.1742: bf16[]) -> bf16[] {
  %x.1741 = bf16[] parameter(0)
  %y.1742 = bf16[] parameter(1)
  ROOT %maximum.1743 = bf16[] maximum(bf16[] %x.1741, bf16[] %y.1742)
}

%AddComputation.1749 (x.1750: bf16[], y.1751: bf16[]) -> bf16[] {
  %x.1750 = bf16[] parameter(0)
  %y.1751 = bf16[] parameter(1)
  ROOT %add.1752 = bf16[] add(bf16[] %x.1750, bf16[] %y.1751)
}

%MaxComputation.2035 (x.2036: bf16[], y.2037: bf16[]) -> bf16[] {
  %x.2036 = bf16[] parameter(0)
  %y.2037 = bf16[] parameter(1)
  ROOT %maximum.2038 = bf16[] maximum(bf16[] %x.2036, bf16[] %y.2037)
}

%AddComputation.2044 (x.2045: bf16[], y.2046: bf16[]) -> bf16[] {
  %x.2045 = bf16[] parameter(0)
  %y.2046 = bf16[] parameter(1)
  ROOT %add.2047 = bf16[] add(bf16[] %x.2045, bf16[] %y.2046)
}

%MaxComputation.2330 (x.2331: bf16[], y.2332: bf16[]) -> bf16[] {
  %x.2331 = bf16[] parameter(0)
  %y.2332 = bf16[] parameter(1)
  ROOT %maximum.2333 = bf16[] maximum(bf16[] %x.2331, bf16[] %y.2332)
}

%AddComputation.2339 (x.2340: bf16[], y.2341: bf16[]) -> bf16[] {
  %x.2340 = bf16[] parameter(0)
  %y.2341 = bf16[] parameter(1)
  ROOT %add.2342 = bf16[] add(bf16[] %x.2340, bf16[] %y.2341)
}

%MaxComputation.2625 (x.2626: bf16[], y.2627: bf16[]) -> bf16[] {
  %x.2626 = bf16[] parameter(0)
  %y.2627 = bf16[] parameter(1)
  ROOT %maximum.2628 = bf16[] maximum(bf16[] %x.2626, bf16[] %y.2627)
}

%AddComputation.2634 (x.2635: bf16[], y.2636: bf16[]) -> bf16[] {
  %x.2635 = bf16[] parameter(0)
  %y.2636 = bf16[] parameter(1)
  ROOT %add.2637 = bf16[] add(bf16[] %x.2635, bf16[] %y.2636)
}

%MaxComputation.2920 (x.2921: bf16[], y.2922: bf16[]) -> bf16[] {
  %x.2921 = bf16[] parameter(0)
  %y.2922 = bf16[] parameter(1)
  ROOT %maximum.2923 = bf16[] maximum(bf16[] %x.2921, bf16[] %y.2922)
}

%AddComputation.2929 (x.2930: bf16[], y.2931: bf16[]) -> bf16[] {
  %x.2930 = bf16[] parameter(0)
  %y.2931 = bf16[] parameter(1)
  ROOT %add.2932 = bf16[] add(bf16[] %x.2930, bf16[] %y.2931)
}

%MaxComputation.3215 (x.3216: bf16[], y.3217: bf16[]) -> bf16[] {
  %x.3216 = bf16[] parameter(0)
  %y.3217 = bf16[] parameter(1)
  ROOT %maximum.3218 = bf16[] maximum(bf16[] %x.3216, bf16[] %y.3217)
}

%AddComputation.3224 (x.3225: bf16[], y.3226: bf16[]) -> bf16[] {
  %x.3225 = bf16[] parameter(0)
  %y.3226 = bf16[] parameter(1)
  ROOT %add.3227 = bf16[] add(bf16[] %x.3225, bf16[] %y.3226)
}

%MaxComputation.3510 (x.3511: bf16[], y.3512: bf16[]) -> bf16[] {
  %x.3511 = bf16[] parameter(0)
  %y.3512 = bf16[] parameter(1)
  ROOT %maximum.3513 = bf16[] maximum(bf16[] %x.3511, bf16[] %y.3512)
}

%AddComputation.3519 (x.3520: bf16[], y.3521: bf16[]) -> bf16[] {
  %x.3520 = bf16[] parameter(0)
  %y.3521 = bf16[] parameter(1)
  ROOT %add.3522 = bf16[] add(bf16[] %x.3520, bf16[] %y.3521)
}

%MaxComputation.3805 (x.3806: bf16[], y.3807: bf16[]) -> bf16[] {
  %x.3806 = bf16[] parameter(0)
  %y.3807 = bf16[] parameter(1)
  ROOT %maximum.3808 = bf16[] maximum(bf16[] %x.3806, bf16[] %y.3807)
}

%AddComputation.3814 (x.3815: bf16[], y.3816: bf16[]) -> bf16[] {
  %x.3815 = bf16[] parameter(0)
  %y.3816 = bf16[] parameter(1)
  ROOT %add.3817 = bf16[] add(bf16[] %x.3815, bf16[] %y.3816)
}

%MaxComputation.4100 (x.4101: bf16[], y.4102: bf16[]) -> bf16[] {
  %x.4101 = bf16[] parameter(0)
  %y.4102 = bf16[] parameter(1)
  ROOT %maximum.4103 = bf16[] maximum(bf16[] %x.4101, bf16[] %y.4102)
}

%AddComputation.4109 (x.4110: bf16[], y.4111: bf16[]) -> bf16[] {
  %x.4110 = bf16[] parameter(0)
  %y.4111 = bf16[] parameter(1)
  ROOT %add.4112 = bf16[] add(bf16[] %x.4110, bf16[] %y.4111)
}

%MaxComputation.4395 (x.4396: bf16[], y.4397: bf16[]) -> bf16[] {
  %x.4396 = bf16[] parameter(0)
  %y.4397 = bf16[] parameter(1)
  ROOT %maximum.4398 = bf16[] maximum(bf16[] %x.4396, bf16[] %y.4397)
}

%AddComputation.4404 (x.4405: bf16[], y.4406: bf16[]) -> bf16[] {
  %x.4405 = bf16[] parameter(0)
  %y.4406 = bf16[] parameter(1)
  ROOT %add.4407 = bf16[] add(bf16[] %x.4405, bf16[] %y.4406)
}

%SimpleCrossEntropyLossForwardMax.4555 (p0.4556: bf16[], p1.4557: bf16[]) -> bf16[] {
  %p0.4556 = bf16[] parameter(0)
  %p1.4557 = bf16[] parameter(1)
  ROOT %maximum.4558 = bf16[] maximum(bf16[] %p0.4556, bf16[] %p1.4557)
}

%SimpleCrossEntropyLossForwardAdd.4559 (p0.4560: bf16[], p1.4561: bf16[]) -> bf16[] {
  %p0.4560 = bf16[] parameter(0)
  %p1.4561 = bf16[] parameter(1)
  ROOT %add.4562 = bf16[] add(bf16[] %p0.4560, bf16[] %p1.4561)
}

%SimpleCrossEntropyLossForwardAdd.4563 (p0.4564: bf16[], p1.4565: bf16[]) -> bf16[] {
  %p0.4564 = bf16[] parameter(0)
  %p1.4565 = bf16[] parameter(1)
  ROOT %add.4566 = bf16[] add(bf16[] %p0.4564, bf16[] %p1.4565)
}

%SimpleCrossEntropyLossForwardAdd.4567 (p0.4568: bf16[], p1.4569: bf16[]) -> bf16[] {
  %p0.4568 = bf16[] parameter(0)
  %p1.4569 = bf16[] parameter(1)
  ROOT %add.4570 = bf16[] add(bf16[] %p0.4568, bf16[] %p1.4569)
}

%SimpleCrossEntropyLossForwardAdd.4571 (p0.4572: bf16[], p1.4573: bf16[]) -> bf16[] {
  %p0.4572 = bf16[] parameter(0)
  %p1.4573 = bf16[] parameter(1)
  ROOT %add.4574 = bf16[] add(bf16[] %p0.4572, bf16[] %p1.4573)
}

ENTRY %SyncTensorsGraph.4622 (p0.2: s64[8], p1.3: bf16[2], p2.4: bf16[2,768], p3.6: bf16[], p4.7: s64[], p5.193: bf16[768], p6.194: bf16[768,768], p7.197: bf16[768], p8.224: bf16[768], p9.251: bf16[768], p10.278: bf16[768], p11.305: bf16[768], p12.332: bf16[768], p13.359: bf16[768], p14.386: bf16[768], p15.413: bf16[768], p16.440: bf16[768], p17.467: bf16[768], p18.494: bf16[768], p19.521: bf16[768], p20.548: bf16[768], p21.575: bf16[768], p22.602: bf16[768], p23.629: bf16[768], p24.656: bf16[768], p25.683: bf16[768], p26.710: bf16[768], p27.737: bf16[768], p28.764: bf16[768], p29.791: bf16[768], p30.818: bf16[768], p31.878: bf16[768], p32.904: s64[1,512], p33.908: bf16[512,768], p34.925: s64[8,128], p35.927: bf16[2,768], p36.939: s64[8,128], p37.941: bf16[28996,768], p38.967: bf16[768], p39.1015: bf16[768], p40.1017: bf16[768,768], p41.1024: bf16[768], p42.1026: bf16[768,768], p43.1077: bf16[], p44.1078: s64[8,128], p45.1099: bf16[], p46.1105: bf16[768], p47.1107: bf16[768,768], p48.1126: bf16[768], p49.1128: bf16[768,768], p50.1192: bf16[768], p51.1239: bf16[768], p52.1241: bf16[768,3072], p53.1248: bf16[3072], p54.1250: bf16[3072,768], p55.1285: bf16[768], p56.1332: bf16[768], p57.1334: bf16[768,768], p58.1341: bf16[768], p59.1343: bf16[768,768], p60.1400: bf16[768], p61.1402: bf16[768,768], p62.1421: bf16[768], p63.1423: bf16[768,768], p64.1487: bf16[768], p65.1534: bf16[768], p66.1536: bf16[768,3072], p67.1543: bf16[3072], p68.1545: bf16[3072,768], p69.1580: bf16[768], p70.1627: bf16[768], p71.1629: bf16[768,768], p72.1636: bf16[768], p73.1638: bf16[768,768], p74.1695: bf16[768], p75.1697: bf16[768,768], p76.1716: bf16[768], p77.1718: bf16[768,768], p78.1782: bf16[768], p79.1829: bf16[768], p80.1831: bf16[768,3072], p81.1838: bf16[3072], p82.1840: bf16[3072,768], p83.1875: bf16[768], p84.1922: bf16[768], p85.1924: bf16[768,768], p86.1931: bf16[768], p87.1933: bf16[768,768], p88.1990: bf16[768], p89.1992: bf16[768,768], p90.2011: bf16[768], p91.2013: bf16[768,768], p92.2077: bf16[768], p93.2124: bf16[768], p94.2126: bf16[768,3072], p95.2133: bf16[3072], p96.2135: bf16[3072,768], p97.2170: bf16[768], p98.2217: bf16[768], p99.2219: bf16[768,768], p100.2226: bf16[768], p101.2228: bf16[768,768], p102.2285: bf16[768], p103.2287: bf16[768,768], p104.2306: bf16[768], p105.2308: bf16[768,768], p106.2372: bf16[768], p107.2419: bf16[768], p108.2421: bf16[768,3072], p109.2428: bf16[3072], p110.2430: bf16[3072,768], p111.2465: bf16[768], p112.2512: bf16[768], p113.2514: bf16[768,768], p114.2521: bf16[768], p115.2523: bf16[768,768], p116.2580: bf16[768], p117.2582: bf16[768,768], p118.2601: bf16[768], p119.2603: bf16[768,768], p120.2667: bf16[768], p121.2714: bf16[768], p122.2716: bf16[768,3072], p123.2723: bf16[3072], p124.2725: bf16[3072,768], p125.2760: bf16[768], p126.2807: bf16[768], p127.2809: bf16[768,768], p128.2816: bf16[768], p129.2818: bf16[768,768], p130.2875: bf16[768], p131.2877: bf16[768,768], p132.2896: bf16[768], p133.2898: bf16[768,768], p134.2962: bf16[768], p135.3009: bf16[768], p136.3011: bf16[768,3072], p137.3018: bf16[3072], p138.3020: bf16[3072,768], p139.3055: bf16[768], p140.3102: bf16[768], p141.3104: bf16[768,768], p142.3111: bf16[768], p143.3113: bf16[768,768], p144.3170: bf16[768], p145.3172: bf16[768,768], p146.3191: bf16[768], p147.3193: bf16[768,768], p148.3257: bf16[768], p149.3304: bf16[768], p150.3306: bf16[768,3072], p151.3313: bf16[3072], p152.3315: bf16[3072,768], p153.3350: bf16[768], p154.3397: bf16[768], p155.3399: bf16[768,768], p156.3406: bf16[768], p157.3408: bf16[768,768], p158.3465: bf16[768], p159.3467: bf16[768,768], p160.3486: bf16[768], p161.3488: bf16[768,768], p162.3552: bf16[768], p163.3599: bf16[768], p164.3601: bf16[768,3072], p165.3608: bf16[3072], p166.3610: bf16[3072,768], p167.3645: bf16[768], p168.3692: bf16[768], p169.3694: bf16[768,768], p170.3701: bf16[768], p171.3703: bf16[768,768], p172.3760: bf16[768], p173.3762: bf16[768,768], p174.3781: bf16[768], p175.3783: bf16[768,768], p176.3847: bf16[768], p177.3894: bf16[768], p178.3896: bf16[768,3072], p179.3903: bf16[3072], p180.3905: bf16[3072,768], p181.3940: bf16[768], p182.3987: bf16[768], p183.3989: bf16[768,768], p184.3996: bf16[768], p185.3998: bf16[768,768], p186.4055: bf16[768], p187.4057: bf16[768,768], p188.4076: bf16[768], p189.4078: bf16[768,768], p190.4142: bf16[768], p191.4189: bf16[768], p192.4191: bf16[768,3072], p193.4198: bf16[3072], p194.4200: bf16[3072,768], p195.4235: bf16[768], p196.4282: bf16[768], p197.4284: bf16[768,768], p198.4291: bf16[768], p199.4293: bf16[768,768], p200.4350: bf16[768], p201.4352: bf16[768,768], p202.4371: bf16[768], p203.4373: bf16[768,768], p204.4437: bf16[768], p205.4484: bf16[768], p206.4486: bf16[768,3072], p207.4493: bf16[3072], p208.4495: bf16[3072,768], p209.4530: bf16[768], p210.4619: bf16[]) -> (bf16[]) {
  %p210.4619 = bf16[] parameter(210), frontend_attributes={neff_input_names="input210"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/trainer.py" source_line=1914}
  %p0.2 = s64[8]{0} parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=1597}
  %constant.5 = s64[] constant(-100)
  %broadcast.8 = s64[8]{0} broadcast(s64[] %constant.5), dimensions={}
  %compare.1 = pred[8]{0} compare(s64[8]{0} %p0.2, s64[8]{0} %broadcast.8), direction=NE
  %p209.4530 = bf16[768]{0} parameter(209), frontend_attributes={neff_input_names="input209"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4536 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p209.4530), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p204.4437 = bf16[768]{0} parameter(204), frontend_attributes={neff_input_names="input204"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4443 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p204.4437), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p195.4235 = bf16[768]{0} parameter(195), frontend_attributes={neff_input_names="input195"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4241 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p195.4235), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p190.4142 = bf16[768]{0} parameter(190), frontend_attributes={neff_input_names="input190"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4148 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p190.4142), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p181.3940 = bf16[768]{0} parameter(181), frontend_attributes={neff_input_names="input181"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3946 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p181.3940), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p176.3847 = bf16[768]{0} parameter(176), frontend_attributes={neff_input_names="input176"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3853 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p176.3847), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p167.3645 = bf16[768]{0} parameter(167), frontend_attributes={neff_input_names="input167"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3651 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p167.3645), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p162.3552 = bf16[768]{0} parameter(162), frontend_attributes={neff_input_names="input162"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3558 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p162.3552), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p153.3350 = bf16[768]{0} parameter(153), frontend_attributes={neff_input_names="input153"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3356 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p153.3350), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p148.3257 = bf16[768]{0} parameter(148), frontend_attributes={neff_input_names="input148"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3263 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p148.3257), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p139.3055 = bf16[768]{0} parameter(139), frontend_attributes={neff_input_names="input139"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3061 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p139.3055), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p134.2962 = bf16[768]{0} parameter(134), frontend_attributes={neff_input_names="input134"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2968 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p134.2962), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p125.2760 = bf16[768]{0} parameter(125), frontend_attributes={neff_input_names="input125"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2766 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p125.2760), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p120.2667 = bf16[768]{0} parameter(120), frontend_attributes={neff_input_names="input120"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2673 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p120.2667), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p111.2465 = bf16[768]{0} parameter(111), frontend_attributes={neff_input_names="input111"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2471 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p111.2465), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p106.2372 = bf16[768]{0} parameter(106), frontend_attributes={neff_input_names="input106"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2378 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p106.2372), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p97.2170 = bf16[768]{0} parameter(97), frontend_attributes={neff_input_names="input97"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2176 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p97.2170), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p92.2077 = bf16[768]{0} parameter(92), frontend_attributes={neff_input_names="input92"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2083 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p92.2077), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p83.1875 = bf16[768]{0} parameter(83), frontend_attributes={neff_input_names="input83"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1881 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p83.1875), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p78.1782 = bf16[768]{0} parameter(78), frontend_attributes={neff_input_names="input78"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1788 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p78.1782), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p69.1580 = bf16[768]{0} parameter(69), frontend_attributes={neff_input_names="input69"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1586 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p69.1580), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p64.1487 = bf16[768]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1493 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p64.1487), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p55.1285 = bf16[768]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1291 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p55.1285), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p50.1192 = bf16[768]{0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1198 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p50.1192), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p38.967 = bf16[768]{0} parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.973 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p38.967), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p37.941 = bf16[28996,768]{1,0} parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.15 = bf16[28996,768]{1,0} custom-call(bf16[28996,768]{1,0} %p37.941), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %p36.939 = s64[8,128]{1,0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2233}
  %convert.5 = u32[8,128]{1,0} convert(s64[8,128]{1,0} %p36.939)
  %reshape.935 = u32[1024]{0} reshape(u32[8,128]{1,0} %convert.5), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2233}
  %gather.950 = bf16[1024,768]{1,0} gather(bf16[28996,768]{1,0} %custom-call.15, u32[1024]{0} %reshape.935), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,768}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2233}
  %p35.927 = bf16[2,768]{1,0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.16 = bf16[2,768]{1,0} custom-call(bf16[2,768]{1,0} %p35.927), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %p34.925 = s64[8,128]{1,0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %convert.4 = u32[8,128]{1,0} convert(s64[8,128]{1,0} %p34.925)
  %reshape.934 = u32[1024]{0} reshape(u32[8,128]{1,0} %convert.4), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %gather.936 = bf16[1024,768]{1,0} gather(bf16[2,768]{1,0} %custom-call.16, u32[1024]{0} %reshape.934), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,768}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %add.48 = bf16[1024,768]{1,0} add(bf16[1024,768]{1,0} %gather.950, bf16[1024,768]{1,0} %gather.936), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=233}
  %reshape.1220 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %add.48), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=233}
  %p33.908 = bf16[512,768]{1,0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.17 = bf16[512,768]{1,0} custom-call(bf16[512,768]{1,0} %p33.908), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %p32.904 = s64[1,512]{1,0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=216}
  %convert.3 = u32[1,512]{1,0} convert(s64[1,512]{1,0} %p32.904)
  %slice.0 = u32[1,128]{1,0} slice(u32[1,512]{1,0} %convert.3), slice={[0:1], [0:128]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %reshape.933 = u32[128]{0} reshape(u32[1,128]{1,0} %slice.0), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %gather.917 = bf16[128,768]{1,0} gather(bf16[512,768]{1,0} %custom-call.17, u32[128]{0} %reshape.933), offset_dims={1}, collapsed_slice_dims={0}, start_index_map={0}, index_vector_dim=1, slice_sizes={1,768}, metadata={op_type="aten__index_select" op_name="aten__index_select" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_neuronx/xla_impl/ops.py" source_line=1137}
  %broadcast.955 = bf16[8,128,768]{2,1,0} broadcast(bf16[128,768]{1,0} %gather.917), dimensions={1,2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=236}
  %add.956 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1220, bf16[8,128,768]{2,1,0} %broadcast.955), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=236}
  %reshape.957 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.956), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.894 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.898 = bf16[1024]{0} broadcast(bf16[] %constant.894), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.889 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.893 = bf16[1024]{0} broadcast(bf16[] %constant.889), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.958 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.957, bf16[1024]{0} %broadcast.898, bf16[1024]{0} %broadcast.893), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.959 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.958), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.966 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.959), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p31.878 = bf16[768]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.969 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p31.878), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.972 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.966, bf16[8,128,768]{2,1,0} %broadcast.969), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.974 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.973, bf16[8,128,768]{2,1,0} %multiply.972), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.8 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %p4.7 = s64[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.9 = s64[] multiply(s64[] %constant.8, s64[] %p4.7), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.10 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.11 = s64[] add(s64[] %multiply.9, s64[] %constant.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.850 = u64[] convert(s64[] %add.11), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.854 = u64[1]{0} reshape(u64[] %convert.850), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.160 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.856 = u64[2]{0} concatenate(u64[1]{0} %reshape.854, u64[1]{0} %constant.160), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.857 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.856), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.858 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.857), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.860 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.861 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.860), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.862 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.858, u32[8,128,768]{2,1,0} %broadcast.861), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.863 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.862), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.166 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.10 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.166), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.869 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.863, f32[8,128,768]{2,1,0} %broadcast.10), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.872 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.869), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %p3.6 = bf16[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.847 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.873 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.872, bf16[8,128,768]{2,1,0} %broadcast.847), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.6 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.1 = bf16[] divide(bf16[] %constant.6, bf16[] %p3.6)
  %broadcast.11 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.1), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.83 = bf16[] constant(0)
  %broadcast.107 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.83), dimensions={}
  %select.2 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.873, bf16[8,128,768]{2,1,0} %broadcast.11, bf16[8,128,768]{2,1,0} %broadcast.107), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.976 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.974, bf16[8,128,768]{2,1,0} %select.2), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1130 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %multiply.976), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p49.1128 = bf16[768,768]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1129 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p49.1128), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1131 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1130, bf16[768,768]{0,1} %transpose.1129), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1132 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1131), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p48.1126 = bf16[768]{0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1133 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p48.1126), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1134 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1132, bf16[8,128,768]{2,1,0} %broadcast.1133), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1137 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1134), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1138 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1137), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1140 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1138), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1109 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %multiply.976), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p47.1107 = bf16[768,768]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1108 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p47.1107), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1110 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1109, bf16[768,768]{0,1} %transpose.1108), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1111 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1110), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p46.1105 = bf16[768]{0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1112 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p46.1105), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1113 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1111, bf16[8,128,768]{2,1,0} %broadcast.1112), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1116 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1113), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1118 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1116), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1120 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.1118), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.1141 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.1140, bf16[96,64,128]{2,1,0} %reshape.1120), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %p45.1099 = bf16[] parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.440 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.39 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.1141, bf16[96,128,128]{2,1,0} %broadcast.440), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1226 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.39), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %constant.1090 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=909}
  %broadcast.442 = bf16[8,128]{1,0} broadcast(bf16[] %constant.1090), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=909}
  %p44.1078 = s64[8,128]{1,0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=846}
  %convert.1 = bf16[8,128]{1,0} convert(s64[8,128]{1,0} %p44.1078), metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=857}
  %subtract.2 = bf16[8,128]{1,0} subtract(bf16[8,128]{1,0} %broadcast.442, bf16[8,128]{1,0} %convert.1), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/_tensor.py" source_line=909}
  %p43.1077 = bf16[] parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=858}
  %broadcast.481 = bf16[8,128]{1,0} broadcast(bf16[] %p43.1077), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=858}
  %multiply.152 = bf16[8,128]{1,0} multiply(bf16[8,128]{1,0} %subtract.2, bf16[8,128]{1,0} %broadcast.481), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/modeling_utils.py" source_line=858}
  %broadcast.1147 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.1148 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1226, bf16[8,12,128,128]{3,2,1,0} %broadcast.1147), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.1149 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1154 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.1148, bf16[] %constant.1149), dimensions={3}, to_apply=%MaxComputation.1150, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1155 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1154), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.1156 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.1148, bf16[8,12,128,128]{3,2,1,0} %broadcast.1155), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.1157 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.1156), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.1158 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1163 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.1157, bf16[] %constant.1158), dimensions={3}, to_apply=%AddComputation.1159, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1164 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1163), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.1165 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.1157, bf16[8,12,128,128]{3,2,1,0} %broadcast.1164), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.12 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.13 = s64[] multiply(s64[] %constant.12, s64[] %add.11), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.14 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.15 = s64[] add(s64[] %multiply.13, s64[] %constant.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1045 = u64[] convert(s64[] %add.15), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1049 = u64[1]{0} reshape(u64[] %convert.1045), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.167 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1051 = u64[2]{0} concatenate(u64[1]{0} %reshape.1049, u64[1]{0} %constant.167), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1052 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1051), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1053 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.1052), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1055 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1056 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.1055), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1057 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.1053, u32[8,12,128,128]{3,2,1,0} %broadcast.1056), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1058 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.1057), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.172 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.15 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.172), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1064 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.1058, f32[8,12,128,128]{3,2,1,0} %broadcast.15), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1067 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.1064), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1042 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1068 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.1067, bf16[8,12,128,128]{3,2,1,0} %broadcast.1042), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.7 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.2 = bf16[] divide(bf16[] %constant.7, bf16[] %p3.6)
  %broadcast.16 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.2), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.85 = bf16[] constant(0)
  %broadcast.114 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.85), dimensions={}
  %select.3 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.1068, bf16[8,12,128,128]{3,2,1,0} %broadcast.16, bf16[8,12,128,128]{3,2,1,0} %broadcast.114), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1166 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.1165, bf16[8,12,128,128]{3,2,1,0} %select.3), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1168 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.1166), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1028 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %multiply.976), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p42.1026 = bf16[768,768]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1027 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p42.1026), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1029 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1028, bf16[768,768]{0,1} %transpose.1027), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1030 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1029), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p41.1024 = bf16[768]{0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1031 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p41.1024), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1032 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1030, bf16[8,128,768]{2,1,0} %broadcast.1031), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1035 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1032), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.1036 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1035), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1038 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1036), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.1169 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.1168, bf16[96,128,64]{2,1,0} %reshape.1038), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1170 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.1169), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1171 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.1170), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1173 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.1171), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p40.1017 = bf16[768,768]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1018 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p40.1017), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1174 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1173, bf16[768,768]{0,1} %transpose.1018), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1175 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1174), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p39.1015 = bf16[768]{0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1176 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p39.1015), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1177 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1175, bf16[8,128,768]{2,1,0} %broadcast.1176), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.16 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.17 = s64[] multiply(s64[] %constant.16, s64[] %add.15), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.18 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.19 = s64[] add(s64[] %multiply.17, s64[] %constant.18), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.983 = u64[] convert(s64[] %add.19), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.987 = u64[1]{0} reshape(u64[] %convert.983), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.173 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.989 = u64[2]{0} concatenate(u64[1]{0} %reshape.987, u64[1]{0} %constant.173), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.990 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.989), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.991 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.990), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.993 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.994 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.993), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.995 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.991, u32[8,128,768]{2,1,0} %broadcast.994), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.996 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.995), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.178 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.17 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.178), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1002 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.996, f32[8,128,768]{2,1,0} %broadcast.17), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1005 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1002), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.980 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1006 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1005, bf16[8,128,768]{2,1,0} %broadcast.980), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.9 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.3 = bf16[] divide(bf16[] %constant.9, bf16[] %p3.6)
  %broadcast.18 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.3), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.87 = bf16[] constant(0)
  %broadcast.118 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.87), dimensions={}
  %select.4 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1006, bf16[8,128,768]{2,1,0} %broadcast.18, bf16[8,128,768]{2,1,0} %broadcast.118), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1180 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1177, bf16[8,128,768]{2,1,0} %select.4), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1181 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1180, bf16[8,128,768]{2,1,0} %multiply.976), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.1182 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1181), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.834 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.838 = bf16[1024]{0} broadcast(bf16[] %constant.834), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.829 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.833 = bf16[1024]{0} broadcast(bf16[] %constant.829), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1183 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1182, bf16[1024]{0} %broadcast.838, bf16[1024]{0} %broadcast.833), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1184 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1183), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1191 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1184), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p30.818 = bf16[768]{0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1194 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p30.818), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1197 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1191, bf16[8,128,768]{2,1,0} %broadcast.1194), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1199 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1198, bf16[8,128,768]{2,1,0} %multiply.1197), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1252 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1199), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p54.1250 = bf16[3072,768]{1,0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1251 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p54.1250), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1253 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.1252, bf16[768,3072]{0,1} %transpose.1251), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1254 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.1253), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p53.1248 = bf16[3072]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1255 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p53.1248), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1256 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.1254, bf16[8,128,3072]{2,1,0} %broadcast.1255), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.18 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.1256), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1266 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.18), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p52.1241 = bf16[768,3072]{1,0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1242 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p52.1241), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1267 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.1266, bf16[3072,768]{0,1} %transpose.1242), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1268 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1267), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p51.1239 = bf16[768]{0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1269 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p51.1239), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1270 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1268, bf16[8,128,768]{2,1,0} %broadcast.1269), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.20 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.21 = s64[] multiply(s64[] %constant.20, s64[] %add.19), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.22 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.23 = s64[] add(s64[] %multiply.21, s64[] %constant.22), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1207 = u64[] convert(s64[] %add.23), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1211 = u64[1]{0} reshape(u64[] %convert.1207), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.181 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1213 = u64[2]{0} concatenate(u64[1]{0} %reshape.1211, u64[1]{0} %constant.181), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1214 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1213), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1215 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1214), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1217 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1218 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1217), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1219 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1215, u32[8,128,768]{2,1,0} %broadcast.1218), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1220 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1219), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.185 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.19 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.185), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1226 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1220, f32[8,128,768]{2,1,0} %broadcast.19), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1229 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1226), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1204 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1230 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1229, bf16[8,128,768]{2,1,0} %broadcast.1204), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.11 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.4 = bf16[] divide(bf16[] %constant.11, bf16[] %p3.6)
  %broadcast.20 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.4), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.89 = bf16[] constant(0)
  %broadcast.125 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.89), dimensions={}
  %select.5 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1230, bf16[8,128,768]{2,1,0} %broadcast.20, bf16[8,128,768]{2,1,0} %broadcast.125), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1273 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1270, bf16[8,128,768]{2,1,0} %select.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1274 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1273, bf16[8,128,768]{2,1,0} %add.1199), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.1275 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1274), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.807 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.811 = bf16[1024]{0} broadcast(bf16[] %constant.807), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.802 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.806 = bf16[1024]{0} broadcast(bf16[] %constant.802), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1276 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1275, bf16[1024]{0} %broadcast.811, bf16[1024]{0} %broadcast.806), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1277 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1276), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1284 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1277), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p29.791 = bf16[768]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1287 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p29.791), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1290 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1284, bf16[8,128,768]{2,1,0} %broadcast.1287), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1292 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1291, bf16[8,128,768]{2,1,0} %multiply.1290), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1425 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1292), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p63.1423 = bf16[768,768]{1,0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1424 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p63.1423), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1426 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1425, bf16[768,768]{0,1} %transpose.1424), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1427 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1426), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p62.1421 = bf16[768]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1428 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p62.1421), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1429 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1427, bf16[8,128,768]{2,1,0} %broadcast.1428), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1432 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1429), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1433 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1432), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1435 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1433), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1404 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1292), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p61.1402 = bf16[768,768]{1,0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1403 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p61.1402), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1405 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1404, bf16[768,768]{0,1} %transpose.1403), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1406 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1405), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p60.1400 = bf16[768]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1407 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p60.1400), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1408 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1406, bf16[8,128,768]{2,1,0} %broadcast.1407), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1411 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1408), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1413 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1411), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1415 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.1413), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.1436 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.1435, bf16[96,64,128]{2,1,0} %reshape.1415), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.446 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.40 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.1436, bf16[96,128,128]{2,1,0} %broadcast.446), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1229 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.40), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.1442 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.1443 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1229, bf16[8,12,128,128]{3,2,1,0} %broadcast.1442), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.1444 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1449 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.1443, bf16[] %constant.1444), dimensions={3}, to_apply=%MaxComputation.1445, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1450 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1449), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.1451 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.1443, bf16[8,12,128,128]{3,2,1,0} %broadcast.1450), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.1452 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.1451), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.1453 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1458 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.1452, bf16[] %constant.1453), dimensions={3}, to_apply=%AddComputation.1454, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1459 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1458), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.1460 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.1452, bf16[8,12,128,128]{3,2,1,0} %broadcast.1459), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.24 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.25 = s64[] multiply(s64[] %constant.24, s64[] %add.23), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.26 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.27 = s64[] add(s64[] %multiply.25, s64[] %constant.26), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1362 = u64[] convert(s64[] %add.27), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1366 = u64[1]{0} reshape(u64[] %convert.1362), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.187 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1368 = u64[2]{0} concatenate(u64[1]{0} %reshape.1366, u64[1]{0} %constant.187), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1369 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1368), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1370 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.1369), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1372 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1373 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.1372), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1374 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.1370, u32[8,12,128,128]{3,2,1,0} %broadcast.1373), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1375 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.1374), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.191 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.22 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.191), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1381 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.1375, f32[8,12,128,128]{3,2,1,0} %broadcast.22), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1384 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.1381), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1359 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1385 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.1384, bf16[8,12,128,128]{3,2,1,0} %broadcast.1359), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.13 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.5 = bf16[] divide(bf16[] %constant.13, bf16[] %p3.6)
  %broadcast.23 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.91 = bf16[] constant(0)
  %broadcast.133 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.91), dimensions={}
  %select.6 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.1385, bf16[8,12,128,128]{3,2,1,0} %broadcast.23, bf16[8,12,128,128]{3,2,1,0} %broadcast.133), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1461 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.1460, bf16[8,12,128,128]{3,2,1,0} %select.6), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1463 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.1461), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1345 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1292), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p59.1343 = bf16[768,768]{1,0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1344 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p59.1343), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1346 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1345, bf16[768,768]{0,1} %transpose.1344), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1347 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1346), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p58.1341 = bf16[768]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1348 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p58.1341), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1349 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1347, bf16[8,128,768]{2,1,0} %broadcast.1348), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1352 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1349), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.1353 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1352), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1355 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1353), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.1464 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.1463, bf16[96,128,64]{2,1,0} %reshape.1355), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1465 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.1464), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1466 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.1465), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1468 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.1466), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p57.1334 = bf16[768,768]{1,0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1335 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p57.1334), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1469 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1468, bf16[768,768]{0,1} %transpose.1335), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1470 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1469), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p56.1332 = bf16[768]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1471 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p56.1332), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1472 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1470, bf16[8,128,768]{2,1,0} %broadcast.1471), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.28 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.29 = s64[] multiply(s64[] %constant.28, s64[] %add.27), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.30 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.31 = s64[] add(s64[] %multiply.29, s64[] %constant.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1300 = u64[] convert(s64[] %add.31), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1304 = u64[1]{0} reshape(u64[] %convert.1300), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.192 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1306 = u64[2]{0} concatenate(u64[1]{0} %reshape.1304, u64[1]{0} %constant.192), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1307 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1306), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1308 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1307), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1310 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1311 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1310), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1312 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1308, u32[8,128,768]{2,1,0} %broadcast.1311), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1313 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1312), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.197 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.24 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.197), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1319 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1313, f32[8,128,768]{2,1,0} %broadcast.24), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1322 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1319), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1297 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1323 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1322, bf16[8,128,768]{2,1,0} %broadcast.1297), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.15 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.6 = bf16[] divide(bf16[] %constant.15, bf16[] %p3.6)
  %broadcast.25 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.6), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.93 = bf16[] constant(0)
  %broadcast.137 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.93), dimensions={}
  %select.7 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1323, bf16[8,128,768]{2,1,0} %broadcast.25, bf16[8,128,768]{2,1,0} %broadcast.137), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1475 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1472, bf16[8,128,768]{2,1,0} %select.7), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1476 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1475, bf16[8,128,768]{2,1,0} %add.1292), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.1477 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1476), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.780 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.784 = bf16[1024]{0} broadcast(bf16[] %constant.780), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.775 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.779 = bf16[1024]{0} broadcast(bf16[] %constant.775), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1478 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1477, bf16[1024]{0} %broadcast.784, bf16[1024]{0} %broadcast.779), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1479 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1478), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1486 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1479), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p28.764 = bf16[768]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1489 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p28.764), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1492 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1486, bf16[8,128,768]{2,1,0} %broadcast.1489), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1494 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1493, bf16[8,128,768]{2,1,0} %multiply.1492), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1547 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1494), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p68.1545 = bf16[3072,768]{1,0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1546 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p68.1545), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1548 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.1547, bf16[768,3072]{0,1} %transpose.1546), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1549 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.1548), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p67.1543 = bf16[3072]{0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1550 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p67.1543), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1551 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.1549, bf16[8,128,3072]{2,1,0} %broadcast.1550), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.19 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.1551), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1561 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.19), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p66.1536 = bf16[768,3072]{1,0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1537 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p66.1536), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1562 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.1561, bf16[3072,768]{0,1} %transpose.1537), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1563 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1562), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p65.1534 = bf16[768]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1564 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p65.1534), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1565 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1563, bf16[8,128,768]{2,1,0} %broadcast.1564), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.32 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.33 = s64[] multiply(s64[] %constant.32, s64[] %add.31), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.34 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.35 = s64[] add(s64[] %multiply.33, s64[] %constant.34), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1502 = u64[] convert(s64[] %add.35), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1506 = u64[1]{0} reshape(u64[] %convert.1502), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.200 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1508 = u64[2]{0} concatenate(u64[1]{0} %reshape.1506, u64[1]{0} %constant.200), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1509 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1508), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1510 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1509), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1512 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1513 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1512), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1514 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1510, u32[8,128,768]{2,1,0} %broadcast.1513), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1515 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1514), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.205 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.26 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.205), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1521 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1515, f32[8,128,768]{2,1,0} %broadcast.26), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1524 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1521), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1499 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1525 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1524, bf16[8,128,768]{2,1,0} %broadcast.1499), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.17 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.7 = bf16[] divide(bf16[] %constant.17, bf16[] %p3.6)
  %broadcast.27 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.7), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.95 = bf16[] constant(0)
  %broadcast.144 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.95), dimensions={}
  %select.8 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1525, bf16[8,128,768]{2,1,0} %broadcast.27, bf16[8,128,768]{2,1,0} %broadcast.144), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1568 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1565, bf16[8,128,768]{2,1,0} %select.8), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1569 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1568, bf16[8,128,768]{2,1,0} %add.1494), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.1570 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1569), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.753 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.757 = bf16[1024]{0} broadcast(bf16[] %constant.753), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.748 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.752 = bf16[1024]{0} broadcast(bf16[] %constant.748), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1571 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1570, bf16[1024]{0} %broadcast.757, bf16[1024]{0} %broadcast.752), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1572 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1571), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1579 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1572), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p27.737 = bf16[768]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1582 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p27.737), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1585 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1579, bf16[8,128,768]{2,1,0} %broadcast.1582), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1587 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1586, bf16[8,128,768]{2,1,0} %multiply.1585), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1720 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1587), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p77.1718 = bf16[768,768]{1,0} parameter(77), frontend_attributes={neff_input_names="input77"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1719 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p77.1718), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1721 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1720, bf16[768,768]{0,1} %transpose.1719), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1722 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1721), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p76.1716 = bf16[768]{0} parameter(76), frontend_attributes={neff_input_names="input76"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1723 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p76.1716), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1724 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1722, bf16[8,128,768]{2,1,0} %broadcast.1723), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1727 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1724), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1728 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1727), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1730 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1728), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1699 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1587), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p75.1697 = bf16[768,768]{1,0} parameter(75), frontend_attributes={neff_input_names="input75"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1698 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p75.1697), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1700 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1699, bf16[768,768]{0,1} %transpose.1698), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1701 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1700), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p74.1695 = bf16[768]{0} parameter(74), frontend_attributes={neff_input_names="input74"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1702 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p74.1695), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1703 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1701, bf16[8,128,768]{2,1,0} %broadcast.1702), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1706 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1703), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.1708 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1706), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1710 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.1708), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.1731 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.1730, bf16[96,64,128]{2,1,0} %reshape.1710), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.449 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.41 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.1731, bf16[96,128,128]{2,1,0} %broadcast.449), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1232 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.41), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.1737 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.1738 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1232, bf16[8,12,128,128]{3,2,1,0} %broadcast.1737), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.1739 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1744 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.1738, bf16[] %constant.1739), dimensions={3}, to_apply=%MaxComputation.1740, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1745 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1744), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.1746 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.1738, bf16[8,12,128,128]{3,2,1,0} %broadcast.1745), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.1747 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.1746), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.1748 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.1753 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.1747, bf16[] %constant.1748), dimensions={3}, to_apply=%AddComputation.1749, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.1754 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.1753), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.1755 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.1747, bf16[8,12,128,128]{3,2,1,0} %broadcast.1754), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.36 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.37 = s64[] multiply(s64[] %constant.36, s64[] %add.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.38 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.39 = s64[] add(s64[] %multiply.37, s64[] %constant.38), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1657 = u64[] convert(s64[] %add.39), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1661 = u64[1]{0} reshape(u64[] %convert.1657), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.207 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1663 = u64[2]{0} concatenate(u64[1]{0} %reshape.1661, u64[1]{0} %constant.207), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1664 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1663), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1665 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.1664), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1667 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1668 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.1667), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1669 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.1665, u32[8,12,128,128]{3,2,1,0} %broadcast.1668), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1670 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.1669), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.212 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.29 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.212), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1676 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.1670, f32[8,12,128,128]{3,2,1,0} %broadcast.29), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1679 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.1676), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1654 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1680 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.1679, bf16[8,12,128,128]{3,2,1,0} %broadcast.1654), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.19 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.8 = bf16[] divide(bf16[] %constant.19, bf16[] %p3.6)
  %broadcast.30 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.8), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.97 = bf16[] constant(0)
  %broadcast.152 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.97), dimensions={}
  %select.9 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.1680, bf16[8,12,128,128]{3,2,1,0} %broadcast.30, bf16[8,12,128,128]{3,2,1,0} %broadcast.152), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1756 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.1755, bf16[8,12,128,128]{3,2,1,0} %select.9), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1758 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.1756), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1640 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1587), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p73.1638 = bf16[768,768]{1,0} parameter(73), frontend_attributes={neff_input_names="input73"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1639 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p73.1638), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1641 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1640, bf16[768,768]{0,1} %transpose.1639), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1642 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1641), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p72.1636 = bf16[768]{0} parameter(72), frontend_attributes={neff_input_names="input72"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1643 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p72.1636), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1644 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1642, bf16[8,128,768]{2,1,0} %broadcast.1643), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1647 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1644), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.1648 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1647), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1650 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1648), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.1759 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.1758, bf16[96,128,64]{2,1,0} %reshape.1650), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1760 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.1759), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1761 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.1760), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1763 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.1761), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p71.1629 = bf16[768,768]{1,0} parameter(71), frontend_attributes={neff_input_names="input71"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1630 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p71.1629), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1764 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1763, bf16[768,768]{0,1} %transpose.1630), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1765 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1764), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p70.1627 = bf16[768]{0} parameter(70), frontend_attributes={neff_input_names="input70"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1766 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p70.1627), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1767 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1765, bf16[8,128,768]{2,1,0} %broadcast.1766), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.40 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.41 = s64[] multiply(s64[] %constant.40, s64[] %add.39), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.42 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.43 = s64[] add(s64[] %multiply.41, s64[] %constant.42), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1595 = u64[] convert(s64[] %add.43), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1599 = u64[1]{0} reshape(u64[] %convert.1595), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.214 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1601 = u64[2]{0} concatenate(u64[1]{0} %reshape.1599, u64[1]{0} %constant.214), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1602 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1601), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1603 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1602), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1605 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1606 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1605), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1607 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1603, u32[8,128,768]{2,1,0} %broadcast.1606), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1608 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1607), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.219 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.31 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.219), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1614 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1608, f32[8,128,768]{2,1,0} %broadcast.31), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1617 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1614), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1592 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1618 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1617, bf16[8,128,768]{2,1,0} %broadcast.1592), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.21 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.9 = bf16[] divide(bf16[] %constant.21, bf16[] %p3.6)
  %broadcast.32 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.9), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.99 = bf16[] constant(0)
  %broadcast.156 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.99), dimensions={}
  %select.10 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1618, bf16[8,128,768]{2,1,0} %broadcast.32, bf16[8,128,768]{2,1,0} %broadcast.156), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1770 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1767, bf16[8,128,768]{2,1,0} %select.10), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1771 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1770, bf16[8,128,768]{2,1,0} %add.1587), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.1772 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1771), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.726 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.730 = bf16[1024]{0} broadcast(bf16[] %constant.726), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.721 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.725 = bf16[1024]{0} broadcast(bf16[] %constant.721), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1773 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1772, bf16[1024]{0} %broadcast.730, bf16[1024]{0} %broadcast.725), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1774 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1773), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1781 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1774), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p26.710 = bf16[768]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1784 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p26.710), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1787 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1781, bf16[8,128,768]{2,1,0} %broadcast.1784), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1789 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1788, bf16[8,128,768]{2,1,0} %multiply.1787), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1842 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1789), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p82.1840 = bf16[3072,768]{1,0} parameter(82), frontend_attributes={neff_input_names="input82"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1841 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p82.1840), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1843 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.1842, bf16[768,3072]{0,1} %transpose.1841), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1844 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.1843), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p81.1838 = bf16[3072]{0} parameter(81), frontend_attributes={neff_input_names="input81"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1845 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p81.1838), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1846 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.1844, bf16[8,128,3072]{2,1,0} %broadcast.1845), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.20 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.1846), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.1856 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.20), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p80.1831 = bf16[768,3072]{1,0} parameter(80), frontend_attributes={neff_input_names="input80"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1832 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p80.1831), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1857 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.1856, bf16[3072,768]{0,1} %transpose.1832), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1858 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1857), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p79.1829 = bf16[768]{0} parameter(79), frontend_attributes={neff_input_names="input79"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1859 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p79.1829), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1860 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1858, bf16[8,128,768]{2,1,0} %broadcast.1859), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.44 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.45 = s64[] multiply(s64[] %constant.44, s64[] %add.43), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.46 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.47 = s64[] add(s64[] %multiply.45, s64[] %constant.46), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1797 = u64[] convert(s64[] %add.47), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1801 = u64[1]{0} reshape(u64[] %convert.1797), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.221 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1803 = u64[2]{0} concatenate(u64[1]{0} %reshape.1801, u64[1]{0} %constant.221), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1804 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1803), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1805 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1804), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1807 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1808 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1807), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1809 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1805, u32[8,128,768]{2,1,0} %broadcast.1808), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1810 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1809), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.227 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.33 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.227), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1816 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1810, f32[8,128,768]{2,1,0} %broadcast.33), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1819 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1816), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1794 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1820 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1819, bf16[8,128,768]{2,1,0} %broadcast.1794), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.23 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.10 = bf16[] divide(bf16[] %constant.23, bf16[] %p3.6)
  %broadcast.34 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.10), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.101 = bf16[] constant(0)
  %broadcast.165 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.101), dimensions={}
  %select.11 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1820, bf16[8,128,768]{2,1,0} %broadcast.34, bf16[8,128,768]{2,1,0} %broadcast.165), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1863 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.1860, bf16[8,128,768]{2,1,0} %select.11), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.1864 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.1863, bf16[8,128,768]{2,1,0} %add.1789), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.1865 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1864), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.699 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.703 = bf16[1024]{0} broadcast(bf16[] %constant.699), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.694 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.698 = bf16[1024]{0} broadcast(bf16[] %constant.694), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.1866 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.1865, bf16[1024]{0} %broadcast.703, bf16[1024]{0} %broadcast.698), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.1867 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.1866), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.1874 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.1867), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p25.683 = bf16[768]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.1877 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p25.683), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.1880 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.1874, bf16[8,128,768]{2,1,0} %broadcast.1877), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.1882 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.1881, bf16[8,128,768]{2,1,0} %multiply.1880), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2015 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1882), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p91.2013 = bf16[768,768]{1,0} parameter(91), frontend_attributes={neff_input_names="input91"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2014 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p91.2013), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2016 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2015, bf16[768,768]{0,1} %transpose.2014), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2017 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2016), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p90.2011 = bf16[768]{0} parameter(90), frontend_attributes={neff_input_names="input90"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2018 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p90.2011), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2019 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2017, bf16[8,128,768]{2,1,0} %broadcast.2018), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2022 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2019), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2023 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2022), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2025 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2023), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.1994 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1882), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p89.1992 = bf16[768,768]{1,0} parameter(89), frontend_attributes={neff_input_names="input89"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1993 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p89.1992), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1995 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1994, bf16[768,768]{0,1} %transpose.1993), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1996 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1995), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p88.1990 = bf16[768]{0} parameter(88), frontend_attributes={neff_input_names="input88"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1997 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p88.1990), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1998 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1996, bf16[8,128,768]{2,1,0} %broadcast.1997), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2001 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1998), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2003 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2001), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2005 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.2003), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.2026 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.2025, bf16[96,64,128]{2,1,0} %reshape.2005), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.452 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.42 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.2026, bf16[96,128,128]{2,1,0} %broadcast.452), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1236 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.42), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.2032 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.2033 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1236, bf16[8,12,128,128]{3,2,1,0} %broadcast.2032), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.2034 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2039 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.2033, bf16[] %constant.2034), dimensions={3}, to_apply=%MaxComputation.2035, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2040 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2039), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.2041 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.2033, bf16[8,12,128,128]{3,2,1,0} %broadcast.2040), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.2042 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.2041), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.2043 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2048 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.2042, bf16[] %constant.2043), dimensions={3}, to_apply=%AddComputation.2044, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2049 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2048), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.2050 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.2042, bf16[8,12,128,128]{3,2,1,0} %broadcast.2049), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.48 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.49 = s64[] multiply(s64[] %constant.48, s64[] %add.47), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.50 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.51 = s64[] add(s64[] %multiply.49, s64[] %constant.50), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1952 = u64[] convert(s64[] %add.51), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1956 = u64[1]{0} reshape(u64[] %convert.1952), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.229 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1958 = u64[2]{0} concatenate(u64[1]{0} %reshape.1956, u64[1]{0} %constant.229), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1959 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1958), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1960 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.1959), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1962 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1963 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.1962), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1964 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.1960, u32[8,12,128,128]{3,2,1,0} %broadcast.1963), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1965 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.1964), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.234 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.36 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.234), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1971 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.1965, f32[8,12,128,128]{3,2,1,0} %broadcast.36), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1974 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.1971), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1949 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1975 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.1974, bf16[8,12,128,128]{3,2,1,0} %broadcast.1949), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.25 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.11 = bf16[] divide(bf16[] %constant.25, bf16[] %p3.6)
  %broadcast.37 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.11), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.103 = bf16[] constant(0)
  %broadcast.173 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.103), dimensions={}
  %select.12 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.1975, bf16[8,12,128,128]{3,2,1,0} %broadcast.37, bf16[8,12,128,128]{3,2,1,0} %broadcast.173), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2051 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.2050, bf16[8,12,128,128]{3,2,1,0} %select.12), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2053 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.2051), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1935 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.1882), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p87.1933 = bf16[768,768]{1,0} parameter(87), frontend_attributes={neff_input_names="input87"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1934 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p87.1933), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.1936 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.1935, bf16[768,768]{0,1} %transpose.1934), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1937 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.1936), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p86.1931 = bf16[768]{0} parameter(86), frontend_attributes={neff_input_names="input86"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.1938 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p86.1931), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.1939 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.1937, bf16[8,128,768]{2,1,0} %broadcast.1938), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.1942 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.1939), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.1943 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.1942), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.1945 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.1943), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.2054 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.2053, bf16[96,128,64]{2,1,0} %reshape.1945), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2055 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.2054), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2056 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.2055), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2058 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.2056), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p85.1924 = bf16[768,768]{1,0} parameter(85), frontend_attributes={neff_input_names="input85"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.1925 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p85.1924), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2059 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2058, bf16[768,768]{0,1} %transpose.1925), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2060 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2059), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p84.1922 = bf16[768]{0} parameter(84), frontend_attributes={neff_input_names="input84"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2061 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p84.1922), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2062 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2060, bf16[8,128,768]{2,1,0} %broadcast.2061), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.52 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.53 = s64[] multiply(s64[] %constant.52, s64[] %add.51), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.54 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.55 = s64[] add(s64[] %multiply.53, s64[] %constant.54), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1890 = u64[] convert(s64[] %add.55), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.1894 = u64[1]{0} reshape(u64[] %convert.1890), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.236 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.1896 = u64[2]{0} concatenate(u64[1]{0} %reshape.1894, u64[1]{0} %constant.236), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.1897 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.1896), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.1898 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.1897), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.1900 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1901 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.1900), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.1902 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.1898, u32[8,128,768]{2,1,0} %broadcast.1901), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1903 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.1902), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.241 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.38 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.241), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.1909 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.1903, f32[8,128,768]{2,1,0} %broadcast.38), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.1912 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.1909), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.1887 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.1913 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.1912, bf16[8,128,768]{2,1,0} %broadcast.1887), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.27 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.12 = bf16[] divide(bf16[] %constant.27, bf16[] %p3.6)
  %broadcast.39 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.12), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.105 = bf16[] constant(0)
  %broadcast.178 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.105), dimensions={}
  %select.13 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.1913, bf16[8,128,768]{2,1,0} %broadcast.39, bf16[8,128,768]{2,1,0} %broadcast.178), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2065 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2062, bf16[8,128,768]{2,1,0} %select.13), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2066 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2065, bf16[8,128,768]{2,1,0} %add.1882), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.2067 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2066), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.672 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.676 = bf16[1024]{0} broadcast(bf16[] %constant.672), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.667 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.671 = bf16[1024]{0} broadcast(bf16[] %constant.667), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2068 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2067, bf16[1024]{0} %broadcast.676, bf16[1024]{0} %broadcast.671), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2069 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2068), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2076 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2069), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p24.656 = bf16[768]{0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2079 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p24.656), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2082 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2076, bf16[8,128,768]{2,1,0} %broadcast.2079), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2084 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2083, bf16[8,128,768]{2,1,0} %multiply.2082), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2137 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2084), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p96.2135 = bf16[3072,768]{1,0} parameter(96), frontend_attributes={neff_input_names="input96"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2136 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p96.2135), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2138 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.2137, bf16[768,3072]{0,1} %transpose.2136), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2139 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.2138), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p95.2133 = bf16[3072]{0} parameter(95), frontend_attributes={neff_input_names="input95"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2140 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p95.2133), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2141 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.2139, bf16[8,128,3072]{2,1,0} %broadcast.2140), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.21 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.2141), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.2151 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.21), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p94.2126 = bf16[768,3072]{1,0} parameter(94), frontend_attributes={neff_input_names="input94"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2127 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p94.2126), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2152 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.2151, bf16[3072,768]{0,1} %transpose.2127), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2153 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2152), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p93.2124 = bf16[768]{0} parameter(93), frontend_attributes={neff_input_names="input93"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2154 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p93.2124), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2155 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2153, bf16[8,128,768]{2,1,0} %broadcast.2154), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.56 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.57 = s64[] multiply(s64[] %constant.56, s64[] %add.55), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.58 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.59 = s64[] add(s64[] %multiply.57, s64[] %constant.58), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2092 = u64[] convert(s64[] %add.59), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2096 = u64[1]{0} reshape(u64[] %convert.2092), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.243 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2098 = u64[2]{0} concatenate(u64[1]{0} %reshape.2096, u64[1]{0} %constant.243), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2099 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2098), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2100 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2099), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2102 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2103 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2102), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2104 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2100, u32[8,128,768]{2,1,0} %broadcast.2103), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2105 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2104), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.248 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.40 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.248), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2111 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2105, f32[8,128,768]{2,1,0} %broadcast.40), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2114 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2111), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2089 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2115 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2114, bf16[8,128,768]{2,1,0} %broadcast.2089), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.29 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.13 = bf16[] divide(bf16[] %constant.29, bf16[] %p3.6)
  %broadcast.41 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.13), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.107 = bf16[] constant(0)
  %broadcast.188 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.107), dimensions={}
  %select.14 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2115, bf16[8,128,768]{2,1,0} %broadcast.41, bf16[8,128,768]{2,1,0} %broadcast.188), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2158 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2155, bf16[8,128,768]{2,1,0} %select.14), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2159 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2158, bf16[8,128,768]{2,1,0} %add.2084), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.2160 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2159), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.645 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.649 = bf16[1024]{0} broadcast(bf16[] %constant.645), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.640 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.644 = bf16[1024]{0} broadcast(bf16[] %constant.640), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2161 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2160, bf16[1024]{0} %broadcast.649, bf16[1024]{0} %broadcast.644), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2162 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2161), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2169 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2162), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p23.629 = bf16[768]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2172 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p23.629), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2175 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2169, bf16[8,128,768]{2,1,0} %broadcast.2172), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2177 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2176, bf16[8,128,768]{2,1,0} %multiply.2175), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2310 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2177), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p105.2308 = bf16[768,768]{1,0} parameter(105), frontend_attributes={neff_input_names="input105"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2309 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p105.2308), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2311 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2310, bf16[768,768]{0,1} %transpose.2309), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2312 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2311), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p104.2306 = bf16[768]{0} parameter(104), frontend_attributes={neff_input_names="input104"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2313 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p104.2306), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2314 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2312, bf16[8,128,768]{2,1,0} %broadcast.2313), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2317 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2314), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2318 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2317), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2320 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2318), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2289 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2177), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p103.2287 = bf16[768,768]{1,0} parameter(103), frontend_attributes={neff_input_names="input103"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2288 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p103.2287), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2290 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2289, bf16[768,768]{0,1} %transpose.2288), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2291 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2290), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p102.2285 = bf16[768]{0} parameter(102), frontend_attributes={neff_input_names="input102"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2292 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p102.2285), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2293 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2291, bf16[8,128,768]{2,1,0} %broadcast.2292), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2296 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2293), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2298 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2296), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2300 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.2298), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.2321 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.2320, bf16[96,64,128]{2,1,0} %reshape.2300), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.456 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.43 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.2321, bf16[96,128,128]{2,1,0} %broadcast.456), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1240 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.43), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.2327 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.2328 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1240, bf16[8,12,128,128]{3,2,1,0} %broadcast.2327), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.2329 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2334 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.2328, bf16[] %constant.2329), dimensions={3}, to_apply=%MaxComputation.2330, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2335 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2334), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.2336 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.2328, bf16[8,12,128,128]{3,2,1,0} %broadcast.2335), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.2337 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.2336), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.2338 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2343 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.2337, bf16[] %constant.2338), dimensions={3}, to_apply=%AddComputation.2339, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2344 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2343), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.2345 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.2337, bf16[8,12,128,128]{3,2,1,0} %broadcast.2344), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.60 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.61 = s64[] multiply(s64[] %constant.60, s64[] %add.59), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.62 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.63 = s64[] add(s64[] %multiply.61, s64[] %constant.62), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2247 = u64[] convert(s64[] %add.63), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2251 = u64[1]{0} reshape(u64[] %convert.2247), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.251 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2253 = u64[2]{0} concatenate(u64[1]{0} %reshape.2251, u64[1]{0} %constant.251), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2254 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2253), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2255 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.2254), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2257 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2258 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.2257), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2259 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.2255, u32[8,12,128,128]{3,2,1,0} %broadcast.2258), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2260 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.2259), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.256 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.43 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.256), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2266 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.2260, f32[8,12,128,128]{3,2,1,0} %broadcast.43), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2269 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.2266), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2244 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2270 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.2269, bf16[8,12,128,128]{3,2,1,0} %broadcast.2244), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.31 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.14 = bf16[] divide(bf16[] %constant.31, bf16[] %p3.6)
  %broadcast.44 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.14), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.109 = bf16[] constant(0)
  %broadcast.197 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.109), dimensions={}
  %select.15 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.2270, bf16[8,12,128,128]{3,2,1,0} %broadcast.44, bf16[8,12,128,128]{3,2,1,0} %broadcast.197), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2346 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.2345, bf16[8,12,128,128]{3,2,1,0} %select.15), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2348 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.2346), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2230 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2177), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p101.2228 = bf16[768,768]{1,0} parameter(101), frontend_attributes={neff_input_names="input101"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2229 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p101.2228), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2231 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2230, bf16[768,768]{0,1} %transpose.2229), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2232 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2231), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p100.2226 = bf16[768]{0} parameter(100), frontend_attributes={neff_input_names="input100"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2233 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p100.2226), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2234 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2232, bf16[8,128,768]{2,1,0} %broadcast.2233), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2237 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2234), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.2238 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2237), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2240 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2238), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.2349 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.2348, bf16[96,128,64]{2,1,0} %reshape.2240), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2350 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.2349), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2351 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.2350), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2353 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.2351), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p99.2219 = bf16[768,768]{1,0} parameter(99), frontend_attributes={neff_input_names="input99"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2220 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p99.2219), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2354 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2353, bf16[768,768]{0,1} %transpose.2220), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2355 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2354), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p98.2217 = bf16[768]{0} parameter(98), frontend_attributes={neff_input_names="input98"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2356 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p98.2217), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2357 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2355, bf16[8,128,768]{2,1,0} %broadcast.2356), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.64 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.65 = s64[] multiply(s64[] %constant.64, s64[] %add.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.66 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.67 = s64[] add(s64[] %multiply.65, s64[] %constant.66), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2185 = u64[] convert(s64[] %add.67), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2189 = u64[1]{0} reshape(u64[] %convert.2185), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.258 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2191 = u64[2]{0} concatenate(u64[1]{0} %reshape.2189, u64[1]{0} %constant.258), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2192 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2191), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2193 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2192), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2195 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2196 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2195), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2197 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2193, u32[8,128,768]{2,1,0} %broadcast.2196), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2198 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2197), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.263 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.45 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.263), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2204 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2198, f32[8,128,768]{2,1,0} %broadcast.45), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2207 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2204), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2182 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2208 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2207, bf16[8,128,768]{2,1,0} %broadcast.2182), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.33 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.15 = bf16[] divide(bf16[] %constant.33, bf16[] %p3.6)
  %broadcast.46 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.15), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.111 = bf16[] constant(0)
  %broadcast.203 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.111), dimensions={}
  %select.16 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2208, bf16[8,128,768]{2,1,0} %broadcast.46, bf16[8,128,768]{2,1,0} %broadcast.203), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2360 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2357, bf16[8,128,768]{2,1,0} %select.16), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2361 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2360, bf16[8,128,768]{2,1,0} %add.2177), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.2362 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2361), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.618 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.622 = bf16[1024]{0} broadcast(bf16[] %constant.618), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.613 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.617 = bf16[1024]{0} broadcast(bf16[] %constant.613), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2363 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2362, bf16[1024]{0} %broadcast.622, bf16[1024]{0} %broadcast.617), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2364 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2363), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2371 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2364), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p22.602 = bf16[768]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2374 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p22.602), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2377 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2371, bf16[8,128,768]{2,1,0} %broadcast.2374), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2379 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2378, bf16[8,128,768]{2,1,0} %multiply.2377), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2432 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2379), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p110.2430 = bf16[3072,768]{1,0} parameter(110), frontend_attributes={neff_input_names="input110"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2431 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p110.2430), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2433 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.2432, bf16[768,3072]{0,1} %transpose.2431), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2434 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.2433), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p109.2428 = bf16[3072]{0} parameter(109), frontend_attributes={neff_input_names="input109"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2435 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p109.2428), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2436 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.2434, bf16[8,128,3072]{2,1,0} %broadcast.2435), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.22 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.2436), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.2446 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.22), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p108.2421 = bf16[768,3072]{1,0} parameter(108), frontend_attributes={neff_input_names="input108"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2422 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p108.2421), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2447 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.2446, bf16[3072,768]{0,1} %transpose.2422), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2448 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2447), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p107.2419 = bf16[768]{0} parameter(107), frontend_attributes={neff_input_names="input107"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2449 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p107.2419), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2450 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2448, bf16[8,128,768]{2,1,0} %broadcast.2449), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.68 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.69 = s64[] multiply(s64[] %constant.68, s64[] %add.67), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.70 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.71 = s64[] add(s64[] %multiply.69, s64[] %constant.70), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2387 = u64[] convert(s64[] %add.71), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2391 = u64[1]{0} reshape(u64[] %convert.2387), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.265 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2393 = u64[2]{0} concatenate(u64[1]{0} %reshape.2391, u64[1]{0} %constant.265), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2394 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2393), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2395 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2394), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2397 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2398 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2397), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2399 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2395, u32[8,128,768]{2,1,0} %broadcast.2398), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2400 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2399), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.270 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.47 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.270), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2406 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2400, f32[8,128,768]{2,1,0} %broadcast.47), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2409 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2406), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2384 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2410 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2409, bf16[8,128,768]{2,1,0} %broadcast.2384), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.35 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.16 = bf16[] divide(bf16[] %constant.35, bf16[] %p3.6)
  %broadcast.48 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.16), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.113 = bf16[] constant(0)
  %broadcast.214 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.113), dimensions={}
  %select.17 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2410, bf16[8,128,768]{2,1,0} %broadcast.48, bf16[8,128,768]{2,1,0} %broadcast.214), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2453 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2450, bf16[8,128,768]{2,1,0} %select.17), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2454 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2453, bf16[8,128,768]{2,1,0} %add.2379), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.2455 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2454), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.591 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.595 = bf16[1024]{0} broadcast(bf16[] %constant.591), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.586 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.590 = bf16[1024]{0} broadcast(bf16[] %constant.586), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2456 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2455, bf16[1024]{0} %broadcast.595, bf16[1024]{0} %broadcast.590), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2457 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2456), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2464 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2457), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p21.575 = bf16[768]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2467 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p21.575), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2470 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2464, bf16[8,128,768]{2,1,0} %broadcast.2467), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2472 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2471, bf16[8,128,768]{2,1,0} %multiply.2470), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2605 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2472), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p119.2603 = bf16[768,768]{1,0} parameter(119), frontend_attributes={neff_input_names="input119"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2604 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p119.2603), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2606 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2605, bf16[768,768]{0,1} %transpose.2604), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2607 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2606), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p118.2601 = bf16[768]{0} parameter(118), frontend_attributes={neff_input_names="input118"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2608 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p118.2601), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2609 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2607, bf16[8,128,768]{2,1,0} %broadcast.2608), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2612 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2609), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2613 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2612), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2615 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2613), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2584 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2472), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p117.2582 = bf16[768,768]{1,0} parameter(117), frontend_attributes={neff_input_names="input117"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2583 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p117.2582), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2585 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2584, bf16[768,768]{0,1} %transpose.2583), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2586 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2585), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p116.2580 = bf16[768]{0} parameter(116), frontend_attributes={neff_input_names="input116"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2587 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p116.2580), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2588 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2586, bf16[8,128,768]{2,1,0} %broadcast.2587), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2591 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2588), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2593 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2591), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2595 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.2593), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.2616 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.2615, bf16[96,64,128]{2,1,0} %reshape.2595), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.459 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.44 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.2616, bf16[96,128,128]{2,1,0} %broadcast.459), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1243 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.44), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.2622 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.2623 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1243, bf16[8,12,128,128]{3,2,1,0} %broadcast.2622), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.2624 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2629 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.2623, bf16[] %constant.2624), dimensions={3}, to_apply=%MaxComputation.2625, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2630 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2629), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.2631 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.2623, bf16[8,12,128,128]{3,2,1,0} %broadcast.2630), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.2632 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.2631), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.2633 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2638 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.2632, bf16[] %constant.2633), dimensions={3}, to_apply=%AddComputation.2634, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2639 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2638), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.2640 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.2632, bf16[8,12,128,128]{3,2,1,0} %broadcast.2639), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.72 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.73 = s64[] multiply(s64[] %constant.72, s64[] %add.71), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.74 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.75 = s64[] add(s64[] %multiply.73, s64[] %constant.74), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2542 = u64[] convert(s64[] %add.75), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2546 = u64[1]{0} reshape(u64[] %convert.2542), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.273 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2548 = u64[2]{0} concatenate(u64[1]{0} %reshape.2546, u64[1]{0} %constant.273), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2549 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2548), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2550 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.2549), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2552 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2553 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.2552), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2554 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.2550, u32[8,12,128,128]{3,2,1,0} %broadcast.2553), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2555 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.2554), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.278 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.50 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.278), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2561 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.2555, f32[8,12,128,128]{3,2,1,0} %broadcast.50), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2564 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.2561), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2539 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2565 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.2564, bf16[8,12,128,128]{3,2,1,0} %broadcast.2539), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.37 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.17 = bf16[] divide(bf16[] %constant.37, bf16[] %p3.6)
  %broadcast.51 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.17), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.115 = bf16[] constant(0)
  %broadcast.226 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.115), dimensions={}
  %select.18 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.2565, bf16[8,12,128,128]{3,2,1,0} %broadcast.51, bf16[8,12,128,128]{3,2,1,0} %broadcast.226), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2641 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.2640, bf16[8,12,128,128]{3,2,1,0} %select.18), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2643 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.2641), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2525 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2472), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p115.2523 = bf16[768,768]{1,0} parameter(115), frontend_attributes={neff_input_names="input115"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2524 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p115.2523), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2526 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2525, bf16[768,768]{0,1} %transpose.2524), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2527 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2526), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p114.2521 = bf16[768]{0} parameter(114), frontend_attributes={neff_input_names="input114"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2528 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p114.2521), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2529 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2527, bf16[8,128,768]{2,1,0} %broadcast.2528), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2532 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2529), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.2533 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2532), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2535 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2533), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.2644 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.2643, bf16[96,128,64]{2,1,0} %reshape.2535), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2645 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.2644), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2646 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.2645), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2648 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.2646), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p113.2514 = bf16[768,768]{1,0} parameter(113), frontend_attributes={neff_input_names="input113"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2515 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p113.2514), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2649 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2648, bf16[768,768]{0,1} %transpose.2515), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2650 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2649), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p112.2512 = bf16[768]{0} parameter(112), frontend_attributes={neff_input_names="input112"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2651 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p112.2512), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2652 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2650, bf16[8,128,768]{2,1,0} %broadcast.2651), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.76 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.77 = s64[] multiply(s64[] %constant.76, s64[] %add.75), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.78 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.79 = s64[] add(s64[] %multiply.77, s64[] %constant.78), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2480 = u64[] convert(s64[] %add.79), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2484 = u64[1]{0} reshape(u64[] %convert.2480), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.280 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2486 = u64[2]{0} concatenate(u64[1]{0} %reshape.2484, u64[1]{0} %constant.280), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2487 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2486), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2488 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2487), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2490 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2491 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2490), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2492 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2488, u32[8,128,768]{2,1,0} %broadcast.2491), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2493 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2492), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.285 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.52 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.285), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2499 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2493, f32[8,128,768]{2,1,0} %broadcast.52), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2502 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2499), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2477 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2503 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2502, bf16[8,128,768]{2,1,0} %broadcast.2477), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.39 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.18 = bf16[] divide(bf16[] %constant.39, bf16[] %p3.6)
  %broadcast.53 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.18), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.117 = bf16[] constant(0)
  %broadcast.233 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.117), dimensions={}
  %select.19 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2503, bf16[8,128,768]{2,1,0} %broadcast.53, bf16[8,128,768]{2,1,0} %broadcast.233), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2655 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2652, bf16[8,128,768]{2,1,0} %select.19), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2656 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2655, bf16[8,128,768]{2,1,0} %add.2472), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.2657 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2656), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.564 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.568 = bf16[1024]{0} broadcast(bf16[] %constant.564), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.559 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.563 = bf16[1024]{0} broadcast(bf16[] %constant.559), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2658 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2657, bf16[1024]{0} %broadcast.568, bf16[1024]{0} %broadcast.563), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2659 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2658), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2666 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2659), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p20.548 = bf16[768]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2669 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p20.548), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2672 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2666, bf16[8,128,768]{2,1,0} %broadcast.2669), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2674 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2673, bf16[8,128,768]{2,1,0} %multiply.2672), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2727 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2674), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p124.2725 = bf16[3072,768]{1,0} parameter(124), frontend_attributes={neff_input_names="input124"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2726 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p124.2725), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2728 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.2727, bf16[768,3072]{0,1} %transpose.2726), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2729 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.2728), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p123.2723 = bf16[3072]{0} parameter(123), frontend_attributes={neff_input_names="input123"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2730 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p123.2723), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2731 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.2729, bf16[8,128,3072]{2,1,0} %broadcast.2730), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.23 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.2731), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.2741 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.23), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p122.2716 = bf16[768,3072]{1,0} parameter(122), frontend_attributes={neff_input_names="input122"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2717 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p122.2716), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2742 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.2741, bf16[3072,768]{0,1} %transpose.2717), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2743 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2742), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p121.2714 = bf16[768]{0} parameter(121), frontend_attributes={neff_input_names="input121"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2744 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p121.2714), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2745 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2743, bf16[8,128,768]{2,1,0} %broadcast.2744), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.80 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.81 = s64[] multiply(s64[] %constant.80, s64[] %add.79), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.82 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.83 = s64[] add(s64[] %multiply.81, s64[] %constant.82), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2682 = u64[] convert(s64[] %add.83), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2686 = u64[1]{0} reshape(u64[] %convert.2682), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.287 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2688 = u64[2]{0} concatenate(u64[1]{0} %reshape.2686, u64[1]{0} %constant.287), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2689 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2688), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2690 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2689), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2692 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2693 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2692), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2694 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2690, u32[8,128,768]{2,1,0} %broadcast.2693), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2695 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2694), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.292 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.54 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.292), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2701 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2695, f32[8,128,768]{2,1,0} %broadcast.54), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2704 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2701), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2679 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2705 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2704, bf16[8,128,768]{2,1,0} %broadcast.2679), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.41 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.19 = bf16[] divide(bf16[] %constant.41, bf16[] %p3.6)
  %broadcast.55 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.19), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.119 = bf16[] constant(0)
  %broadcast.245 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.119), dimensions={}
  %select.20 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2705, bf16[8,128,768]{2,1,0} %broadcast.55, bf16[8,128,768]{2,1,0} %broadcast.245), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2748 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2745, bf16[8,128,768]{2,1,0} %select.20), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2749 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2748, bf16[8,128,768]{2,1,0} %add.2674), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.2750 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2749), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.537 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.541 = bf16[1024]{0} broadcast(bf16[] %constant.537), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.532 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.536 = bf16[1024]{0} broadcast(bf16[] %constant.532), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2751 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2750, bf16[1024]{0} %broadcast.541, bf16[1024]{0} %broadcast.536), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2752 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2751), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2759 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2752), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p19.521 = bf16[768]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2762 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p19.521), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2765 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2759, bf16[8,128,768]{2,1,0} %broadcast.2762), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2767 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2766, bf16[8,128,768]{2,1,0} %multiply.2765), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2900 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2767), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p133.2898 = bf16[768,768]{1,0} parameter(133), frontend_attributes={neff_input_names="input133"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2899 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p133.2898), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2901 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2900, bf16[768,768]{0,1} %transpose.2899), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2902 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2901), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p132.2896 = bf16[768]{0} parameter(132), frontend_attributes={neff_input_names="input132"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2903 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p132.2896), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2904 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2902, bf16[8,128,768]{2,1,0} %broadcast.2903), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2907 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2904), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2908 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2907), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2910 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2908), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2879 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2767), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p131.2877 = bf16[768,768]{1,0} parameter(131), frontend_attributes={neff_input_names="input131"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2878 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p131.2877), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2880 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2879, bf16[768,768]{0,1} %transpose.2878), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2881 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2880), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p130.2875 = bf16[768]{0} parameter(130), frontend_attributes={neff_input_names="input130"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2882 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p130.2875), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2883 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2881, bf16[8,128,768]{2,1,0} %broadcast.2882), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2886 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2883), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.2888 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2886), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.2890 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.2888), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.2911 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.2910, bf16[96,64,128]{2,1,0} %reshape.2890), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.462 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.45 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.2911, bf16[96,128,128]{2,1,0} %broadcast.462), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1248 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.45), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.2917 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.2918 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1248, bf16[8,12,128,128]{3,2,1,0} %broadcast.2917), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.2919 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2924 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.2918, bf16[] %constant.2919), dimensions={3}, to_apply=%MaxComputation.2920, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2925 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2924), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.2926 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.2918, bf16[8,12,128,128]{3,2,1,0} %broadcast.2925), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.2927 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.2926), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.2928 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.2933 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.2927, bf16[] %constant.2928), dimensions={3}, to_apply=%AddComputation.2929, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.2934 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.2933), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.2935 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.2927, bf16[8,12,128,128]{3,2,1,0} %broadcast.2934), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.84 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.85 = s64[] multiply(s64[] %constant.84, s64[] %add.83), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.86 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.87 = s64[] add(s64[] %multiply.85, s64[] %constant.86), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2837 = u64[] convert(s64[] %add.87), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2841 = u64[1]{0} reshape(u64[] %convert.2837), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.295 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2843 = u64[2]{0} concatenate(u64[1]{0} %reshape.2841, u64[1]{0} %constant.295), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2844 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2843), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2845 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.2844), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2847 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2848 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.2847), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2849 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.2845, u32[8,12,128,128]{3,2,1,0} %broadcast.2848), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2850 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.2849), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.300 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.57 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.300), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2856 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.2850, f32[8,12,128,128]{3,2,1,0} %broadcast.57), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2859 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.2856), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2834 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2860 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.2859, bf16[8,12,128,128]{3,2,1,0} %broadcast.2834), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.43 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.20 = bf16[] divide(bf16[] %constant.43, bf16[] %p3.6)
  %broadcast.58 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.20), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.121 = bf16[] constant(0)
  %broadcast.257 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.121), dimensions={}
  %select.21 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.2860, bf16[8,12,128,128]{3,2,1,0} %broadcast.58, bf16[8,12,128,128]{3,2,1,0} %broadcast.257), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2936 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.2935, bf16[8,12,128,128]{3,2,1,0} %select.21), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2938 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.2936), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2820 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2767), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p129.2818 = bf16[768,768]{1,0} parameter(129), frontend_attributes={neff_input_names="input129"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2819 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p129.2818), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2821 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2820, bf16[768,768]{0,1} %transpose.2819), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2822 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2821), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p128.2816 = bf16[768]{0} parameter(128), frontend_attributes={neff_input_names="input128"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2823 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p128.2816), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2824 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2822, bf16[8,128,768]{2,1,0} %broadcast.2823), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2827 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2824), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.2828 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.2827), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2830 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.2828), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.2939 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.2938, bf16[96,128,64]{2,1,0} %reshape.2830), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.2940 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.2939), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2941 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.2940), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2943 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.2941), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p127.2809 = bf16[768,768]{1,0} parameter(127), frontend_attributes={neff_input_names="input127"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.2810 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p127.2809), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.2944 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.2943, bf16[768,768]{0,1} %transpose.2810), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.2945 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.2944), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p126.2807 = bf16[768]{0} parameter(126), frontend_attributes={neff_input_names="input126"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.2946 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p126.2807), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.2947 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.2945, bf16[8,128,768]{2,1,0} %broadcast.2946), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.88 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.89 = s64[] multiply(s64[] %constant.88, s64[] %add.87), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.90 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.91 = s64[] add(s64[] %multiply.89, s64[] %constant.90), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2775 = u64[] convert(s64[] %add.91), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2779 = u64[1]{0} reshape(u64[] %convert.2775), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.301 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2781 = u64[2]{0} concatenate(u64[1]{0} %reshape.2779, u64[1]{0} %constant.301), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2782 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2781), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2783 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2782), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2785 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2786 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2785), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2787 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2783, u32[8,128,768]{2,1,0} %broadcast.2786), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2788 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2787), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.307 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.59 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.307), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2794 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2788, f32[8,128,768]{2,1,0} %broadcast.59), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2797 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2794), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2772 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.2798 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2797, bf16[8,128,768]{2,1,0} %broadcast.2772), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.45 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.21 = bf16[] divide(bf16[] %constant.45, bf16[] %p3.6)
  %broadcast.60 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.21), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.123 = bf16[] constant(0)
  %broadcast.263 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.123), dimensions={}
  %select.22 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.2798, bf16[8,128,768]{2,1,0} %broadcast.60, bf16[8,128,768]{2,1,0} %broadcast.263), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2950 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.2947, bf16[8,128,768]{2,1,0} %select.22), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.2951 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.2950, bf16[8,128,768]{2,1,0} %add.2767), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.2952 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.2951), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.510 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.514 = bf16[1024]{0} broadcast(bf16[] %constant.510), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.505 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.509 = bf16[1024]{0} broadcast(bf16[] %constant.505), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.2953 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.2952, bf16[1024]{0} %broadcast.514, bf16[1024]{0} %broadcast.509), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.2954 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.2953), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.2961 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.2954), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p18.494 = bf16[768]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.2964 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p18.494), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.2967 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.2961, bf16[8,128,768]{2,1,0} %broadcast.2964), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.2969 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.2968, bf16[8,128,768]{2,1,0} %multiply.2967), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3022 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.2969), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p138.3020 = bf16[3072,768]{1,0} parameter(138), frontend_attributes={neff_input_names="input138"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3021 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p138.3020), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3023 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.3022, bf16[768,3072]{0,1} %transpose.3021), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3024 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.3023), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p137.3018 = bf16[3072]{0} parameter(137), frontend_attributes={neff_input_names="input137"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3025 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p137.3018), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3026 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.3024, bf16[8,128,3072]{2,1,0} %broadcast.3025), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.24 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.3026), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.3036 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.24), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p136.3011 = bf16[768,3072]{1,0} parameter(136), frontend_attributes={neff_input_names="input136"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3012 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p136.3011), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3037 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.3036, bf16[3072,768]{0,1} %transpose.3012), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3038 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3037), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p135.3009 = bf16[768]{0} parameter(135), frontend_attributes={neff_input_names="input135"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3039 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p135.3009), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3040 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3038, bf16[8,128,768]{2,1,0} %broadcast.3039), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.92 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.93 = s64[] multiply(s64[] %constant.92, s64[] %add.91), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.94 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.95 = s64[] add(s64[] %multiply.93, s64[] %constant.94), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2977 = u64[] convert(s64[] %add.95), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.2981 = u64[1]{0} reshape(u64[] %convert.2977), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.309 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.2983 = u64[2]{0} concatenate(u64[1]{0} %reshape.2981, u64[1]{0} %constant.309), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.2984 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.2983), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.2985 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.2984), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.2987 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2988 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.2987), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.2989 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.2985, u32[8,128,768]{2,1,0} %broadcast.2988), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2990 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.2989), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.314 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.61 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.314), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.2996 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.2990, f32[8,128,768]{2,1,0} %broadcast.61), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.2999 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.2996), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.2974 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3000 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.2999, bf16[8,128,768]{2,1,0} %broadcast.2974), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.47 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.22 = bf16[] divide(bf16[] %constant.47, bf16[] %p3.6)
  %broadcast.62 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.22), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.125 = bf16[] constant(0)
  %broadcast.275 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.125), dimensions={}
  %select.23 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3000, bf16[8,128,768]{2,1,0} %broadcast.62, bf16[8,128,768]{2,1,0} %broadcast.275), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3043 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3040, bf16[8,128,768]{2,1,0} %select.23), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3044 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3043, bf16[8,128,768]{2,1,0} %add.2969), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.3045 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3044), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.483 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.487 = bf16[1024]{0} broadcast(bf16[] %constant.483), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.478 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.482 = bf16[1024]{0} broadcast(bf16[] %constant.478), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3046 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3045, bf16[1024]{0} %broadcast.487, bf16[1024]{0} %broadcast.482), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3047 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3046), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3054 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3047), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p17.467 = bf16[768]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3057 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p17.467), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3060 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3054, bf16[8,128,768]{2,1,0} %broadcast.3057), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3062 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3061, bf16[8,128,768]{2,1,0} %multiply.3060), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3195 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3062), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p147.3193 = bf16[768,768]{1,0} parameter(147), frontend_attributes={neff_input_names="input147"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3194 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p147.3193), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3196 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3195, bf16[768,768]{0,1} %transpose.3194), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3197 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3196), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p146.3191 = bf16[768]{0} parameter(146), frontend_attributes={neff_input_names="input146"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3198 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p146.3191), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3199 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3197, bf16[8,128,768]{2,1,0} %broadcast.3198), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3202 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3199), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3203 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3202), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3205 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3203), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3174 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3062), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p145.3172 = bf16[768,768]{1,0} parameter(145), frontend_attributes={neff_input_names="input145"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3173 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p145.3172), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3175 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3174, bf16[768,768]{0,1} %transpose.3173), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3176 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3175), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p144.3170 = bf16[768]{0} parameter(144), frontend_attributes={neff_input_names="input144"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3177 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p144.3170), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3178 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3176, bf16[8,128,768]{2,1,0} %broadcast.3177), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3181 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3178), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3183 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3181), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3185 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.3183), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.3206 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.3205, bf16[96,64,128]{2,1,0} %reshape.3185), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.466 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.46 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.3206, bf16[96,128,128]{2,1,0} %broadcast.466), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1251 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.46), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.3212 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.3213 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1251, bf16[8,12,128,128]{3,2,1,0} %broadcast.3212), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.3214 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3219 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.3213, bf16[] %constant.3214), dimensions={3}, to_apply=%MaxComputation.3215, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3220 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3219), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.3221 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.3213, bf16[8,12,128,128]{3,2,1,0} %broadcast.3220), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.3222 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.3221), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.3223 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3228 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.3222, bf16[] %constant.3223), dimensions={3}, to_apply=%AddComputation.3224, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3229 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3228), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.3230 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.3222, bf16[8,12,128,128]{3,2,1,0} %broadcast.3229), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.96 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.97 = s64[] multiply(s64[] %constant.96, s64[] %add.95), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.98 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.99 = s64[] add(s64[] %multiply.97, s64[] %constant.98), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3132 = u64[] convert(s64[] %add.99), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3136 = u64[1]{0} reshape(u64[] %convert.3132), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.317 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3138 = u64[2]{0} concatenate(u64[1]{0} %reshape.3136, u64[1]{0} %constant.317), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3139 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3138), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3140 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.3139), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3142 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3143 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.3142), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3144 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.3140, u32[8,12,128,128]{3,2,1,0} %broadcast.3143), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3145 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.3144), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.322 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.64 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.322), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3151 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.3145, f32[8,12,128,128]{3,2,1,0} %broadcast.64), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3154 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.3151), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3129 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3155 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.3154, bf16[8,12,128,128]{3,2,1,0} %broadcast.3129), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.49 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.23 = bf16[] divide(bf16[] %constant.49, bf16[] %p3.6)
  %broadcast.65 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.23), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.127 = bf16[] constant(0)
  %broadcast.287 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.127), dimensions={}
  %select.24 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.3155, bf16[8,12,128,128]{3,2,1,0} %broadcast.65, bf16[8,12,128,128]{3,2,1,0} %broadcast.287), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3231 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.3230, bf16[8,12,128,128]{3,2,1,0} %select.24), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3233 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.3231), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3115 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3062), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p143.3113 = bf16[768,768]{1,0} parameter(143), frontend_attributes={neff_input_names="input143"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3114 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p143.3113), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3116 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3115, bf16[768,768]{0,1} %transpose.3114), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3117 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3116), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p142.3111 = bf16[768]{0} parameter(142), frontend_attributes={neff_input_names="input142"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3118 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p142.3111), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3119 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3117, bf16[8,128,768]{2,1,0} %broadcast.3118), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3122 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3119), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.3123 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3122), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3125 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3123), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.3234 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.3233, bf16[96,128,64]{2,1,0} %reshape.3125), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3235 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.3234), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3236 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.3235), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3238 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.3236), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p141.3104 = bf16[768,768]{1,0} parameter(141), frontend_attributes={neff_input_names="input141"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3105 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p141.3104), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3239 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3238, bf16[768,768]{0,1} %transpose.3105), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3240 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3239), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p140.3102 = bf16[768]{0} parameter(140), frontend_attributes={neff_input_names="input140"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3241 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p140.3102), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3242 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3240, bf16[8,128,768]{2,1,0} %broadcast.3241), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.100 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.101 = s64[] multiply(s64[] %constant.100, s64[] %add.99), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.102 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.103 = s64[] add(s64[] %multiply.101, s64[] %constant.102), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3070 = u64[] convert(s64[] %add.103), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3074 = u64[1]{0} reshape(u64[] %convert.3070), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.323 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3076 = u64[2]{0} concatenate(u64[1]{0} %reshape.3074, u64[1]{0} %constant.323), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3077 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3076), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3078 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3077), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3080 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3081 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3080), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3082 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3078, u32[8,128,768]{2,1,0} %broadcast.3081), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3083 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3082), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.328 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.66 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.328), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3089 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3083, f32[8,128,768]{2,1,0} %broadcast.66), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3092 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3089), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3067 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3093 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3092, bf16[8,128,768]{2,1,0} %broadcast.3067), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.51 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.24 = bf16[] divide(bf16[] %constant.51, bf16[] %p3.6)
  %broadcast.67 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.24), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.129 = bf16[] constant(0)
  %broadcast.294 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.129), dimensions={}
  %select.25 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3093, bf16[8,128,768]{2,1,0} %broadcast.67, bf16[8,128,768]{2,1,0} %broadcast.294), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3245 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3242, bf16[8,128,768]{2,1,0} %select.25), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3246 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3245, bf16[8,128,768]{2,1,0} %add.3062), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.3247 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3246), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.456 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.460 = bf16[1024]{0} broadcast(bf16[] %constant.456), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.451 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.455 = bf16[1024]{0} broadcast(bf16[] %constant.451), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3248 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3247, bf16[1024]{0} %broadcast.460, bf16[1024]{0} %broadcast.455), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3249 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3248), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3256 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3249), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p16.440 = bf16[768]{0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3259 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p16.440), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3262 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3256, bf16[8,128,768]{2,1,0} %broadcast.3259), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3264 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3263, bf16[8,128,768]{2,1,0} %multiply.3262), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3317 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3264), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p152.3315 = bf16[3072,768]{1,0} parameter(152), frontend_attributes={neff_input_names="input152"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3316 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p152.3315), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3318 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.3317, bf16[768,3072]{0,1} %transpose.3316), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3319 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.3318), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p151.3313 = bf16[3072]{0} parameter(151), frontend_attributes={neff_input_names="input151"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3320 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p151.3313), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3321 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.3319, bf16[8,128,3072]{2,1,0} %broadcast.3320), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.25 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.3321), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.3331 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.25), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p150.3306 = bf16[768,3072]{1,0} parameter(150), frontend_attributes={neff_input_names="input150"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3307 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p150.3306), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3332 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.3331, bf16[3072,768]{0,1} %transpose.3307), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3333 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3332), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p149.3304 = bf16[768]{0} parameter(149), frontend_attributes={neff_input_names="input149"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3334 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p149.3304), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3335 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3333, bf16[8,128,768]{2,1,0} %broadcast.3334), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.104 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.105 = s64[] multiply(s64[] %constant.104, s64[] %add.103), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.106 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.107 = s64[] add(s64[] %multiply.105, s64[] %constant.106), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3272 = u64[] convert(s64[] %add.107), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3276 = u64[1]{0} reshape(u64[] %convert.3272), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.330 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3278 = u64[2]{0} concatenate(u64[1]{0} %reshape.3276, u64[1]{0} %constant.330), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3279 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3278), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3280 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3279), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3282 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3283 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3282), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3284 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3280, u32[8,128,768]{2,1,0} %broadcast.3283), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3285 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3284), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.336 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.68 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.336), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3291 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3285, f32[8,128,768]{2,1,0} %broadcast.68), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3294 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3291), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3269 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3295 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3294, bf16[8,128,768]{2,1,0} %broadcast.3269), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.53 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.25 = bf16[] divide(bf16[] %constant.53, bf16[] %p3.6)
  %broadcast.69 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.25), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.131 = bf16[] constant(0)
  %broadcast.305 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.131), dimensions={}
  %select.26 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3295, bf16[8,128,768]{2,1,0} %broadcast.69, bf16[8,128,768]{2,1,0} %broadcast.305), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3338 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3335, bf16[8,128,768]{2,1,0} %select.26), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3339 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3338, bf16[8,128,768]{2,1,0} %add.3264), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.3340 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3339), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.429 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.433 = bf16[1024]{0} broadcast(bf16[] %constant.429), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.424 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.428 = bf16[1024]{0} broadcast(bf16[] %constant.424), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3341 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3340, bf16[1024]{0} %broadcast.433, bf16[1024]{0} %broadcast.428), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3342 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3341), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3349 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3342), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p15.413 = bf16[768]{0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3352 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p15.413), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3355 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3349, bf16[8,128,768]{2,1,0} %broadcast.3352), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3357 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3356, bf16[8,128,768]{2,1,0} %multiply.3355), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3490 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3357), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p161.3488 = bf16[768,768]{1,0} parameter(161), frontend_attributes={neff_input_names="input161"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3489 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p161.3488), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3491 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3490, bf16[768,768]{0,1} %transpose.3489), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3492 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3491), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p160.3486 = bf16[768]{0} parameter(160), frontend_attributes={neff_input_names="input160"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3493 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p160.3486), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3494 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3492, bf16[8,128,768]{2,1,0} %broadcast.3493), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3497 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3494), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3498 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3497), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3500 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3498), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3469 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3357), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p159.3467 = bf16[768,768]{1,0} parameter(159), frontend_attributes={neff_input_names="input159"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3468 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p159.3467), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3470 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3469, bf16[768,768]{0,1} %transpose.3468), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3471 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3470), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p158.3465 = bf16[768]{0} parameter(158), frontend_attributes={neff_input_names="input158"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3472 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p158.3465), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3473 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3471, bf16[8,128,768]{2,1,0} %broadcast.3472), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3476 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3473), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3478 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3476), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3480 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.3478), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.3501 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.3500, bf16[96,64,128]{2,1,0} %reshape.3480), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.468 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.47 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.3501, bf16[96,128,128]{2,1,0} %broadcast.468), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1256 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.47), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.3507 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.3508 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1256, bf16[8,12,128,128]{3,2,1,0} %broadcast.3507), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.3509 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3514 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.3508, bf16[] %constant.3509), dimensions={3}, to_apply=%MaxComputation.3510, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3515 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3514), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.3516 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.3508, bf16[8,12,128,128]{3,2,1,0} %broadcast.3515), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.3517 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.3516), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.3518 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3523 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.3517, bf16[] %constant.3518), dimensions={3}, to_apply=%AddComputation.3519, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3524 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3523), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.3525 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.3517, bf16[8,12,128,128]{3,2,1,0} %broadcast.3524), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.108 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.109 = s64[] multiply(s64[] %constant.108, s64[] %add.107), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.110 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.111 = s64[] add(s64[] %multiply.109, s64[] %constant.110), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3427 = u64[] convert(s64[] %add.111), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3431 = u64[1]{0} reshape(u64[] %convert.3427), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.339 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3433 = u64[2]{0} concatenate(u64[1]{0} %reshape.3431, u64[1]{0} %constant.339), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3434 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3433), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3435 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.3434), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3437 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3438 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.3437), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3439 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.3435, u32[8,12,128,128]{3,2,1,0} %broadcast.3438), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3440 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.3439), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.344 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.71 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.344), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3446 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.3440, f32[8,12,128,128]{3,2,1,0} %broadcast.71), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3449 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.3446), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3424 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3450 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.3449, bf16[8,12,128,128]{3,2,1,0} %broadcast.3424), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.55 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.26 = bf16[] divide(bf16[] %constant.55, bf16[] %p3.6)
  %broadcast.72 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.26), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.133 = bf16[] constant(0)
  %broadcast.317 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.133), dimensions={}
  %select.27 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.3450, bf16[8,12,128,128]{3,2,1,0} %broadcast.72, bf16[8,12,128,128]{3,2,1,0} %broadcast.317), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3526 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.3525, bf16[8,12,128,128]{3,2,1,0} %select.27), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3528 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.3526), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3410 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3357), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p157.3408 = bf16[768,768]{1,0} parameter(157), frontend_attributes={neff_input_names="input157"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3409 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p157.3408), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3411 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3410, bf16[768,768]{0,1} %transpose.3409), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3412 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3411), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p156.3406 = bf16[768]{0} parameter(156), frontend_attributes={neff_input_names="input156"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3413 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p156.3406), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3414 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3412, bf16[8,128,768]{2,1,0} %broadcast.3413), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3417 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3414), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.3418 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3417), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3420 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3418), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.3529 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.3528, bf16[96,128,64]{2,1,0} %reshape.3420), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3530 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.3529), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3531 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.3530), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3533 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.3531), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p155.3399 = bf16[768,768]{1,0} parameter(155), frontend_attributes={neff_input_names="input155"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3400 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p155.3399), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3534 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3533, bf16[768,768]{0,1} %transpose.3400), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3535 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3534), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p154.3397 = bf16[768]{0} parameter(154), frontend_attributes={neff_input_names="input154"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3536 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p154.3397), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3537 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3535, bf16[8,128,768]{2,1,0} %broadcast.3536), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.112 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.113 = s64[] multiply(s64[] %constant.112, s64[] %add.111), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.114 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.115 = s64[] add(s64[] %multiply.113, s64[] %constant.114), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3365 = u64[] convert(s64[] %add.115), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3369 = u64[1]{0} reshape(u64[] %convert.3365), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.345 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3371 = u64[2]{0} concatenate(u64[1]{0} %reshape.3369, u64[1]{0} %constant.345), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3372 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3371), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3373 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3372), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3375 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3376 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3375), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3377 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3373, u32[8,128,768]{2,1,0} %broadcast.3376), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3378 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3377), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.350 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.73 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.350), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3384 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3378, f32[8,128,768]{2,1,0} %broadcast.73), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3387 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3384), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3362 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3388 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3387, bf16[8,128,768]{2,1,0} %broadcast.3362), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.57 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.27 = bf16[] divide(bf16[] %constant.57, bf16[] %p3.6)
  %broadcast.74 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.27), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.135 = bf16[] constant(0)
  %broadcast.324 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.135), dimensions={}
  %select.28 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3388, bf16[8,128,768]{2,1,0} %broadcast.74, bf16[8,128,768]{2,1,0} %broadcast.324), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3540 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3537, bf16[8,128,768]{2,1,0} %select.28), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3541 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3540, bf16[8,128,768]{2,1,0} %add.3357), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.3542 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3541), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.402 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.406 = bf16[1024]{0} broadcast(bf16[] %constant.402), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.397 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.401 = bf16[1024]{0} broadcast(bf16[] %constant.397), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3543 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3542, bf16[1024]{0} %broadcast.406, bf16[1024]{0} %broadcast.401), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3544 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3543), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3551 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3544), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p14.386 = bf16[768]{0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3554 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p14.386), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3557 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3551, bf16[8,128,768]{2,1,0} %broadcast.3554), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3559 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3558, bf16[8,128,768]{2,1,0} %multiply.3557), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3612 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3559), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p166.3610 = bf16[3072,768]{1,0} parameter(166), frontend_attributes={neff_input_names="input166"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3611 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p166.3610), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3613 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.3612, bf16[768,3072]{0,1} %transpose.3611), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3614 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.3613), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p165.3608 = bf16[3072]{0} parameter(165), frontend_attributes={neff_input_names="input165"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3615 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p165.3608), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3616 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.3614, bf16[8,128,3072]{2,1,0} %broadcast.3615), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.26 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.3616), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.3626 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.26), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p164.3601 = bf16[768,3072]{1,0} parameter(164), frontend_attributes={neff_input_names="input164"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3602 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p164.3601), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3627 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.3626, bf16[3072,768]{0,1} %transpose.3602), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3628 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3627), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p163.3599 = bf16[768]{0} parameter(163), frontend_attributes={neff_input_names="input163"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3629 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p163.3599), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3630 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3628, bf16[8,128,768]{2,1,0} %broadcast.3629), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.116 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.117 = s64[] multiply(s64[] %constant.116, s64[] %add.115), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.118 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.119 = s64[] add(s64[] %multiply.117, s64[] %constant.118), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3567 = u64[] convert(s64[] %add.119), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3571 = u64[1]{0} reshape(u64[] %convert.3567), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.352 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3573 = u64[2]{0} concatenate(u64[1]{0} %reshape.3571, u64[1]{0} %constant.352), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3574 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3573), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3575 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3574), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3577 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3578 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3577), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3579 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3575, u32[8,128,768]{2,1,0} %broadcast.3578), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3580 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3579), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.357 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.75 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.357), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3586 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3580, f32[8,128,768]{2,1,0} %broadcast.75), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3589 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3586), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3564 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3590 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3589, bf16[8,128,768]{2,1,0} %broadcast.3564), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.59 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.28 = bf16[] divide(bf16[] %constant.59, bf16[] %p3.6)
  %broadcast.76 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.28), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.137 = bf16[] constant(0)
  %broadcast.334 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.137), dimensions={}
  %select.29 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3590, bf16[8,128,768]{2,1,0} %broadcast.76, bf16[8,128,768]{2,1,0} %broadcast.334), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3633 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3630, bf16[8,128,768]{2,1,0} %select.29), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3634 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3633, bf16[8,128,768]{2,1,0} %add.3559), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.3635 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3634), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.375 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.379 = bf16[1024]{0} broadcast(bf16[] %constant.375), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.370 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.374 = bf16[1024]{0} broadcast(bf16[] %constant.370), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3636 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3635, bf16[1024]{0} %broadcast.379, bf16[1024]{0} %broadcast.374), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3637 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3636), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3644 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3637), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p13.359 = bf16[768]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3647 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p13.359), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3650 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3644, bf16[8,128,768]{2,1,0} %broadcast.3647), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3652 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3651, bf16[8,128,768]{2,1,0} %multiply.3650), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3785 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3652), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p175.3783 = bf16[768,768]{1,0} parameter(175), frontend_attributes={neff_input_names="input175"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3784 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p175.3783), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3786 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3785, bf16[768,768]{0,1} %transpose.3784), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3787 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3786), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p174.3781 = bf16[768]{0} parameter(174), frontend_attributes={neff_input_names="input174"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3788 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p174.3781), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3789 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3787, bf16[8,128,768]{2,1,0} %broadcast.3788), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3792 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3789), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3793 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3792), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3795 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3793), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3764 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3652), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p173.3762 = bf16[768,768]{1,0} parameter(173), frontend_attributes={neff_input_names="input173"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3763 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p173.3762), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3765 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3764, bf16[768,768]{0,1} %transpose.3763), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3766 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3765), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p172.3760 = bf16[768]{0} parameter(172), frontend_attributes={neff_input_names="input172"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3767 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p172.3760), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3768 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3766, bf16[8,128,768]{2,1,0} %broadcast.3767), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3771 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3768), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.3773 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3771), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.3775 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.3773), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.3796 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.3795, bf16[96,64,128]{2,1,0} %reshape.3775), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.471 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.48 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.3796, bf16[96,128,128]{2,1,0} %broadcast.471), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1261 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.48), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.3802 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.3803 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1261, bf16[8,12,128,128]{3,2,1,0} %broadcast.3802), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.3804 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3809 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.3803, bf16[] %constant.3804), dimensions={3}, to_apply=%MaxComputation.3805, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3810 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3809), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.3811 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.3803, bf16[8,12,128,128]{3,2,1,0} %broadcast.3810), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.3812 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.3811), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.3813 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.3818 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.3812, bf16[] %constant.3813), dimensions={3}, to_apply=%AddComputation.3814, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.3819 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.3818), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.3820 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.3812, bf16[8,12,128,128]{3,2,1,0} %broadcast.3819), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.120 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.121 = s64[] multiply(s64[] %constant.120, s64[] %add.119), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.122 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.123 = s64[] add(s64[] %multiply.121, s64[] %constant.122), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3722 = u64[] convert(s64[] %add.123), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3726 = u64[1]{0} reshape(u64[] %convert.3722), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.361 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3728 = u64[2]{0} concatenate(u64[1]{0} %reshape.3726, u64[1]{0} %constant.361), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3729 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3728), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3730 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.3729), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3732 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3733 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.3732), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3734 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.3730, u32[8,12,128,128]{3,2,1,0} %broadcast.3733), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3735 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.3734), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.366 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.78 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.366), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3741 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.3735, f32[8,12,128,128]{3,2,1,0} %broadcast.78), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3744 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.3741), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3719 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3745 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.3744, bf16[8,12,128,128]{3,2,1,0} %broadcast.3719), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.61 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.29 = bf16[] divide(bf16[] %constant.61, bf16[] %p3.6)
  %broadcast.79 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.29), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.139 = bf16[] constant(0)
  %broadcast.348 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.139), dimensions={}
  %select.30 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.3745, bf16[8,12,128,128]{3,2,1,0} %broadcast.79, bf16[8,12,128,128]{3,2,1,0} %broadcast.348), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3821 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.3820, bf16[8,12,128,128]{3,2,1,0} %select.30), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3823 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.3821), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3705 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3652), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p171.3703 = bf16[768,768]{1,0} parameter(171), frontend_attributes={neff_input_names="input171"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3704 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p171.3703), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3706 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3705, bf16[768,768]{0,1} %transpose.3704), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3707 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3706), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p170.3701 = bf16[768]{0} parameter(170), frontend_attributes={neff_input_names="input170"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3708 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p170.3701), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3709 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3707, bf16[8,128,768]{2,1,0} %broadcast.3708), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3712 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3709), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.3713 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.3712), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3715 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.3713), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.3824 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.3823, bf16[96,128,64]{2,1,0} %reshape.3715), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.3825 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.3824), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3826 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.3825), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3828 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.3826), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p169.3694 = bf16[768,768]{1,0} parameter(169), frontend_attributes={neff_input_names="input169"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3695 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p169.3694), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3829 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.3828, bf16[768,768]{0,1} %transpose.3695), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3830 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3829), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p168.3692 = bf16[768]{0} parameter(168), frontend_attributes={neff_input_names="input168"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3831 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p168.3692), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3832 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3830, bf16[8,128,768]{2,1,0} %broadcast.3831), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.124 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.125 = s64[] multiply(s64[] %constant.124, s64[] %add.123), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.126 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.127 = s64[] add(s64[] %multiply.125, s64[] %constant.126), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3660 = u64[] convert(s64[] %add.127), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3664 = u64[1]{0} reshape(u64[] %convert.3660), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.367 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3666 = u64[2]{0} concatenate(u64[1]{0} %reshape.3664, u64[1]{0} %constant.367), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3667 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3666), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3668 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3667), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3670 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3671 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3670), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3672 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3668, u32[8,128,768]{2,1,0} %broadcast.3671), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3673 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3672), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.372 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.80 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.372), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3679 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3673, f32[8,128,768]{2,1,0} %broadcast.80), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3682 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3679), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3657 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3683 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3682, bf16[8,128,768]{2,1,0} %broadcast.3657), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.63 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.30 = bf16[] divide(bf16[] %constant.63, bf16[] %p3.6)
  %broadcast.81 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.30), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.141 = bf16[] constant(0)
  %broadcast.354 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.141), dimensions={}
  %select.31 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3683, bf16[8,128,768]{2,1,0} %broadcast.81, bf16[8,128,768]{2,1,0} %broadcast.354), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3835 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3832, bf16[8,128,768]{2,1,0} %select.31), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3836 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3835, bf16[8,128,768]{2,1,0} %add.3652), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.3837 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3836), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.348 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.352 = bf16[1024]{0} broadcast(bf16[] %constant.348), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.343 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.347 = bf16[1024]{0} broadcast(bf16[] %constant.343), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3838 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3837, bf16[1024]{0} %broadcast.352, bf16[1024]{0} %broadcast.347), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3839 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3838), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3846 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3839), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p12.332 = bf16[768]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3849 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p12.332), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3852 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3846, bf16[8,128,768]{2,1,0} %broadcast.3849), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3854 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3853, bf16[8,128,768]{2,1,0} %multiply.3852), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3907 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3854), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p180.3905 = bf16[3072,768]{1,0} parameter(180), frontend_attributes={neff_input_names="input180"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3906 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p180.3905), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3908 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.3907, bf16[768,3072]{0,1} %transpose.3906), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3909 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.3908), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p179.3903 = bf16[3072]{0} parameter(179), frontend_attributes={neff_input_names="input179"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3910 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p179.3903), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3911 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.3909, bf16[8,128,3072]{2,1,0} %broadcast.3910), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.27 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.3911), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.3921 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.27), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p178.3896 = bf16[768,3072]{1,0} parameter(178), frontend_attributes={neff_input_names="input178"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3897 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p178.3896), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.3922 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.3921, bf16[3072,768]{0,1} %transpose.3897), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.3923 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.3922), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p177.3894 = bf16[768]{0} parameter(177), frontend_attributes={neff_input_names="input177"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.3924 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p177.3894), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.3925 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.3923, bf16[8,128,768]{2,1,0} %broadcast.3924), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.128 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.129 = s64[] multiply(s64[] %constant.128, s64[] %add.127), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.130 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.131 = s64[] add(s64[] %multiply.129, s64[] %constant.130), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3862 = u64[] convert(s64[] %add.131), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3866 = u64[1]{0} reshape(u64[] %convert.3862), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.374 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3868 = u64[2]{0} concatenate(u64[1]{0} %reshape.3866, u64[1]{0} %constant.374), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3869 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3868), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3870 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3869), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3872 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3873 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3872), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3874 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3870, u32[8,128,768]{2,1,0} %broadcast.3873), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3875 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3874), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.379 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.82 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.379), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3881 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3875, f32[8,128,768]{2,1,0} %broadcast.82), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3884 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3881), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3859 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3885 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3884, bf16[8,128,768]{2,1,0} %broadcast.3859), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.65 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.31 = bf16[] divide(bf16[] %constant.65, bf16[] %p3.6)
  %broadcast.83 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.31), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.143 = bf16[] constant(0)
  %broadcast.365 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.143), dimensions={}
  %select.32 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3885, bf16[8,128,768]{2,1,0} %broadcast.83, bf16[8,128,768]{2,1,0} %broadcast.365), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3928 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.3925, bf16[8,128,768]{2,1,0} %select.32), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.3929 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.3928, bf16[8,128,768]{2,1,0} %add.3854), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.3930 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.3929), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.321 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.325 = bf16[1024]{0} broadcast(bf16[] %constant.321), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.316 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.320 = bf16[1024]{0} broadcast(bf16[] %constant.316), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.3931 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.3930, bf16[1024]{0} %broadcast.325, bf16[1024]{0} %broadcast.320), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.3932 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.3931), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.3939 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.3932), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p11.305 = bf16[768]{0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.3942 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p11.305), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.3945 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.3939, bf16[8,128,768]{2,1,0} %broadcast.3942), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.3947 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.3946, bf16[8,128,768]{2,1,0} %multiply.3945), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4080 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3947), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p189.4078 = bf16[768,768]{1,0} parameter(189), frontend_attributes={neff_input_names="input189"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4079 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p189.4078), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4081 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4080, bf16[768,768]{0,1} %transpose.4079), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4082 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4081), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p188.4076 = bf16[768]{0} parameter(188), frontend_attributes={neff_input_names="input188"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4083 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p188.4076), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4084 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4082, bf16[8,128,768]{2,1,0} %broadcast.4083), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4087 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4084), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.4088 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4087), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4090 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.4088), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4059 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3947), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p187.4057 = bf16[768,768]{1,0} parameter(187), frontend_attributes={neff_input_names="input187"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4058 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p187.4057), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4060 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4059, bf16[768,768]{0,1} %transpose.4058), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4061 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4060), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p186.4055 = bf16[768]{0} parameter(186), frontend_attributes={neff_input_names="input186"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4062 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p186.4055), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4063 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4061, bf16[8,128,768]{2,1,0} %broadcast.4062), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4066 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4063), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.4068 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4066), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4070 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.4068), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.4091 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.4090, bf16[96,64,128]{2,1,0} %reshape.4070), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.474 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.49 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.4091, bf16[96,128,128]{2,1,0} %broadcast.474), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1264 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.49), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.4097 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.4098 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1264, bf16[8,12,128,128]{3,2,1,0} %broadcast.4097), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.4099 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.4104 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.4098, bf16[] %constant.4099), dimensions={3}, to_apply=%MaxComputation.4100, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.4105 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.4104), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.4106 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.4098, bf16[8,12,128,128]{3,2,1,0} %broadcast.4105), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.4107 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.4106), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.4108 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.4113 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.4107, bf16[] %constant.4108), dimensions={3}, to_apply=%AddComputation.4109, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.4114 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.4113), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.4115 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.4107, bf16[8,12,128,128]{3,2,1,0} %broadcast.4114), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.132 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.133 = s64[] multiply(s64[] %constant.132, s64[] %add.131), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.134 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.135 = s64[] add(s64[] %multiply.133, s64[] %constant.134), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4017 = u64[] convert(s64[] %add.135), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4021 = u64[1]{0} reshape(u64[] %convert.4017), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.382 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.4023 = u64[2]{0} concatenate(u64[1]{0} %reshape.4021, u64[1]{0} %constant.382), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.4024 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.4023), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.4025 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.4024), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.4027 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4028 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.4027), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.4029 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.4025, u32[8,12,128,128]{3,2,1,0} %broadcast.4028), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4030 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.4029), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.388 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.85 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.388), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4036 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.4030, f32[8,12,128,128]{3,2,1,0} %broadcast.85), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4039 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.4036), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4014 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.4040 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.4039, bf16[8,12,128,128]{3,2,1,0} %broadcast.4014), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.67 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.32 = bf16[] divide(bf16[] %constant.67, bf16[] %p3.6)
  %broadcast.86 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.32), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.145 = bf16[] constant(0)
  %broadcast.378 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.145), dimensions={}
  %select.33 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.4040, bf16[8,12,128,128]{3,2,1,0} %broadcast.86, bf16[8,12,128,128]{3,2,1,0} %broadcast.378), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4116 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.4115, bf16[8,12,128,128]{3,2,1,0} %select.33), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4118 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.4116), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4000 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.3947), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p185.3998 = bf16[768,768]{1,0} parameter(185), frontend_attributes={neff_input_names="input185"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3999 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p185.3998), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4001 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4000, bf16[768,768]{0,1} %transpose.3999), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4002 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4001), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p184.3996 = bf16[768]{0} parameter(184), frontend_attributes={neff_input_names="input184"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4003 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p184.3996), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4004 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4002, bf16[8,128,768]{2,1,0} %broadcast.4003), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4007 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4004), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.4008 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4007), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4010 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.4008), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.4119 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.4118, bf16[96,128,64]{2,1,0} %reshape.4010), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4120 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.4119), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4121 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.4120), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4123 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.4121), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p183.3989 = bf16[768,768]{1,0} parameter(183), frontend_attributes={neff_input_names="input183"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.3990 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p183.3989), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4124 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4123, bf16[768,768]{0,1} %transpose.3990), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4125 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4124), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p182.3987 = bf16[768]{0} parameter(182), frontend_attributes={neff_input_names="input182"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4126 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p182.3987), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4127 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4125, bf16[8,128,768]{2,1,0} %broadcast.4126), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.136 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.137 = s64[] multiply(s64[] %constant.136, s64[] %add.135), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.138 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.139 = s64[] add(s64[] %multiply.137, s64[] %constant.138), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3955 = u64[] convert(s64[] %add.139), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.3959 = u64[1]{0} reshape(u64[] %convert.3955), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.389 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.3961 = u64[2]{0} concatenate(u64[1]{0} %reshape.3959, u64[1]{0} %constant.389), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.3962 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.3961), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.3963 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.3962), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.3965 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3966 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.3965), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.3967 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.3963, u32[8,128,768]{2,1,0} %broadcast.3966), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3968 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.3967), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.394 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.87 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.394), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.3974 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.3968, f32[8,128,768]{2,1,0} %broadcast.87), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.3977 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.3974), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.3952 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.3978 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.3977, bf16[8,128,768]{2,1,0} %broadcast.3952), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.69 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.33 = bf16[] divide(bf16[] %constant.69, bf16[] %p3.6)
  %broadcast.88 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.33), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.147 = bf16[] constant(0)
  %broadcast.385 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.147), dimensions={}
  %select.34 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.3978, bf16[8,128,768]{2,1,0} %broadcast.88, bf16[8,128,768]{2,1,0} %broadcast.385), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4130 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.4127, bf16[8,128,768]{2,1,0} %select.34), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.4131 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.4130, bf16[8,128,768]{2,1,0} %add.3947), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.4132 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4131), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.294 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.298 = bf16[1024]{0} broadcast(bf16[] %constant.294), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.289 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.293 = bf16[1024]{0} broadcast(bf16[] %constant.289), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.4133 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.4132, bf16[1024]{0} %broadcast.298, bf16[1024]{0} %broadcast.293), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.4134 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.4133), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4141 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.4134), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p10.278 = bf16[768]{0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4144 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p10.278), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.4147 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.4141, bf16[8,128,768]{2,1,0} %broadcast.4144), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.4149 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.4148, bf16[8,128,768]{2,1,0} %multiply.4147), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4202 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.4149), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p194.4200 = bf16[3072,768]{1,0} parameter(194), frontend_attributes={neff_input_names="input194"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4201 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p194.4200), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4203 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.4202, bf16[768,3072]{0,1} %transpose.4201), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4204 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.4203), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p193.4198 = bf16[3072]{0} parameter(193), frontend_attributes={neff_input_names="input193"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4205 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p193.4198), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4206 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.4204, bf16[8,128,3072]{2,1,0} %broadcast.4205), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.28 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.4206), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.4216 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.28), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p192.4191 = bf16[768,3072]{1,0} parameter(192), frontend_attributes={neff_input_names="input192"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4192 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p192.4191), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4217 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.4216, bf16[3072,768]{0,1} %transpose.4192), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4218 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4217), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p191.4189 = bf16[768]{0} parameter(191), frontend_attributes={neff_input_names="input191"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4219 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p191.4189), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4220 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4218, bf16[8,128,768]{2,1,0} %broadcast.4219), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.140 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.141 = s64[] multiply(s64[] %constant.140, s64[] %add.139), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.142 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.143 = s64[] add(s64[] %multiply.141, s64[] %constant.142), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4157 = u64[] convert(s64[] %add.143), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4161 = u64[1]{0} reshape(u64[] %convert.4157), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.396 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.4163 = u64[2]{0} concatenate(u64[1]{0} %reshape.4161, u64[1]{0} %constant.396), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.4164 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.4163), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.4165 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.4164), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.4167 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4168 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.4167), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.4169 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.4165, u32[8,128,768]{2,1,0} %broadcast.4168), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4170 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.4169), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.401 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.89 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.401), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4176 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.4170, f32[8,128,768]{2,1,0} %broadcast.89), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4179 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.4176), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4154 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.4180 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.4179, bf16[8,128,768]{2,1,0} %broadcast.4154), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.71 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.34 = bf16[] divide(bf16[] %constant.71, bf16[] %p3.6)
  %broadcast.90 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.34), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.149 = bf16[] constant(0)
  %broadcast.395 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.149), dimensions={}
  %select.35 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.4180, bf16[8,128,768]{2,1,0} %broadcast.90, bf16[8,128,768]{2,1,0} %broadcast.395), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4223 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.4220, bf16[8,128,768]{2,1,0} %select.35), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.4224 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.4223, bf16[8,128,768]{2,1,0} %add.4149), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.4225 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4224), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.267 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.271 = bf16[1024]{0} broadcast(bf16[] %constant.267), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.262 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.266 = bf16[1024]{0} broadcast(bf16[] %constant.262), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.4226 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.4225, bf16[1024]{0} %broadcast.271, bf16[1024]{0} %broadcast.266), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.4227 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.4226), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4234 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.4227), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p9.251 = bf16[768]{0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4237 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p9.251), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.4240 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.4234, bf16[8,128,768]{2,1,0} %broadcast.4237), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.4242 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.4241, bf16[8,128,768]{2,1,0} %multiply.4240), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4375 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.4242), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p203.4373 = bf16[768,768]{1,0} parameter(203), frontend_attributes={neff_input_names="input203"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4374 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p203.4373), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4376 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4375, bf16[768,768]{0,1} %transpose.4374), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4377 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4376), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p202.4371 = bf16[768]{0} parameter(202), frontend_attributes={neff_input_names="input202"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4378 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p202.4371), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4379 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4377, bf16[8,128,768]{2,1,0} %broadcast.4378), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4382 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4379), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.4383 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4382), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4385 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.4383), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4354 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.4242), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p201.4352 = bf16[768,768]{1,0} parameter(201), frontend_attributes={neff_input_names="input201"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4353 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p201.4352), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4355 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4354, bf16[768,768]{0,1} %transpose.4353), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4356 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4355), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p200.4350 = bf16[768]{0} parameter(200), frontend_attributes={neff_input_names="input200"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4357 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p200.4350), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4358 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4356, bf16[8,128,768]{2,1,0} %broadcast.4357), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4361 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4358), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %transpose.4363 = bf16[8,12,64,128]{2,1,3,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4361), dimensions={0,2,3,1}, metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %reshape.4365 = bf16[96,64,128]{2,1,0} reshape(bf16[8,12,64,128]{2,1,3,0} %transpose.4363), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %dot.4386 = bf16[96,128,128]{2,1,0} dot(bf16[96,128,64]{2,1,0} %reshape.4385, bf16[96,64,128]{2,1,0} %reshape.4365), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=323}
  %broadcast.478 = bf16[96,128,128]{2,1,0} broadcast(bf16[] %p45.1099), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %divide.50 = bf16[96,128,128]{2,1,0} divide(bf16[96,128,128]{2,1,0} %dot.4386, bf16[96,128,128]{2,1,0} %broadcast.478), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %reshape.1269 = bf16[8,12,128,128]{3,2,1,0} reshape(bf16[96,128,128]{2,1,0} %divide.50), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=347}
  %broadcast.4392 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,128]{1,0} %multiply.152), dimensions={0,3}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %add.4393 = bf16[8,12,128,128]{3,2,1,0} add(bf16[8,12,128,128]{3,2,1,0} %reshape.1269, bf16[8,12,128,128]{3,2,1,0} %broadcast.4392), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=350}
  %constant.4394 = bf16[] constant(-inf), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.4399 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %add.4393, bf16[] %constant.4394), dimensions={3}, to_apply=%MaxComputation.4395, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.4400 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.4399), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %subtract.4401 = bf16[8,12,128,128]{3,2,1,0} subtract(bf16[8,12,128,128]{3,2,1,0} %add.4393, bf16[8,12,128,128]{3,2,1,0} %broadcast.4400), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %exponential.4402 = bf16[8,12,128,128]{3,2,1,0} exponential(bf16[8,12,128,128]{3,2,1,0} %subtract.4401), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.4403 = bf16[] constant(0), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %reduce.4408 = bf16[8,12,128]{2,1,0} reduce(bf16[8,12,128,128]{3,2,1,0} %exponential.4402, bf16[] %constant.4403), dimensions={3}, to_apply=%AddComputation.4404, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %broadcast.4409 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[8,12,128]{2,1,0} %reduce.4408), dimensions={0,1,2}, metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %divide.4410 = bf16[8,12,128,128]{3,2,1,0} divide(bf16[8,12,128,128]{3,2,1,0} %exponential.4402, bf16[8,12,128,128]{3,2,1,0} %broadcast.4409), metadata={op_type="aten__softmax" op_name="aten__softmax" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1856}
  %constant.144 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.145 = s64[] multiply(s64[] %constant.144, s64[] %add.143), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.146 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.147 = s64[] add(s64[] %multiply.145, s64[] %constant.146), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4312 = u64[] convert(s64[] %add.147), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4316 = u64[1]{0} reshape(u64[] %convert.4312), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.404 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.4318 = u64[2]{0} concatenate(u64[1]{0} %reshape.4316, u64[1]{0} %constant.404), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.4319 = (u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.4318), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.4320 = u32[8,12,128,128]{3,2,1,0} get-tuple-element((u64[2]{0}, u32[8,12,128,128]{3,2,1,0}) %rng-bit-generator.4319), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.4322 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4323 = u32[8,12,128,128]{3,2,1,0} broadcast(u32[] %constant.4322), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.4324 = u32[8,12,128,128]{3,2,1,0} shift-right-logical(u32[8,12,128,128]{3,2,1,0} %get-tuple-element.4320, u32[8,12,128,128]{3,2,1,0} %broadcast.4323), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4325 = f32[8,12,128,128]{3,2,1,0} convert(u32[8,12,128,128]{3,2,1,0} %shift-right-logical.4324), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.409 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.92 = f32[8,12,128,128]{3,2,1,0} broadcast(f32[] %constant.409), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4331 = f32[8,12,128,128]{3,2,1,0} multiply(f32[8,12,128,128]{3,2,1,0} %convert.4325, f32[8,12,128,128]{3,2,1,0} %broadcast.92), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4334 = bf16[8,12,128,128]{3,2,1,0} convert(f32[8,12,128,128]{3,2,1,0} %multiply.4331), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4309 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.4335 = pred[8,12,128,128]{3,2,1,0} compare(bf16[8,12,128,128]{3,2,1,0} %convert.4334, bf16[8,12,128,128]{3,2,1,0} %broadcast.4309), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.73 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.35 = bf16[] divide(bf16[] %constant.73, bf16[] %p3.6)
  %broadcast.93 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %divide.35), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.151 = bf16[] constant(0)
  %broadcast.408 = bf16[8,12,128,128]{3,2,1,0} broadcast(bf16[] %constant.151), dimensions={}
  %select.36 = bf16[8,12,128,128]{3,2,1,0} select(pred[8,12,128,128]{3,2,1,0} %compare.4335, bf16[8,12,128,128]{3,2,1,0} %broadcast.93, bf16[8,12,128,128]{3,2,1,0} %broadcast.408), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4411 = bf16[8,12,128,128]{3,2,1,0} multiply(bf16[8,12,128,128]{3,2,1,0} %divide.4410, bf16[8,12,128,128]{3,2,1,0} %select.36), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4413 = bf16[96,128,128]{2,1,0} reshape(bf16[8,12,128,128]{3,2,1,0} %multiply.4411), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4295 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.4242), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p199.4293 = bf16[768,768]{1,0} parameter(199), frontend_attributes={neff_input_names="input199"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4294 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p199.4293), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4296 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4295, bf16[768,768]{0,1} %transpose.4294), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4297 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4296), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p198.4291 = bf16[768]{0} parameter(198), frontend_attributes={neff_input_names="input198"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4298 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p198.4291), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4299 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4297, bf16[8,128,768]{2,1,0} %broadcast.4298), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4302 = bf16[8,128,12,64]{3,2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4299), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %transpose.4303 = bf16[8,12,128,64]{3,1,2,0} transpose(bf16[8,128,12,64]{3,2,1,0} %reshape.4302), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4305 = bf16[96,128,64]{2,1,0} reshape(bf16[8,12,128,64]{3,1,2,0} %transpose.4303), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %dot.4414 = bf16[96,128,64]{2,1,0} dot(bf16[96,128,128]{2,1,0} %reshape.4413, bf16[96,128,64]{2,1,0} %reshape.4305), lhs_batch_dims={0}, lhs_contracting_dims={2}, rhs_batch_dims={0}, rhs_contracting_dims={1}, metadata={op_type="aten__matmul" op_name="aten__matmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=363}
  %reshape.4415 = bf16[8,12,128,64]{3,2,1,0} reshape(bf16[96,128,64]{2,1,0} %dot.4414), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4416 = bf16[8,128,12,64]{3,1,2,0} transpose(bf16[8,12,128,64]{3,2,1,0} %reshape.4415), dimensions={0,2,1,3}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4418 = bf16[1024,768]{1,0} reshape(bf16[8,128,12,64]{3,1,2,0} %transpose.4416), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p197.4284 = bf16[768,768]{1,0} parameter(197), frontend_attributes={neff_input_names="input197"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4285 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p197.4284), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4419 = bf16[1024,768]{1,0} dot(bf16[1024,768]{1,0} %reshape.4418, bf16[768,768]{0,1} %transpose.4285), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4420 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4419), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p196.4282 = bf16[768]{0} parameter(196), frontend_attributes={neff_input_names="input196"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4421 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p196.4282), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4422 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4420, bf16[8,128,768]{2,1,0} %broadcast.4421), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.148 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.149 = s64[] multiply(s64[] %constant.148, s64[] %add.147), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.150 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.151 = s64[] add(s64[] %multiply.149, s64[] %constant.150), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4250 = u64[] convert(s64[] %add.151), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4254 = u64[1]{0} reshape(u64[] %convert.4250), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.410 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.4256 = u64[2]{0} concatenate(u64[1]{0} %reshape.4254, u64[1]{0} %constant.410), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.4257 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.4256), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.4258 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.4257), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.4260 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4261 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.4260), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.4262 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.4258, u32[8,128,768]{2,1,0} %broadcast.4261), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4263 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.4262), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.416 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.94 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.416), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4269 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.4263, f32[8,128,768]{2,1,0} %broadcast.94), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4272 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.4269), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4247 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.4273 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.4272, bf16[8,128,768]{2,1,0} %broadcast.4247), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.75 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.36 = bf16[] divide(bf16[] %constant.75, bf16[] %p3.6)
  %broadcast.95 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.36), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.153 = bf16[] constant(0)
  %broadcast.414 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.153), dimensions={}
  %select.37 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.4273, bf16[8,128,768]{2,1,0} %broadcast.95, bf16[8,128,768]{2,1,0} %broadcast.414), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4425 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.4422, bf16[8,128,768]{2,1,0} %select.37), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.4426 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.4425, bf16[8,128,768]{2,1,0} %add.4242), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=386}
  %reshape.4427 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4426), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.240 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.244 = bf16[1024]{0} broadcast(bf16[] %constant.240), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.235 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.239 = bf16[1024]{0} broadcast(bf16[] %constant.235), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.4428 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.4427, bf16[1024]{0} %broadcast.244, bf16[1024]{0} %broadcast.239), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.4429 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.4428), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4436 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.4429), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p8.224 = bf16[768]{0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4439 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p8.224), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.4442 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.4436, bf16[8,128,768]{2,1,0} %broadcast.4439), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.4444 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.4443, bf16[8,128,768]{2,1,0} %multiply.4442), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4497 = bf16[1024,768]{1,0} reshape(bf16[8,128,768]{2,1,0} %add.4444), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p208.4495 = bf16[3072,768]{1,0} parameter(208), frontend_attributes={neff_input_names="input208"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4496 = bf16[768,3072]{0,1} transpose(bf16[3072,768]{1,0} %p208.4495), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4498 = bf16[1024,3072]{1,0} dot(bf16[1024,768]{1,0} %reshape.4497, bf16[768,3072]{0,1} %transpose.4496), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4499 = bf16[8,128,3072]{2,1,0} reshape(bf16[1024,3072]{1,0} %dot.4498), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p207.4493 = bf16[3072]{0} parameter(207), frontend_attributes={neff_input_names="input207"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4500 = bf16[8,128,3072]{2,1,0} broadcast(bf16[3072]{0} %p207.4493), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4501 = bf16[8,128,3072]{2,1,0} add(bf16[8,128,3072]{2,1,0} %reshape.4499, bf16[8,128,3072]{2,1,0} %broadcast.4500), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.29 = bf16[8,128,3072]{2,1,0} custom-call(bf16[8,128,3072]{2,1,0} %add.4501), custom_call_target="AwsNeuronGelu", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_GeluForwardImpl" op_name="xla___op_GeluForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.4511 = bf16[1024,3072]{1,0} reshape(bf16[8,128,3072]{2,1,0} %custom-call.29), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p206.4486 = bf16[768,3072]{1,0} parameter(206), frontend_attributes={neff_input_names="input206"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.4487 = bf16[3072,768]{0,1} transpose(bf16[768,3072]{1,0} %p206.4486), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4512 = bf16[1024,768]{1,0} dot(bf16[1024,3072]{1,0} %reshape.4511, bf16[3072,768]{0,1} %transpose.4487), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4513 = bf16[8,128,768]{2,1,0} reshape(bf16[1024,768]{1,0} %dot.4512), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p205.4484 = bf16[768]{0} parameter(205), frontend_attributes={neff_input_names="input205"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4514 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p205.4484), dimensions={2}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4515 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %reshape.4513, bf16[8,128,768]{2,1,0} %broadcast.4514), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.152 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.153 = s64[] multiply(s64[] %constant.152, s64[] %add.151), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.154 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.155 = s64[] add(s64[] %multiply.153, s64[] %constant.154), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4452 = u64[] convert(s64[] %add.155), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.4456 = u64[1]{0} reshape(u64[] %convert.4452), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.418 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.4458 = u64[2]{0} concatenate(u64[1]{0} %reshape.4456, u64[1]{0} %constant.418), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.4459 = (u64[2]{0}, u32[8,128,768]{2,1,0}) rng-bit-generator(u64[2]{0} %concatenate.4458), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.4460 = u32[8,128,768]{2,1,0} get-tuple-element((u64[2]{0}, u32[8,128,768]{2,1,0}) %rng-bit-generator.4459), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.4462 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4463 = u32[8,128,768]{2,1,0} broadcast(u32[] %constant.4462), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.4464 = u32[8,128,768]{2,1,0} shift-right-logical(u32[8,128,768]{2,1,0} %get-tuple-element.4460, u32[8,128,768]{2,1,0} %broadcast.4463), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4465 = f32[8,128,768]{2,1,0} convert(u32[8,128,768]{2,1,0} %shift-right-logical.4464), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.423 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.96 = f32[8,128,768]{2,1,0} broadcast(f32[] %constant.423), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4471 = f32[8,128,768]{2,1,0} multiply(f32[8,128,768]{2,1,0} %convert.4465, f32[8,128,768]{2,1,0} %broadcast.96), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.4474 = bf16[8,128,768]{2,1,0} convert(f32[8,128,768]{2,1,0} %multiply.4471), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.4449 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.4475 = pred[8,128,768]{2,1,0} compare(bf16[8,128,768]{2,1,0} %convert.4474, bf16[8,128,768]{2,1,0} %broadcast.4449), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.77 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.37 = bf16[] divide(bf16[] %constant.77, bf16[] %p3.6)
  %broadcast.97 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %divide.37), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.155 = bf16[] constant(0)
  %broadcast.425 = bf16[8,128,768]{2,1,0} broadcast(bf16[] %constant.155), dimensions={}
  %select.38 = bf16[8,128,768]{2,1,0} select(pred[8,128,768]{2,1,0} %compare.4475, bf16[8,128,768]{2,1,0} %broadcast.97, bf16[8,128,768]{2,1,0} %broadcast.425), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4518 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %add.4515, bf16[8,128,768]{2,1,0} %select.38), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.4519 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %multiply.4518, bf16[8,128,768]{2,1,0} %add.4444), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py" source_line=464}
  %reshape.4520 = bf16[1,1024,768]{2,1,0} reshape(bf16[8,128,768]{2,1,0} %add.4519), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.213 = bf16[] constant(1), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.217 = bf16[1024]{0} broadcast(bf16[] %constant.213), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %constant.208 = bf16[] constant(0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.212 = bf16[1024]{0} broadcast(bf16[] %constant.208), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %batch-norm-training.4521 = (bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) batch-norm-training(bf16[1,1024,768]{2,1,0} %reshape.4520, bf16[1024]{0} %broadcast.217, bf16[1024]{0} %broadcast.212), epsilon=1e-12, feature_index=1, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %get-tuple-element.4522 = bf16[1,1024,768]{2,1,0} get-tuple-element((bf16[1,1024,768]{2,1,0}, bf16[1024]{0}, bf16[1024]{0}) %batch-norm-training.4521), index=0, metadata={op_type="aten__native_batch_norm" op_name="aten__native_batch_norm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %reshape.4529 = bf16[8,128,768]{2,1,0} reshape(bf16[1,1024,768]{2,1,0} %get-tuple-element.4522), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %p7.197 = bf16[768]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %broadcast.4532 = bf16[8,128,768]{2,1,0} broadcast(bf16[768]{0} %p7.197), dimensions={2}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %multiply.4535 = bf16[8,128,768]{2,1,0} multiply(bf16[8,128,768]{2,1,0} %reshape.4529, bf16[8,128,768]{2,1,0} %broadcast.4532), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %add.4537 = bf16[8,128,768]{2,1,0} add(bf16[8,128,768]{2,1,0} %broadcast.4536, bf16[8,128,768]{2,1,0} %multiply.4535), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=2543}
  %slice.4539 = bf16[8,1,768]{2,1,0} slice(bf16[8,128,768]{2,1,0} %add.4537), slice={[0:8], [0:1], [0:768]}, metadata={op_type="xla__generic_slice" op_name="xla__generic_slice" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.4540 = bf16[8,768]{1,0} reshape(bf16[8,1,768]{2,1,0} %slice.4539), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p6.194 = bf16[768,768]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.195 = bf16[768,768]{0,1} transpose(bf16[768,768]{1,0} %p6.194), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4541 = bf16[8,768]{1,0} dot(bf16[8,768]{1,0} %reshape.4540, bf16[768,768]{0,1} %transpose.195), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p5.193 = bf16[768]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4545 = bf16[8,768]{1,0} broadcast(bf16[768]{0} %p5.193), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4546 = bf16[8,768]{1,0} add(bf16[8,768]{1,0} %dot.4541, bf16[8,768]{1,0} %broadcast.4545), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %tanh.4547 = bf16[8,768]{1,0} tanh(bf16[8,768]{1,0} %add.4546), metadata={op_type="aten__tanh" op_name="aten__tanh" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/activation.py" source_line=356}
  %constant.156 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.157 = s64[] multiply(s64[] %constant.156, s64[] %add.155), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.158 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %add.159 = s64[] add(s64[] %multiply.157, s64[] %constant.158), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.166 = u64[] convert(s64[] %add.159), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %reshape.170 = u64[1]{0} reshape(u64[] %convert.166), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.426 = u64[1]{0} constant({0}), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %concatenate.172 = u64[2]{0} concatenate(u64[1]{0} %reshape.170, u64[1]{0} %constant.426), dimensions={0}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %rng-bit-generator.173 = (u64[2]{0}, u32[8,768]{1,0}) rng-bit-generator(u64[2]{0} %concatenate.172), algorithm=rng_default, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %get-tuple-element.174 = u32[8,768]{1,0} get-tuple-element((u64[2]{0}, u32[8,768]{1,0}) %rng-bit-generator.173), index=1, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.176 = u32[] constant(9), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.177 = u32[8,768]{1,0} broadcast(u32[] %constant.176), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %shift-right-logical.178 = u32[8,768]{1,0} shift-right-logical(u32[8,768]{1,0} %get-tuple-element.174, u32[8,768]{1,0} %broadcast.177), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.179 = f32[8,768]{1,0} convert(u32[8,768]{1,0} %shift-right-logical.178), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.431 = f32[] constant(1.1920929e-07), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.98 = f32[8,768]{1,0} broadcast(f32[] %constant.431), dimensions={}, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.185 = f32[8,768]{1,0} multiply(f32[8,768]{1,0} %convert.179, f32[8,768]{1,0} %broadcast.98), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %convert.188 = bf16[8,768]{1,0} convert(f32[8,768]{1,0} %multiply.185), metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %broadcast.163 = bf16[8,768]{1,0} broadcast(bf16[] %p3.6), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %compare.189 = pred[8,768]{1,0} compare(bf16[8,768]{1,0} %convert.188, bf16[8,768]{1,0} %broadcast.163), direction=LT, metadata={op_type="aten__bernoulli" op_name="aten__bernoulli" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.79 = bf16[] constant(1), metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %divide.38 = bf16[] divide(bf16[] %constant.79, bf16[] %p3.6)
  %broadcast.99 = bf16[8,768]{1,0} broadcast(bf16[] %divide.38), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %constant.157 = bf16[] constant(0)
  %broadcast.435 = bf16[8,768]{1,0} broadcast(bf16[] %constant.157), dimensions={}
  %select.39 = bf16[8,768]{1,0} select(pred[8,768]{1,0} %compare.189, bf16[8,768]{1,0} %broadcast.99, bf16[8,768]{1,0} %broadcast.435), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %multiply.4548 = bf16[8,768]{1,0} multiply(bf16[8,768]{1,0} %tanh.4547, bf16[8,768]{1,0} %select.39), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/functional.py" source_line=1266}
  %p2.4 = bf16[2,768]{1,0} parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %transpose.5 = bf16[768,2]{0,1} transpose(bf16[2,768]{1,0} %p2.4), dimensions={1,0}, metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %dot.4549 = bf16[8,2]{1,0} dot(bf16[8,768]{1,0} %multiply.4548, bf16[768,2]{0,1} %transpose.5), lhs_contracting_dims={1}, rhs_contracting_dims={0}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p1.3 = bf16[2]{0} parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %broadcast.4553 = bf16[8,2]{1,0} broadcast(bf16[2]{0} %p1.3), dimensions={1}, metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.4554 = bf16[8,2]{1,0} add(bf16[8,2]{1,0} %dot.4549, bf16[8,2]{1,0} %broadcast.4553), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %constant.0 = bf16[] constant(-inf)
  %reduce.0 = bf16[8]{0} reduce(bf16[8,2]{1,0} %add.4554, bf16[] %constant.0), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardMax.4555
  %broadcast.0 = bf16[8,2]{1,0} broadcast(bf16[8]{0} %reduce.0), dimensions={0}
  %subtract.0 = bf16[8,2]{1,0} subtract(bf16[8,2]{1,0} %add.4554, bf16[8,2]{1,0} %broadcast.0)
  %exponential.0 = bf16[8,2]{1,0} exponential(bf16[8,2]{1,0} %subtract.0)
  %constant.2 = bf16[] constant(0)
  %reduce.1 = bf16[8]{0} reduce(bf16[8,2]{1,0} %exponential.0, bf16[] %constant.2), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.4559
  %log.0 = bf16[8]{0} log(bf16[8]{0} %reduce.1)
  %broadcast.1 = bf16[8,2]{1,0} broadcast(bf16[8]{0} %log.0), dimensions={0}
  %subtract.1 = bf16[8,2]{1,0} subtract(bf16[8,2]{1,0} %subtract.0, bf16[8,2]{1,0} %broadcast.1)
  %broadcast.3 = s64[8,2]{1,0} broadcast(s64[8]{0} %p0.2), dimensions={0}
  %iota.2 = s64[8,2]{1,0} iota(), iota_dimension=1
  %compare.0 = pred[8,2]{1,0} compare(s64[8,2]{1,0} %broadcast.3, s64[8,2]{1,0} %iota.2), direction=EQ
  %constant.3 = bf16[] constant(1)
  %broadcast.6 = bf16[8,2]{1,0} broadcast(bf16[] %constant.3), dimensions={}
  %constant.4 = bf16[] constant(0)
  %broadcast.7 = bf16[8,2]{1,0} broadcast(bf16[] %constant.4), dimensions={}
  %select.0 = bf16[8,2]{1,0} select(pred[8,2]{1,0} %compare.0, bf16[8,2]{1,0} %broadcast.6, bf16[8,2]{1,0} %broadcast.7)
  %multiply.0 = bf16[8,2]{1,0} multiply(bf16[8,2]{1,0} %subtract.1, bf16[8,2]{1,0} %select.0)
  %reduce.2 = bf16[8]{0} reduce(bf16[8,2]{1,0} %multiply.0, bf16[] %constant.2), dimensions={1}, to_apply=%SimpleCrossEntropyLossForwardAdd.4563
  %constant.81 = bf16[] constant(0)
  %broadcast.100 = bf16[8]{0} broadcast(bf16[] %constant.81), dimensions={}
  %select.1 = bf16[8]{0} select(pred[8]{0} %compare.1, bf16[8]{0} %reduce.2, bf16[8]{0} %broadcast.100)
  %reduce.3 = bf16[] reduce(bf16[8]{0} %select.1, bf16[] %constant.2), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.4567
  %convert.0 = bf16[8]{0} convert(pred[8]{0} %compare.1)
  %reduce.4 = bf16[] reduce(bf16[8]{0} %convert.0, bf16[] %constant.2), dimensions={0}, to_apply=%SimpleCrossEntropyLossForwardAdd.4571
  %divide.0 = bf16[] divide(bf16[] %reduce.3, bf16[] %reduce.4)
  %negate.0 = bf16[] negate(bf16[] %divide.0), metadata={op_type="xla___op_SimpleCrossEntropyLossForwardImpl" op_name="xla___op_SimpleCrossEntropyLossForwardImpl" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.4620 = bf16[] add(bf16[] %p210.4619, bf16[] %negate.0), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/SemanticEquivalenceFramework/training_experiments/neuronx_distributed_venv/lib/python3.8/site-packages/transformers/trainer.py" source_line=1914}
  ROOT %tuple.4621 = (bf16[]) tuple(bf16[] %add.4620), frontend_attributes={neff_output_names="output0"}
}

`;

export default text;
