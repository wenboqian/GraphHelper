const text = `
    HloModule SyncTensorsGraph.354, input_output_alias={ {0}: (8, {}, must-alias), {1}: (7, {}, must-alias) }

%AddComputation.48 (x.49: f32[], y.50: f32[]) -> f32[] {
  %x.49 = f32[] parameter(0)
  %y.50 = f32[] parameter(1)
  ROOT %add.51 = f32[] add(f32[] %x.49, f32[] %y.50)
}

%AddComputation.183 (x.184: f32[], y.185: f32[]) -> f32[] {
  %x.184 = f32[] parameter(0)
  %y.185 = f32[] parameter(1)
  ROOT %add.186 = f32[] add(f32[] %x.184, f32[] %y.185)
}

%AddComputation.228 (x.229: f32[], y.230: f32[]) -> f32[] {
  %x.229 = f32[] parameter(0)
  %y.230 = f32[] parameter(1)
  ROOT %add.231 = f32[] add(f32[] %x.229, f32[] %y.230)
}

%AddComputation.238 (x.239: f32[], y.240: f32[]) -> f32[] {
  %x.239 = f32[] parameter(0)
  %y.240 = f32[] parameter(1)
  ROOT %add.241 = f32[] add(f32[] %x.239, f32[] %y.240)
}

ENTRY %SyncTensorsGraph.354 (p0.1: f32[], p1.3: f32[], p2.5: f32[], p3.6: f32[], p4.12: f32[], p5.17: f32[], p6.18: s64[], p7.64: f32[1], p8.72: f32[1,1], p9.191: f32[], p10.218: f32[1], p11.262: f32[], p12.277: f32[], p13.281: f32[], p14.291: f32[], p15.292: f32[]) -> (f32[1,1], f32[1], f32[1], f32[1,1], f32[1], /*index=5*/f32[1,1], f32[1,1], f32[1], f32[1]) {
  %p8.72 = f32[1,1]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %p15.292 = f32[] parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape = f32[1,1]{1,0} reshape(f32[] %p15.292), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.294 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %p8.72, f32[1,1]{1,0} %reshape), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p14.291 = f32[] parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape.1 = f32[1,1]{1,0} reshape(f32[] %p14.291), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.297 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %multiply.294, f32[1,1]{1,0} %reshape.1), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.298 = f32[1,1]{1,0} subtract(f32[1,1]{1,0} %p8.72, f32[1,1]{1,0} %multiply.297), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.38 = f32[] constant(0)
  %p13.281 = f32[] parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.8 = f32[] multiply(f32[] %constant.38, f32[] %p13.281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.90 = f32[1,1]{1,0} reshape(f32[] %multiply.8), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.3 = f32[1,1]{1,0} constant({ {0} })
  %constant.4 = f32[1,1]{1,0} constant({ {0} })
  %constant.5 = f32[1,1]{1,0} constant({ {0} })
  %constant.19 = s64[] constant(214013), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %p6.18 = s64[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %multiply.20 = s64[] multiply(s64[] %constant.19, s64[] %p6.18), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %constant.21 = s64[] constant(2531011), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %add.22 = s64[] add(s64[] %multiply.20, s64[] %constant.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %convert.25 = u64[] convert(s64[] %add.22), metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %reshape.27 = u64[1]{0} reshape(u64[] %convert.25), metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %constant.6 = u64[1]{0} constant({0})
  %concatenate.29 = u64[2]{0} concatenate(u64[1]{0} %reshape.27, u64[1]{0} %constant.6), dimensions={0}, metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %rng-bit-generator.30 = (u64[2]{0}, u32[1]{0}) rng-bit-generator(u64[2]{0} %concatenate.29), algorithm=rng_default, metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %get-tuple-element.31 = u32[1]{0} get-tuple-element((u64[2]{0}, u32[1]{0}) %rng-bit-generator.30), index=1, metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %constant.8 = u32[1]{0} constant({9})
  %shift-right-logical.35 = u32[1]{0} shift-right-logical(u32[1]{0} %get-tuple-element.31, u32[1]{0} %constant.8), metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %convert.36 = f32[1]{0} convert(u32[1]{0} %shift-right-logical.35), metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %constant.9 = f32[1]{0} constant({1.1920929e-07})
  %multiply.42 = f32[1]{0} multiply(f32[1]{0} %convert.36, f32[1]{0} %constant.9), metadata={op_type="aten__uniform" op_name="aten__uniform" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/parallel_state.py" source_line=90}
  %p5.17 = f32[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.52 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %multiply.42, f32[] %p5.17), replica_groups={}, to_apply=%AddComputation.48, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.60 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.52), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-gather.61 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.5, f32[] %get-tuple-element.60), replica_groups={{8,16},{24,0},{9,17},{25,1},{10,18},{26,2},{11,19},{27,3},{12,20},{28,4},{13,21},{29,5},{14,22},{30,6},{15,23},{31,7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.62 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.61), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.81 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.62), slice={[0:1], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %custom-call.6 = f32[1,1]{1,0} custom-call(f32[1,1]{1,0} %p8.72), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.11 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %slice.81, f32[1,1]{1,0} %custom-call.6), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p7.64 = f32[1]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %custom-call.7 = f32[1]{0} custom-call(f32[1]{0} %p7.64), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.18 = f32[1,1]{1,0} reshape(f32[1]{0} %custom-call.7), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.85 = f32[1,1]{1,0} add(f32[1,1]{1,0} %multiply.11, f32[1,1]{1,0} %reshape.18), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %get-tuple-element.88 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.61), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.89 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %add.85, f32[] %get-tuple-element.88), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.97 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.89), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.98 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.4, f32[] %get-tuple-element.97), replica_groups={{8,16},{24,0},{9,17},{25,1},{10,18},{26,2},{11,19},{27,3},{12,20},{28,4},{13,21},{29,5},{14,22},{30,6},{15,23},{31,7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.99 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.98), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.116 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.99), slice={[0:1], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %custom-call.8 = f32[1,1]{1,0} custom-call(f32[1,1]{1,0} %p8.72), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.12 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %slice.116, f32[1,1]{1,0} %custom-call.8), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.9 = f32[1]{0} custom-call(f32[1]{0} %p7.64), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.23 = f32[1,1]{1,0} reshape(f32[1]{0} %custom-call.9), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.120 = f32[1,1]{1,0} add(f32[1,1]{1,0} %multiply.12, f32[1,1]{1,0} %reshape.23), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %get-tuple-element.123 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.98), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.124 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %add.120, f32[] %get-tuple-element.123), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.132 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.124), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.133 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.3, f32[] %get-tuple-element.132), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.134 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.133), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.136 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.134), slice={[1:2], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %reshape.169 = f32[1]{0} reshape(f32[1,1]{1,0} %slice.136), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.10 = f32[1]{0} custom-call(f32[1]{0} %reshape.169), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.14 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %slice.136, f32[1,1]{1,0} %slice.116), metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.11 = f32[1,1]{1,0} custom-call(f32[1,1]{1,0} %multiply.14), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.15 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %custom-call.8, f32[1,1]{1,0} %slice.136), metadata={op_type="aten__mm" op_name="aten__mm"}
  %get-tuple-element.142 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.133), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.143 = (f32[2,1]{0,1}, f32[]) all-gather(f32[1,1]{1,0} %multiply.15, f32[] %get-tuple-element.142), replica_groups={{8,16},{24,0},{9,17},{25,1},{10,18},{26,2},{11,19},{27,3},{12,20},{28,4},{13,21},{29,5},{14,22},{30,6},{15,23},{31,7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.182 = f32[] get-tuple-element((f32[2,1]{0,1}, f32[]) %all-gather.143), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-reduce.187 = (f32[1]{0}, f32[1,1]{1,0}, f32[]) all-reduce(f32[1]{0} %custom-call.10, f32[1,1]{1,0} %custom-call.11, f32[] %get-tuple-element.182), replica_groups={{0},{1},{2},{3},{4},{5},{6},{7},{8},{9},{10},{11},{12},{13},{14},{15},{16},{17},{18},{19},{20},{21},{22},{23},{24},{25},{26},{27},{28},{29},{30},{31}}, constrain_layout=true, to_apply=%AddComputation.183, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.189 = f32[1,1]{1,0} get-tuple-element((f32[1]{0}, f32[1,1]{1,0}, f32[]) %all-reduce.187), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.17 = f32[1]{0} constant({1})
  %p10.218 = f32[1]{0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=114}
  %multiply.16 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %get-tuple-element.189, f32[1,1]{1,0} %get-tuple-element.189), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.44 = f32[1]{0} reshape(f32[1,1]{1,0} %multiply.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.220 = f32[1]{0} add(f32[1]{0} %p10.218, f32[1]{0} %reshape.44), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.188 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[1,1]{1,0}, f32[]) %all-reduce.187), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.17 = f32[1]{0} multiply(f32[1]{0} %get-tuple-element.188, f32[1]{0} %get-tuple-element.188), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %add.222 = f32[1]{0} add(f32[1]{0} %add.220, f32[1]{0} %multiply.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %p9.191 = f32[] parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %reshape.47 = f32[1]{0} reshape(f32[] %p9.191), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %divide.224 = f32[1]{0} divide(f32[1]{0} %add.222, f32[1]{0} %reshape.47), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %get-tuple-element.227 = f32[] get-tuple-element((f32[1]{0}, f32[1,1]{1,0}, f32[]) %all-reduce.187), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.232 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %divide.224, f32[] %get-tuple-element.227), replica_groups={{0,1,2,3,4,5,6,7},{8,9,10,11,12,13,14,15},{16,17,18,19,20,21,22,23},{24,25,26,27,28,29,30,31}}, to_apply=%AddComputation.228, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.236 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.232), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.237 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.232), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.242 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %get-tuple-element.236, f32[] %get-tuple-element.237), replica_groups={{0,8,16,24},{1,9,17,25},{2,10,18,26},{3,11,19,27},{4,12,20,28},{5,13,21,29},{6,14,22,30},{7,15,23,31}}, to_apply=%AddComputation.238, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.243 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.242), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.18 = f32[1]{0} constant({0.5})
  %power.245 = f32[1]{0} power(f32[1]{0} %get-tuple-element.243, f32[1]{0} %constant.18), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=137}
  %p4.12 = f32[] parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %reshape.49 = f32[1]{0} reshape(f32[] %p4.12), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %add.247 = f32[1]{0} add(f32[1]{0} %power.245, f32[1]{0} %reshape.49), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %divide.250 = f32[1]{0} divide(f32[1]{0} %constant.17, f32[1]{0} %add.247), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/_tensor.py" source_line=913}
  %constant.25 = f32[1]{0} constant({1})
  %compare.257 = pred[1]{0} compare(f32[1]{0} %divide.250, f32[1]{0} %constant.25), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.27 = f32[1]{0} constant({1})
  %select.259 = f32[1]{0} select(pred[1]{0} %compare.257, f32[1]{0} %divide.250, f32[1]{0} %constant.27), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %reshape.55 = f32[1,1]{1,0} reshape(f32[1]{0} %select.259), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.261 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %get-tuple-element.189, f32[1,1]{1,0} %reshape.55), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %p12.277 = f32[] parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.57 = f32[1,1]{1,0} reshape(f32[] %p12.277), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.280 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %multiply.261, f32[1,1]{1,0} %reshape.57), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.287 = f32[1,1]{1,0} add(f32[1,1]{1,0} %reshape.90, f32[1,1]{1,0} %multiply.280), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.39 = f32[] constant(0)
  %p11.262 = f32[] parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.7 = f32[] multiply(f32[] %constant.39, f32[] %p11.262), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.87 = f32[1,1]{1,0} reshape(f32[] %multiply.7), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.268 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %multiply.261, f32[1,1]{1,0} %multiply.261), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.60 = f32[1,1]{1,0} reshape(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.270 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %multiply.268, f32[1,1]{1,0} %reshape.60), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.271 = f32[1,1]{1,0} add(f32[1,1]{1,0} %reshape.87, f32[1,1]{1,0} %multiply.270), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.272 = f32[1,1]{1,0} sqrt(f32[1,1]{1,0} %add.271), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.61 = f32[1,1]{1,0} reshape(f32[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.274 = f32[1,1]{1,0} divide(f32[1,1]{1,0} %sqrt.272, f32[1,1]{1,0} %reshape.61), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.62 = f32[1,1]{1,0} reshape(f32[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.276 = f32[1,1]{1,0} add(f32[1,1]{1,0} %divide.274, f32[1,1]{1,0} %reshape.62), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.299 = f32[1,1]{1,0} divide(f32[1,1]{1,0} %add.287, f32[1,1]{1,0} %add.276), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.63 = f32[1,1]{1,0} reshape(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.301 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %divide.299, f32[1,1]{1,0} %reshape.63), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.302 = f32[1,1]{1,0} add(f32[1,1]{1,0} %subtract.298, f32[1,1]{1,0} %multiply.301), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.64 = f32[1]{0} reshape(f32[] %p15.292), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.344 = f32[1]{0} multiply(f32[1]{0} %p7.64, f32[1]{0} %reshape.64), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.29 = f32[1]{0} constant({0})
  %multiply.347 = f32[1]{0} multiply(f32[1]{0} %multiply.344, f32[1]{0} %constant.29), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.348 = f32[1]{0} subtract(f32[1]{0} %p7.64, f32[1]{0} %multiply.347), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.40 = f32[] constant(0)
  %multiply.10 = f32[] multiply(f32[] %constant.40, f32[] %p13.281), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.97 = f32[1]{0} reshape(f32[] %multiply.10), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.34 = f32[1]{0} constant({1})
  %compare.312 = pred[1]{0} compare(f32[1]{0} %divide.250, f32[1]{0} %constant.34), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.35 = f32[1]{0} constant({1})
  %select.314 = f32[1]{0} select(pred[1]{0} %compare.312, f32[1]{0} %divide.250, f32[1]{0} %constant.35), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %multiply.315 = f32[1]{0} multiply(f32[1]{0} %get-tuple-element.188, f32[1]{0} %select.314), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.73 = f32[1]{0} reshape(f32[] %p12.277), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.332 = f32[1]{0} multiply(f32[1]{0} %multiply.315, f32[1]{0} %reshape.73), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.338 = f32[1]{0} add(f32[1]{0} %reshape.97, f32[1]{0} %multiply.332), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.41 = f32[] constant(0)
  %multiply.9 = f32[] multiply(f32[] %constant.41, f32[] %p11.262), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.94 = f32[1]{0} reshape(f32[] %multiply.9), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.321 = f32[1]{0} multiply(f32[1]{0} %multiply.315, f32[1]{0} %multiply.315), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.76 = f32[1]{0} reshape(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.323 = f32[1]{0} multiply(f32[1]{0} %multiply.321, f32[1]{0} %reshape.76), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.324 = f32[1]{0} add(f32[1]{0} %reshape.94, f32[1]{0} %multiply.323), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.325 = f32[1]{0} sqrt(f32[1]{0} %add.324), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.77 = f32[1]{0} reshape(f32[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.327 = f32[1]{0} divide(f32[1]{0} %sqrt.325, f32[1]{0} %reshape.77), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.78 = f32[1]{0} reshape(f32[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.329 = f32[1]{0} add(f32[1]{0} %divide.327, f32[1]{0} %reshape.78), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.349 = f32[1]{0} divide(f32[1]{0} %add.338, f32[1]{0} %add.329), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.79 = f32[1]{0} reshape(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.351 = f32[1]{0} multiply(f32[1]{0} %divide.349, f32[1]{0} %reshape.79), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.352 = f32[1]{0} add(f32[1]{0} %subtract.348, f32[1]{0} %multiply.351), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  ROOT %tuple.353 = (f32[1,1]{1,0}, f32[1]{0}, f32[1]{0}, f32[1,1]{1,0}, f32[1]{0}, /*index=5*/f32[1,1]{1,0}, f32[1,1]{1,0}, f32[1]{0}, f32[1]{0}) tuple(f32[1,1]{1,0} %add.302, f32[1]{0} %add.352, f32[1]{0} %multiply.315, f32[1,1]{1,0} %multiply.261, f32[1]{0} %power.245, /*index=5*/f32[1,1]{1,0} %add.287, f32[1,1]{1,0} %add.271, f32[1]{0} %add.338, f32[1]{0} %add.324), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8"}
}
`

export default text;
