const text = `
    HloModule SyncTensorsGraph.310, input_output_alias={ {0}: (11, {}, must-alias), {1}: (12, {}, must-alias), {2}: (4, {}, must-alias), {3}: (13, {}, must-alias), {4}: (5, {}, must-alias) }

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.310 (p0.1: f32[], p1.3: f32[], p2.5: f32[], p3.6: f32[], p4.7: f32[1,3], p5.28: f32[4], p6.40: f32[], p7.57: f32[], p8.63: f32[], p9.77: f32[], p10.78: f32[], p11.79: f32[3,4], p12.134: f32[3], p13.262: f32[1], p14.306: f32[]) -> (f32[3,4], f32[3], f32[1,3], f32[1], f32[4], /*index=5*/f32[], f32[], f32[1], f32[1,3], f32[3], /*index=10*/f32[3,4], f32[3,4], f32[3,4], f32[3], f32[3], /*index=15*/f32[1,3], f32[1,3], f32[1], f32[1]) {
    %p5.17 = f32[] parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.52 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %multiply.42, f32[] %p5.17), replica_groups={}, to_apply=%AddComputation.48, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.60 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.52), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-gather.61 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.5, f32[] %get-tuple-element.60), replica_groups={{8,16},{24,0},{9,17},{25,1},{10,18},{26,2},{11,19},{27,3},{12,20},{28,4},{13,21},{29,5},{14,22},{30,6},{15,23},{31,7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.62 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.61), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.81 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.62), slice={[0:1], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %custom-call.6 = f32[1,1]{1,0} custom-call(f32[1,1]{1,0} %p8.72), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.11 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %slice.81, f32[1,1]{1,0} %custom-call.6), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %p7.64 = f32[1]{0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %custom-call.7 = f32[1]{0} custom-call(f32[1]{0} %p7.64), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.18 = f32[1,1]{1,0} reshape(f32[1]{0} %custom-call.7), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.85 = f32[1,1]{1,0} add(f32[1,1]{1,0} %multiply.11, f32[1,1]{1,0} %reshape.18), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %get-tuple-element.88 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.61), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.89 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %add.85, f32[] %get-tuple-element.88), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.97 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.89), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.98 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.4, f32[] %get-tuple-element.97), replica_groups={{8,16},{24,0},{9,17},{25,1},{10,18},{26,2},{11,19},{27,3},{12,20},{28,4},{13,21},{29,5},{14,22},{30,6},{15,23},{31,7}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.99 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.98), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.116 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.99), slice={[0:1], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %custom-call.8 = f32[1,1]{1,0} custom-call(f32[1,1]{1,0} %p8.72), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.12 = f32[1,1]{1,0} multiply(f32[1,1]{1,0} %slice.116, f32[1,1]{1,0} %custom-call.8), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.9 = f32[1]{0} custom-call(f32[1]{0} %p7.64), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.23 = f32[1,1]{1,0} reshape(f32[1]{0} %custom-call.9), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %add.120 = f32[1,1]{1,0} add(f32[1,1]{1,0} %multiply.12, f32[1,1]{1,0} %reshape.23), metadata={op_type="aten__addmm" op_name="aten__addmm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %get-tuple-element.123 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.98), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.124 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %add.120, f32[] %get-tuple-element.123), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.132 = f32[] get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.124), index=1, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %all-gather.133 = (f32[2,1]{1,0}, f32[]) all-gather(f32[1,1]{1,0} %constant.3, f32[] %get-tuple-element.132), replica_groups={{0,8},{16,24},{1,9},{17,25},{2,10},{18,26},{3,11},{19,27},{4,12},{20,28},{5,13},{21,29},{6,14},{22,30},{7,15},{23,31}}, dimensions={0}, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %get-tuple-element.134 = f32[2,1]{1,0} get-tuple-element((f32[2,1]{1,0}, f32[]) %all-gather.133), index=0, metadata={op_type="xla__all_gather" op_name="xla__all_gather" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=586}
  %slice.136 = f32[1,1]{1,0} slice(f32[2,1]{1,0} %get-tuple-element.134), slice={[1:2], [0:1]}, metadata={op_type="xla__select" op_name="xla__select" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/neuronx_distributed/pipeline/comm.py" source_line=90}
  %reshape.169 = f32[1]{0} reshape(f32[1,1]{1,0} %slice.136), metadata={op_type="aten__view" op_name="aten__view" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
    
}

`

export default text;
