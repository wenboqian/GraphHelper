const text = `
    HloModule SyncTensorsGraph.310, input_output_alias={ {0}: (11, {}, must-alias), {1}: (12, {}, must-alias), {2}: (4, {}, must-alias), {3}: (13, {}, must-alias), {4}: (5, {}, must-alias) }

%scalar_add_computation (scalar_lhs: f32[], scalar_rhs: f32[]) -> f32[] {
  %scalar_lhs = f32[] parameter(0)
  %scalar_rhs = f32[] parameter(1)
  ROOT %add = f32[] add(f32[] %scalar_lhs, f32[] %scalar_rhs)
}

ENTRY %SyncTensorsGraph.310 (p0.1: f32[], p1.3: f32[], p2.5: f32[], p3.6: f32[], p4.7: f32[1,3], p5.28: f32[4], p6.40: f32[], p7.57: f32[], p8.63: f32[], p9.77: f32[], p10.78: f32[], p11.79: f32[3,4], p12.134: f32[3], p13.262: f32[1], p14.306: f32[]) -> (f32[3,4], f32[3], f32[1,3], f32[1], f32[4], /*index=5*/f32[], f32[], f32[1], f32[1,3], f32[3], /*index=10*/f32[3,4], f32[3,4], f32[3,4], f32[3], f32[3], /*index=15*/f32[1,3], f32[1,3], f32[1], f32[1]) {
  %p11.79 = f32[3,4]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %p10.78 = f32[] parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.80 = f32[3,4]{1,0} broadcast(f32[] %p10.78), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.81 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %p11.79, f32[3,4]{1,0} %broadcast.80), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %p9.77 = f32[] parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.82 = f32[3,4]{1,0} broadcast(f32[] %p9.77), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.84 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %multiply.81, f32[3,4]{1,0} %broadcast.82), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.85 = f32[3,4]{1,0} subtract(f32[3,4]{1,0} %p11.79, f32[3,4]{1,0} %multiply.84), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.3 = f32[] constant(0)
  %p8.63 = f32[] parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.0 = f32[] multiply(f32[] %constant.3, f32[] %p8.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.2 = f32[3,4]{1,0} broadcast(f32[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=121}
  %p4.7 = f32[1,3]{1,0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %custom-call.8 = f32[1,3]{1,0} custom-call(f32[1,3]{1,0} %p4.7), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.17 = f32[3]{0} reshape(f32[1,3]{1,0} %custom-call.8), metadata={op_type="aten__mm" op_name="aten__mm"}
  %broadcast.29 = f32[3,4]{0,1} broadcast(f32[3]{0} %reshape.17), dimensions={0}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %p5.28 = f32[4]{0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model.py" source_line=63}
  %broadcast.30 = f32[3,4]{0,1} broadcast(f32[4]{0} %p5.28), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm"}
  %multiply.8 = f32[3,4]{0,1} multiply(f32[3,4]{0,1} %broadcast.29, f32[3,4]{0,1} %broadcast.30), metadata={op_type="aten__mm" op_name="aten__mm"}
  %custom-call.9 = f32[3,4]{1,0} custom-call(f32[3,4]{0,1} %multiply.8), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %p7.57 = f32[] parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.61 = f32[3,4]{1,0} broadcast(f32[] %p7.57), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.62 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %custom-call.9, f32[3,4]{1,0} %broadcast.61), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.71 = f32[3,4]{1,0} add(f32[3,4]{1,0} %broadcast.2, f32[3,4]{1,0} %multiply.62), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.8 = f32[] constant(0)
  %p6.40 = f32[] parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.1 = f32[] multiply(f32[] %constant.8, f32[] %p6.40), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.5 = f32[3,4]{1,0} broadcast(f32[] %multiply.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=125}
  %multiply.48 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %custom-call.9, f32[3,4]{1,0} %custom-call.9), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %p3.6 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.49 = f32[3,4]{1,0} broadcast(f32[] %p3.6), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.50 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %multiply.48, f32[3,4]{1,0} %broadcast.49), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.51 = f32[3,4]{1,0} add(f32[3,4]{1,0} %broadcast.5, f32[3,4]{1,0} %multiply.50), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.52 = f32[3,4]{1,0} sqrt(f32[3,4]{1,0} %add.51), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p2.5 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.53 = f32[3,4]{1,0} broadcast(f32[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.54 = f32[3,4]{1,0} divide(f32[3,4]{1,0} %sqrt.52, f32[3,4]{1,0} %broadcast.53), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %p1.3 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.55 = f32[3,4]{1,0} broadcast(f32[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.56 = f32[3,4]{1,0} add(f32[3,4]{1,0} %divide.54, f32[3,4]{1,0} %broadcast.55), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.86 = f32[3,4]{1,0} divide(f32[3,4]{1,0} %add.71, f32[3,4]{1,0} %add.56), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p0.1 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.87 = f32[3,4]{1,0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.88 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %divide.86, f32[3,4]{1,0} %broadcast.87), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.89 = f32[3,4]{1,0} add(f32[3,4]{1,0} %subtract.85, f32[3,4]{1,0} %multiply.88), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p12.134 = f32[3]{0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %broadcast.135 = f32[3]{0} broadcast(f32[] %p10.78), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.136 = f32[3]{0} multiply(f32[3]{0} %p12.134, f32[3]{0} %broadcast.135), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.137 = f32[3]{0} broadcast(f32[] %p9.77), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.139 = f32[3]{0} multiply(f32[3]{0} %multiply.136, f32[3]{0} %broadcast.137), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.140 = f32[3]{0} subtract(f32[3]{0} %p12.134, f32[3]{0} %multiply.139), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.9 = f32[] constant(0)
  %multiply.2 = f32[] multiply(f32[] %constant.9, f32[] %p8.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.8 = f32[3]{0} broadcast(f32[] %multiply.2), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=121}
  %custom-call.11 = f32[3]{0} custom-call(f32[3]{0} %reshape.17), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.119 = f32[3]{0} broadcast(f32[] %p7.57), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.120 = f32[3]{0} multiply(f32[3]{0} %custom-call.11, f32[3]{0} %broadcast.119), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.128 = f32[3]{0} add(f32[3]{0} %broadcast.8, f32[3]{0} %multiply.120), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.10 = f32[] constant(0)
  %multiply.5 = f32[] multiply(f32[] %constant.10, f32[] %p6.40), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.12 = f32[3]{0} broadcast(f32[] %multiply.5), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=125}
  %multiply.107 = f32[3]{0} multiply(f32[3]{0} %custom-call.11, f32[3]{0} %custom-call.11), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.108 = f32[3]{0} broadcast(f32[] %p3.6), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.109 = f32[3]{0} multiply(f32[3]{0} %multiply.107, f32[3]{0} %broadcast.108), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.110 = f32[3]{0} add(f32[3]{0} %broadcast.12, f32[3]{0} %multiply.109), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.111 = f32[3]{0} sqrt(f32[3]{0} %add.110), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.112 = f32[3]{0} broadcast(f32[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.113 = f32[3]{0} divide(f32[3]{0} %sqrt.111, f32[3]{0} %broadcast.112), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.114 = f32[3]{0} broadcast(f32[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.115 = f32[3]{0} add(f32[3]{0} %divide.113, f32[3]{0} %broadcast.114), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.141 = f32[3]{0} divide(f32[3]{0} %add.128, f32[3]{0} %add.115), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.142 = f32[3]{0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.143 = f32[3]{0} multiply(f32[3]{0} %divide.141, f32[3]{0} %broadcast.142), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.144 = f32[3]{0} add(f32[3]{0} %subtract.140, f32[3]{0} %multiply.143), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.217 = f32[1,3]{1,0} broadcast(f32[] %p10.78), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.218 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %p4.7, f32[1,3]{1,0} %broadcast.217), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %broadcast.219 = f32[1,3]{1,0} broadcast(f32[] %p9.77), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.221 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %multiply.218, f32[1,3]{1,0} %broadcast.219), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.222 = f32[1,3]{1,0} subtract(f32[1,3]{1,0} %p4.7, f32[1,3]{1,0} %multiply.221), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.24 = f32[] constant(0)
  %multiply.16 = f32[] multiply(f32[] %constant.24, f32[] %p8.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %broadcast.15 = f32[1,3]{1,0} broadcast(f32[] %multiply.16), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=121}
  %broadcast.50 = f32[3,4]{1,0} broadcast(f32[4]{0} %p5.28), dimensions={1}, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.12 = f32[3,4]{1,0} custom-call(f32[3,4]{1,0} %p11.79), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %multiply.19 = f32[3,4]{1,0} multiply(f32[3,4]{1,0} %broadcast.50, f32[3,4]{1,0} %custom-call.12)
  %constant = f32[] constant(0)
  %reduce = f32[3]{0} reduce(f32[3,4]{1,0} %multiply.19, f32[] %constant), dimensions={1}, to_apply=%scalar_add_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.13 = f32[3]{0} custom-call(f32[3]{0} %p12.134), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.171 = f32[3]{0} add(f32[3]{0} %reduce, f32[3]{0} %custom-call.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.55 = f32[1,3]{0,1} reshape(f32[3]{0} %add.171), metadata={op_type="aten__permute" op_name="aten__permute" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %custom-call.14 = f32[1,3]{1,0} custom-call(f32[1,3]{0,1} %reshape.55), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %broadcast.202 = f32[1,3]{1,0} broadcast(f32[] %p7.57), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.203 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %custom-call.14, f32[1,3]{1,0} %broadcast.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.211 = f32[1,3]{1,0} add(f32[1,3]{1,0} %broadcast.15, f32[1,3]{1,0} %multiply.203), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.25 = f32[] constant(0)
  %multiply.17 = f32[] multiply(f32[] %constant.25, f32[] %p6.40), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.18 = f32[1,3]{1,0} broadcast(f32[] %multiply.17), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/optim/adamw.py" source_line=125}
  %multiply.190 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %custom-call.14, f32[1,3]{1,0} %custom-call.14), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %broadcast.191 = f32[1,3]{1,0} broadcast(f32[] %p3.6), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.192 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %multiply.190, f32[1,3]{1,0} %broadcast.191), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.193 = f32[1,3]{1,0} add(f32[1,3]{1,0} %broadcast.18, f32[1,3]{1,0} %multiply.192), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.194 = f32[1,3]{1,0} sqrt(f32[1,3]{1,0} %add.193), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.195 = f32[1,3]{1,0} broadcast(f32[] %p2.5), dimensions={}, metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.196 = f32[1,3]{1,0} divide(f32[1,3]{1,0} %sqrt.194, f32[1,3]{1,0} %broadcast.195), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %broadcast.197 = f32[1,3]{1,0} broadcast(f32[] %p1.3), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.198 = f32[1,3]{1,0} add(f32[1,3]{1,0} %divide.196, f32[1,3]{1,0} %broadcast.197), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.223 = f32[1,3]{1,0} divide(f32[1,3]{1,0} %add.211, f32[1,3]{1,0} %add.198), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %broadcast.224 = f32[1,3]{1,0} broadcast(f32[] %p0.1), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.225 = f32[1,3]{1,0} multiply(f32[1,3]{1,0} %divide.223, f32[1,3]{1,0} %broadcast.224), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.226 = f32[1,3]{1,0} add(f32[1,3]{1,0} %subtract.222, f32[1,3]{1,0} %multiply.225), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %p13.262 = f32[1]{0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/module.py" source_line=1158}
  %reshape.63 = f32[1]{0} reshape(f32[] %p10.78), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.264 = f32[1]{0} multiply(f32[1]{0} %p13.262, f32[1]{0} %reshape.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %reshape.64 = f32[1]{0} reshape(f32[] %p9.77), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %multiply.267 = f32[1]{0} multiply(f32[1]{0} %multiply.264, f32[1]{0} %reshape.64), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %subtract.268 = f32[1]{0} subtract(f32[1]{0} %p13.262, f32[1]{0} %multiply.267), metadata={op_type="aten__sub" op_name="aten__sub" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=58}
  %constant.26 = f32[] constant(0)
  %multiply.13 = f32[] multiply(f32[] %constant.26, f32[] %p8.63), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %reshape.137 = f32[1]{0} reshape(f32[] %multiply.13), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.6 = f32[1]{0} constant({1})
  %custom-call.15 = f32[1]{0} custom-call(f32[1]{0} %constant.6), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %reshape.70 = f32[1]{0} reshape(f32[] %p7.57), metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %multiply.252 = f32[1]{0} multiply(f32[1]{0} %custom-call.15, f32[1]{0} %reshape.70), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %add.258 = f32[1]{0} add(f32[1]{0} %reshape.137, f32[1]{0} %multiply.252), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=61}
  %constant.27 = f32[] constant(0)
  %multiply.12 = f32[] multiply(f32[] %constant.27, f32[] %p6.40), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.134 = f32[1]{0} reshape(f32[] %multiply.12), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.241 = f32[1]{0} multiply(f32[1]{0} %custom-call.15, f32[1]{0} %custom-call.15), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %reshape.74 = f32[1]{0} reshape(f32[] %p3.6), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %multiply.243 = f32[1]{0} multiply(f32[1]{0} %multiply.241, f32[1]{0} %reshape.74), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %add.244 = f32[1]{0} add(f32[1]{0} %reshape.134, f32[1]{0} %multiply.243), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=62}
  %sqrt.245 = f32[1]{0} sqrt(f32[1]{0} %add.244), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.76 = f32[1]{0} reshape(f32[] %p2.5), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.247 = f32[1]{0} divide(f32[1]{0} %sqrt.245, f32[1]{0} %reshape.76), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %reshape.77 = f32[1]{0} reshape(f32[] %p1.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %add.249 = f32[1]{0} add(f32[1]{0} %divide.247, f32[1]{0} %reshape.77), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=117}
  %divide.269 = f32[1]{0} divide(f32[1]{0} %add.258, f32[1]{0} %add.249), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.78 = f32[1]{0} reshape(f32[] %p0.1), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %multiply.271 = f32[1]{0} multiply(f32[1]{0} %divide.269, f32[1]{0} %reshape.78), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %add.272 = f32[1]{0} add(f32[1]{0} %subtract.268, f32[1]{0} %multiply.271), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_neuronx/optim/adamw.py" source_line=119}
  %reshape.81 = f32[3]{0} reshape(f32[1,3]{1,0} %custom-call.8)
  %multiply.11 = f32[3]{0} multiply(f32[3]{0} %add.171, f32[3]{0} %reshape.81)
  %constant.1 = f32[] constant(0)
  %reduce.1 = f32[] reduce(f32[3]{0} %multiply.11, f32[] %constant.1), dimensions={0}, to_apply=%scalar_add_computation, metadata={op_type="aten__mm" op_name="aten__mm" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.287 = f32[1]{0} reshape(f32[] %reduce.1), metadata={op_type="aten__as_strided" op_name="aten__as_strided" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %custom-call.16 = f32[1]{0} custom-call(f32[1]{0} %p13.262), custom_call_target="AwsNeuronTransferWithStaticRing", api_version=API_VERSION_UNSPECIFIED, metadata={op_type="xla___op_TransferWithStaticRingTransfer" op_name="xla___op_TransferWithStaticRingTransfer" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %add.288 = f32[1]{0} add(f32[1]{0} %reshape.287, f32[1]{0} %custom-call.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/assemble-subgraphs-env/lib/python3.8/site-packages/torch/nn/modules/linear.py" source_line=114}
  %reshape.140 = f32[] reshape(f32[1]{0} %add.288), metadata={op_type="aten__mean" op_name="aten__mean" source_file="run_simple_model.py" source_line=33}
  %p14.306 = f32[] parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="run_simple_model.py" source_line=65}
  %subtract.308 = f32[] subtract(f32[] %reshape.140, f32[] %p14.306), metadata={op_type="aten__sub" op_name="aten__sub" source_file="run_simple_model.py" source_line=65}
  ROOT %tuple.309 = (f32[3,4]{1,0}, f32[3]{0}, f32[1,3]{1,0}, f32[1]{0}, f32[4]{0}, /*index=5*/f32[], f32[], f32[1]{0}, f32[1,3]{1,0}, f32[3]{0}, /*index=10*/f32[3,4]{1,0}, f32[3,4]{1,0}, f32[3,4]{1,0}, f32[3]{0}, f32[3]{0}, /*index=15*/f32[1,3]{1,0}, f32[1,3]{1,0}, f32[1]{0}, f32[1]{0}) tuple(f32[3,4]{1,0} %add.89, f32[3]{0} %add.144, f32[1,3]{1,0} %add.226, f32[1]{0} %add.272, f32[4]{0} %p5.28, /*index=5*/f32[] %reshape.140, f32[] %subtract.308, f32[1]{0} %custom-call.15, f32[1,3]{1,0} %custom-call.14, f32[3]{0} %custom-call.11, /*index=10*/f32[3,4]{1,0} %custom-call.9, f32[3,4]{1,0} %add.71, f32[3,4]{1,0} %add.51, f32[3]{0} %add.128, f32[3]{0} %add.110, /*index=15*/f32[1,3]{1,0} %add.211, f32[1,3]{1,0} %add.193, f32[1]{0} %add.258, f32[1]{0} %add.244), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18"}
}

`

export default text;
