const text = `
    HloModule SyncTensorsGraph.2312, input_output_alias={ {0}: (39, {}, must-alias), {1}: (40, {}, must-alias), {2}: (41, {}, must-alias), {3}: (42, {}, must-alias), {4}: (43, {}, must-alias), {5}: (44, {}, must-alias), {6}: (45, {}, must-alias), {7}: (46, {}, must-alias), {8}: (47, {}, must-alias), {9}: (48, {}, must-alias), {10}: (49, {}, must-alias), {11}: (50, {}, must-alias), {12}: (51, {}, must-alias), {13}: (52, {}, must-alias), {14}: (53, {}, must-alias), {15}: (54, {}, must-alias), {16}: (55, {}, must-alias), {17}: (56, {}, must-alias), {18}: (57, {}, must-alias), {19}: (58, {}, must-alias), {20}: (59, {}, must-alias), {21}: (60, {}, must-alias), {22}: (61, {}, must-alias), {23}: (62, {}, must-alias), {24}: (63, {}, must-alias), {25}: (64, {}, must-alias), {26}: (65, {}, must-alias), {27}: (66, {}, must-alias), {28}: (67, {}, must-alias), {29}: (68, {}, must-alias), {30}: (4, {}, must-alias) }

%AddComputation.30 (x.31: f32[], y.32: f32[]) -> f32[] {
  %x.31 = f32[] parameter(0)
  %y.32 = f32[] parameter(1)
  ROOT %add.33 = f32[] add(f32[] %x.31, f32[] %y.32)
}

%AddComputation.100 (x.101: bf16[], y.102: bf16[]) -> bf16[] {
  %x.101 = bf16[] parameter(0)
  %y.102 = bf16[] parameter(1)
  ROOT %add.103 = bf16[] add(bf16[] %x.101, bf16[] %y.102)
}

%AddComputation.230 (x.231: bf16[], y.232: bf16[]) -> bf16[] {
  %x.231 = bf16[] parameter(0)
  %y.232 = bf16[] parameter(1)
  ROOT %add.233 = bf16[] add(bf16[] %x.231, bf16[] %y.232)
}

%AddComputation.243 (x.244: bf16[], y.245: bf16[]) -> bf16[] {
  %x.244 = bf16[] parameter(0)
  %y.245 = bf16[] parameter(1)
  ROOT %add.246 = bf16[] add(bf16[] %x.244, bf16[] %y.245)
}

%AddComputation.256 (x.257: bf16[], y.258: bf16[]) -> bf16[] {
  %x.257 = bf16[] parameter(0)
  %y.258 = bf16[] parameter(1)
  ROOT %add.259 = bf16[] add(bf16[] %x.257, bf16[] %y.258)
}

%AddComputation.269 (x.270: bf16[], y.271: bf16[]) -> bf16[] {
  %x.270 = bf16[] parameter(0)
  %y.271 = bf16[] parameter(1)
  ROOT %add.272 = bf16[] add(bf16[] %x.270, bf16[] %y.271)
}

%AddComputation.282 (x.283: bf16[], y.284: bf16[]) -> bf16[] {
  %x.283 = bf16[] parameter(0)
  %y.284 = bf16[] parameter(1)
  ROOT %add.285 = bf16[] add(bf16[] %x.283, bf16[] %y.284)
}

%AddComputation.295 (x.296: bf16[], y.297: bf16[]) -> bf16[] {
  %x.296 = bf16[] parameter(0)
  %y.297 = bf16[] parameter(1)
  ROOT %add.298 = bf16[] add(bf16[] %x.296, bf16[] %y.297)
}

%AddComputation.308 (x.309: bf16[], y.310: bf16[]) -> bf16[] {
  %x.309 = bf16[] parameter(0)
  %y.310 = bf16[] parameter(1)
  ROOT %add.311 = bf16[] add(bf16[] %x.309, bf16[] %y.310)
}

%AddComputation.322 (x.323: bf16[], y.324: bf16[]) -> bf16[] {
  %x.323 = bf16[] parameter(0)
  %y.324 = bf16[] parameter(1)
  ROOT %add.325 = bf16[] add(bf16[] %x.323, bf16[] %y.324)
}

%AddComputation.335 (x.336: bf16[], y.337: bf16[]) -> bf16[] {
  %x.336 = bf16[] parameter(0)
  %y.337 = bf16[] parameter(1)
  ROOT %add.338 = bf16[] add(bf16[] %x.336, bf16[] %y.337)
}

%AddComputation.348 (x.349: bf16[], y.350: bf16[]) -> bf16[] {
  %x.349 = bf16[] parameter(0)
  %y.350 = bf16[] parameter(1)
  ROOT %add.351 = bf16[] add(bf16[] %x.349, bf16[] %y.350)
}

%AddComputation.361 (x.362: bf16[], y.363: bf16[]) -> bf16[] {
  %x.362 = bf16[] parameter(0)
  %y.363 = bf16[] parameter(1)
  ROOT %add.364 = bf16[] add(bf16[] %x.362, bf16[] %y.363)
}

%AddComputation.374 (x.375: bf16[], y.376: bf16[]) -> bf16[] {
  %x.375 = bf16[] parameter(0)
  %y.376 = bf16[] parameter(1)
  ROOT %add.377 = bf16[] add(bf16[] %x.375, bf16[] %y.376)
}

%AddComputation.387 (x.388: bf16[], y.389: bf16[]) -> bf16[] {
  %x.388 = bf16[] parameter(0)
  %y.389 = bf16[] parameter(1)
  ROOT %add.390 = bf16[] add(bf16[] %x.388, bf16[] %y.389)
}

%AddComputation.400 (x.401: bf16[], y.402: bf16[]) -> bf16[] {
  %x.401 = bf16[] parameter(0)
  %y.402 = bf16[] parameter(1)
  ROOT %add.403 = bf16[] add(bf16[] %x.401, bf16[] %y.402)
}

%AddComputation.413 (x.414: bf16[], y.415: bf16[]) -> bf16[] {
  %x.414 = bf16[] parameter(0)
  %y.415 = bf16[] parameter(1)
  ROOT %add.416 = bf16[] add(bf16[] %x.414, bf16[] %y.415)
}

%AddComputation.426 (x.427: bf16[], y.428: bf16[]) -> bf16[] {
  %x.427 = bf16[] parameter(0)
  %y.428 = bf16[] parameter(1)
  ROOT %add.429 = bf16[] add(bf16[] %x.427, bf16[] %y.428)
}

%AddComputation.439 (x.440: bf16[], y.441: bf16[]) -> bf16[] {
  %x.440 = bf16[] parameter(0)
  %y.441 = bf16[] parameter(1)
  ROOT %add.442 = bf16[] add(bf16[] %x.440, bf16[] %y.441)
}

%AddComputation.452 (x.453: bf16[], y.454: bf16[]) -> bf16[] {
  %x.453 = bf16[] parameter(0)
  %y.454 = bf16[] parameter(1)
  ROOT %add.455 = bf16[] add(bf16[] %x.453, bf16[] %y.454)
}

%AddComputation.465 (x.466: bf16[], y.467: bf16[]) -> bf16[] {
  %x.466 = bf16[] parameter(0)
  %y.467 = bf16[] parameter(1)
  ROOT %add.468 = bf16[] add(bf16[] %x.466, bf16[] %y.467)
}

%AddComputation.478 (x.479: bf16[], y.480: bf16[]) -> bf16[] {
  %x.479 = bf16[] parameter(0)
  %y.480 = bf16[] parameter(1)
  ROOT %add.481 = bf16[] add(bf16[] %x.479, bf16[] %y.480)
}

%AddComputation.491 (x.492: bf16[], y.493: bf16[]) -> bf16[] {
  %x.492 = bf16[] parameter(0)
  %y.493 = bf16[] parameter(1)
  ROOT %add.494 = bf16[] add(bf16[] %x.492, bf16[] %y.493)
}

%AddComputation.504 (x.505: bf16[], y.506: bf16[]) -> bf16[] {
  %x.505 = bf16[] parameter(0)
  %y.506 = bf16[] parameter(1)
  ROOT %add.507 = bf16[] add(bf16[] %x.505, bf16[] %y.506)
}

%AddComputation.517 (x.518: bf16[], y.519: bf16[]) -> bf16[] {
  %x.518 = bf16[] parameter(0)
  %y.519 = bf16[] parameter(1)
  ROOT %add.520 = bf16[] add(bf16[] %x.518, bf16[] %y.519)
}

%AddComputation.530 (x.531: bf16[], y.532: bf16[]) -> bf16[] {
  %x.531 = bf16[] parameter(0)
  %y.532 = bf16[] parameter(1)
  ROOT %add.533 = bf16[] add(bf16[] %x.531, bf16[] %y.532)
}

%AddComputation.543 (x.544: bf16[], y.545: bf16[]) -> bf16[] {
  %x.544 = bf16[] parameter(0)
  %y.545 = bf16[] parameter(1)
  ROOT %add.546 = bf16[] add(bf16[] %x.544, bf16[] %y.545)
}

%AddComputation.556 (x.557: bf16[], y.558: bf16[]) -> bf16[] {
  %x.557 = bf16[] parameter(0)
  %y.558 = bf16[] parameter(1)
  ROOT %add.559 = bf16[] add(bf16[] %x.557, bf16[] %y.558)
}

%AddComputation.569 (x.570: bf16[], y.571: bf16[]) -> bf16[] {
  %x.570 = bf16[] parameter(0)
  %y.571 = bf16[] parameter(1)
  ROOT %add.572 = bf16[] add(bf16[] %x.570, bf16[] %y.571)
}

%AddComputation.582 (x.583: bf16[], y.584: bf16[]) -> bf16[] {
  %x.583 = bf16[] parameter(0)
  %y.584 = bf16[] parameter(1)
  ROOT %add.585 = bf16[] add(bf16[] %x.583, bf16[] %y.584)
}

%AddComputation.595 (x.596: bf16[], y.597: bf16[]) -> bf16[] {
  %x.596 = bf16[] parameter(0)
  %y.597 = bf16[] parameter(1)
  ROOT %add.598 = bf16[] add(bf16[] %x.596, bf16[] %y.597)
}

%AddComputation.608 (x.609: bf16[], y.610: bf16[]) -> bf16[] {
  %x.609 = bf16[] parameter(0)
  %y.610 = bf16[] parameter(1)
  ROOT %add.611 = bf16[] add(bf16[] %x.609, bf16[] %y.610)
}

ENTRY %SyncTensorsGraph.2312 (p0.8: bf16[], p1.10: f32[], p2.22: f32[], p3.23: f32[], p4.24: f32[1], p5.37: bf16[30522,16], p6.38: bf16[512,16], p7.39: bf16[2,16], p8.40: bf16[16,16], p9.41: bf16[16,16], p10.42: bf16[16,16], p11.43: bf16[16,16], p12.44: bf16[4096,16], p13.45: bf16[16,4096], p14.46: bf16[16,16], p15.47: bf16[16,16], p16.48: bf16[2,16], p17.49: bf16[16], p18.50: bf16[16], p19.51: bf16[16], p20.52: bf16[16], p21.53: bf16[16], p22.54: bf16[16], p23.55: bf16[16], p24.56: bf16[16], p25.57: bf16[4096], p26.58: bf16[16], p27.59: bf16[16], p28.60: bf16[16], p29.61: bf16[16], p30.62: bf16[30522], p31.63: bf16[16], p32.64: bf16[16], p33.65: bf16[16], p34.66: bf16[2], p35.616: bf16[1], p36.699: bf16[], p37.715: bf16[], p38.721: bf16[], p39.730: bf16[30522,16], p40.789: bf16[512,16], p41.848: bf16[2,16], p42.901: bf16[16], p43.952: bf16[16], p44.1009: bf16[16,16], p45.1062: bf16[16], p46.1119: bf16[16,16], p47.1172: bf16[16], p48.1229: bf16[16,16], p49.1282: bf16[16], p50.1339: bf16[16,16], p51.1392: bf16[16], p52.1443: bf16[16], p53.1494: bf16[16], p54.1551: bf16[4096,16], p55.1604: bf16[4096], p56.1661: bf16[16,4096], p57.1714: bf16[16], p58.1765: bf16[16], p59.1816: bf16[16], p60.1873: bf16[16,16], p61.1926: bf16[16], p62.1983: bf16[16,16], p63.2036: bf16[16], p64.2087: bf16[16], p65.2138: bf16[16], p66.2189: bf16[30522], p67.2246: bf16[2,16], p68.2299: bf16[2]) -> (bf16[30522,16], bf16[512,16], bf16[2,16], bf16[16], bf16[16], /*index=5*/bf16[16,16], bf16[16], bf16[16,16], bf16[16], bf16[16,16], /*index=10*/bf16[16], bf16[16,16], bf16[16], bf16[16], bf16[16], /*index=15*/bf16[4096,16], bf16[4096], bf16[16,4096], bf16[16], bf16[16], /*index=20*/bf16[16], bf16[16,16], bf16[16], bf16[16,16], bf16[16], /*index=25*/bf16[16], bf16[16], bf16[30522], bf16[2,16], bf16[2], /*index=30*/f32[1], f32[1], f32[1], bf16[30522,16], bf16[30522,16], /*index=35*/bf16[512,16], bf16[512,16], bf16[2,16], bf16[2,16], bf16[16,16], /*index=40*/bf16[16,16], bf16[16,16], bf16[16,16], bf16[16,16], bf16[16,16], /*index=45*/bf16[16,16], bf16[16,16], bf16[4096,16], bf16[4096,16], bf16[16,4096], /*index=50*/bf16[16,4096], bf16[16,16], bf16[16,16], bf16[16,16], bf16[16,16], /*index=55*/bf16[2,16], bf16[2,16], bf16[16], bf16[16], bf16[16], /*index=60*/bf16[16], bf16[16], bf16[16], bf16[16], bf16[16], /*index=65*/bf16[16], bf16[16], bf16[16], bf16[16], bf16[16], /*index=70*/bf16[16], bf16[16], bf16[16], bf16[4096], bf16[4096], /*index=75*/bf16[16], bf16[16], bf16[16], bf16[16], bf16[16], /*index=80*/bf16[16], bf16[16], bf16[16], bf16[30522], bf16[30522], /*index=85*/bf16[16], bf16[16], bf16[16], bf16[16], bf16[16], /*index=90*/bf16[16], bf16[2], bf16[2], bf16[1]) {
  %p39.730 = bf16[30522,16]{1,0} parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant = bf16[] constant(0)
  %p38.721 = bf16[] parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.0 = bf16[] multiply(bf16[] %constant, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.2 = bf16[30522,16]{1,0} broadcast(bf16[] %multiply.0), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %p34.66 = bf16[2]{0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p33.65 = bf16[16]{0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p32.64 = bf16[16]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p31.63 = bf16[16]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p30.62 = bf16[30522]{0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p29.61 = bf16[16]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p28.60 = bf16[16]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p27.59 = bf16[16]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p26.58 = bf16[16]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p25.57 = bf16[4096]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p24.56 = bf16[16]{0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p23.55 = bf16[16]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p22.54 = bf16[16]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p21.53 = bf16[16]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p20.52 = bf16[16]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p19.51 = bf16[16]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p18.50 = bf16[16]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p17.49 = bf16[16]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p16.48 = bf16[2,16]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p15.47 = bf16[16,16]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p14.46 = bf16[16,16]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p13.45 = bf16[16,4096]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p12.44 = bf16[4096,16]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p11.43 = bf16[16,16]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p10.42 = bf16[16,16]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p9.41 = bf16[16,16]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p8.40 = bf16[16,16]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p7.39 = bf16[2,16]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p6.38 = bf16[512,16]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p5.37 = bf16[30522,16]{1,0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p4.24 = f32[1]{0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=516}
  %p3.23 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=516}
  %reshape = f32[1]{0} reshape(f32[] %p3.23), metadata={op_type="aten__div" op_name="aten__div" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=516}
  %divide.26 = f32[1]{0} divide(f32[1]{0} %p4.24, f32[1]{0} %reshape), metadata={op_type="aten__div" op_name="aten__div" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=516}
  %p2.22 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %all-reduce.34 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %divide.26, f32[] %p2.22), replica_groups={{0,1}}, constrain_layout=true, to_apply=%AddComputation.30, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %get-tuple-element.36 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.34), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %convert.67 = bf16[] convert(f32[] %get-tuple-element.36), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.104 = (bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) all-reduce(bf16[2]{0} %p34.66, bf16[16]{0} %p33.65, bf16[16]{0} %p32.64, bf16[16]{0} %p31.63, bf16[30522]{0} %p30.62, /*index=5*/bf16[16]{0} %p29.61, bf16[16]{0} %p28.60, bf16[16]{0} %p27.59, bf16[16]{0} %p26.58, bf16[4096]{0} %p25.57, /*index=10*/bf16[16]{0} %p24.56, bf16[16]{0} %p23.55, bf16[16]{0} %p22.54, bf16[16]{0} %p21.53, bf16[16]{0} %p20.52, /*index=15*/bf16[16]{0} %p19.51, bf16[16]{0} %p18.50, bf16[16]{0} %p17.49, bf16[2,16]{1,0} %p16.48, bf16[16,16]{1,0} %p15.47, /*index=20*/bf16[16,16]{1,0} %p14.46, bf16[16,4096]{1,0} %p13.45, bf16[4096,16]{1,0} %p12.44, bf16[16,16]{1,0} %p11.43, bf16[16,16]{1,0} %p10.42, /*index=25*/bf16[16,16]{1,0} %p9.41, bf16[16,16]{1,0} %p8.40, bf16[2,16]{1,0} %p7.39, bf16[512,16]{1,0} %p6.38, bf16[30522,16]{1,0} %p5.37, /*index=30*/bf16[] %convert.67), replica_groups={{0,1}}, constrain_layout=true, to_apply=%AddComputation.100, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.221 = bf16[30522,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=29, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.2 = bf16[1]{0} constant({1})
  %p35.616 = bf16[1]{0} parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=114}
  %constant.222 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.223 = bf16[30522,16]{1,0} broadcast(bf16[] %constant.222), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.224 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %get-tuple-element.221, bf16[30522,16]{1,0} %broadcast.223), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.605 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %multiply.224, bf16[30522,16]{1,0} %multiply.224), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.606 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.612 = bf16[] reduce(bf16[30522,16]{1,0} %multiply.605, bf16[] %constant.606), dimensions={0,1}, to_apply=%AddComputation.608, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.613 = bf16[] sqrt(bf16[] %reduce.612), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.615 = bf16[] multiply(bf16[] %sqrt.613, bf16[] %sqrt.613), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.6 = bf16[1]{0} reshape(bf16[] %multiply.615), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.618 = bf16[1]{0} add(bf16[1]{0} %p35.616, bf16[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.217 = bf16[512,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=28, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.218 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.219 = bf16[512,16]{1,0} broadcast(bf16[] %constant.218), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.220 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %get-tuple-element.217, bf16[512,16]{1,0} %broadcast.219), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.592 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %multiply.220, bf16[512,16]{1,0} %multiply.220), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.593 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.599 = bf16[] reduce(bf16[512,16]{1,0} %multiply.592, bf16[] %constant.593), dimensions={0,1}, to_apply=%AddComputation.595, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.600 = bf16[] sqrt(bf16[] %reduce.599), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.602 = bf16[] multiply(bf16[] %sqrt.600, bf16[] %sqrt.600), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.7 = bf16[1]{0} reshape(bf16[] %multiply.602), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.620 = bf16[1]{0} add(bf16[1]{0} %add.618, bf16[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.213 = bf16[2,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=27, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.214 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.215 = bf16[2,16]{1,0} broadcast(bf16[] %constant.214), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.216 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %get-tuple-element.213, bf16[2,16]{1,0} %broadcast.215), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.579 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.216, bf16[2,16]{1,0} %multiply.216), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.580 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.586 = bf16[] reduce(bf16[2,16]{1,0} %multiply.579, bf16[] %constant.580), dimensions={0,1}, to_apply=%AddComputation.582, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.587 = bf16[] sqrt(bf16[] %reduce.586), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.589 = bf16[] multiply(bf16[] %sqrt.587, bf16[] %sqrt.587), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.8 = bf16[1]{0} reshape(bf16[] %multiply.589), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.622 = bf16[1]{0} add(bf16[1]{0} %add.620, bf16[1]{0} %reshape.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.173 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=17, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.174 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.175 = bf16[16]{0} broadcast(bf16[] %constant.174), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.176 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.173, bf16[16]{0} %broadcast.175), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.566 = bf16[16]{0} multiply(bf16[16]{0} %multiply.176, bf16[16]{0} %multiply.176), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.567 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.573 = bf16[] reduce(bf16[16]{0} %multiply.566, bf16[] %constant.567), dimensions={0}, to_apply=%AddComputation.569, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.574 = bf16[] sqrt(bf16[] %reduce.573), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.576 = bf16[] multiply(bf16[] %sqrt.574, bf16[] %sqrt.574), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.9 = bf16[1]{0} reshape(bf16[] %multiply.576), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.624 = bf16[1]{0} add(bf16[1]{0} %add.622, bf16[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.169 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=16, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.170 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.171 = bf16[16]{0} broadcast(bf16[] %constant.170), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.172 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.169, bf16[16]{0} %broadcast.171), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.553 = bf16[16]{0} multiply(bf16[16]{0} %multiply.172, bf16[16]{0} %multiply.172), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.554 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.560 = bf16[] reduce(bf16[16]{0} %multiply.553, bf16[] %constant.554), dimensions={0}, to_apply=%AddComputation.556, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.561 = bf16[] sqrt(bf16[] %reduce.560), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.563 = bf16[] multiply(bf16[] %sqrt.561, bf16[] %sqrt.561), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.10 = bf16[1]{0} reshape(bf16[] %multiply.563), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.626 = bf16[1]{0} add(bf16[1]{0} %add.624, bf16[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.153 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=12, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.154 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.155 = bf16[16]{0} broadcast(bf16[] %constant.154), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.156 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.153, bf16[16]{0} %broadcast.155), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.540 = bf16[16]{0} multiply(bf16[16]{0} %multiply.156, bf16[16]{0} %multiply.156), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.541 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.547 = bf16[] reduce(bf16[16]{0} %multiply.540, bf16[] %constant.541), dimensions={0}, to_apply=%AddComputation.543, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.548 = bf16[] sqrt(bf16[] %reduce.547), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.550 = bf16[] multiply(bf16[] %sqrt.548, bf16[] %sqrt.548), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.11 = bf16[1]{0} reshape(bf16[] %multiply.550), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.628 = bf16[1]{0} add(bf16[1]{0} %add.626, bf16[1]{0} %reshape.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.149 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=11, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.150 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.151 = bf16[16]{0} broadcast(bf16[] %constant.150), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.152 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.149, bf16[16]{0} %broadcast.151), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.527 = bf16[16]{0} multiply(bf16[16]{0} %multiply.152, bf16[16]{0} %multiply.152), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.528 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.534 = bf16[] reduce(bf16[16]{0} %multiply.527, bf16[] %constant.528), dimensions={0}, to_apply=%AddComputation.530, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.535 = bf16[] sqrt(bf16[] %reduce.534), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.537 = bf16[] multiply(bf16[] %sqrt.535, bf16[] %sqrt.535), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.13 = bf16[1]{0} reshape(bf16[] %multiply.537), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.630 = bf16[1]{0} add(bf16[1]{0} %add.628, bf16[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.145 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.146 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.147 = bf16[16]{0} broadcast(bf16[] %constant.146), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.148 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.145, bf16[16]{0} %broadcast.147), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.514 = bf16[16]{0} multiply(bf16[16]{0} %multiply.148, bf16[16]{0} %multiply.148), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.515 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.521 = bf16[] reduce(bf16[16]{0} %multiply.514, bf16[] %constant.515), dimensions={0}, to_apply=%AddComputation.517, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.522 = bf16[] sqrt(bf16[] %reduce.521), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.524 = bf16[] multiply(bf16[] %sqrt.522, bf16[] %sqrt.522), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.14 = bf16[1]{0} reshape(bf16[] %multiply.524), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.632 = bf16[1]{0} add(bf16[1]{0} %add.630, bf16[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.193 = bf16[4096,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=22, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.194 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.195 = bf16[4096,16]{1,0} broadcast(bf16[] %constant.194), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.196 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %get-tuple-element.193, bf16[4096,16]{1,0} %broadcast.195), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.501 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %multiply.196, bf16[4096,16]{1,0} %multiply.196), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.502 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.508 = bf16[] reduce(bf16[4096,16]{1,0} %multiply.501, bf16[] %constant.502), dimensions={0,1}, to_apply=%AddComputation.504, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.509 = bf16[] sqrt(bf16[] %reduce.508), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.511 = bf16[] multiply(bf16[] %sqrt.509, bf16[] %sqrt.509), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.15 = bf16[1]{0} reshape(bf16[] %multiply.511), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.634 = bf16[1]{0} add(bf16[1]{0} %add.632, bf16[1]{0} %reshape.15), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.141 = bf16[4096]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=9, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.142 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.143 = bf16[4096]{0} broadcast(bf16[] %constant.142), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.144 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.141, bf16[4096]{0} %broadcast.143), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.488 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.144, bf16[4096]{0} %multiply.144), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.489 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.495 = bf16[] reduce(bf16[4096]{0} %multiply.488, bf16[] %constant.489), dimensions={0}, to_apply=%AddComputation.491, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.496 = bf16[] sqrt(bf16[] %reduce.495), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.498 = bf16[] multiply(bf16[] %sqrt.496, bf16[] %sqrt.496), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.16 = bf16[1]{0} reshape(bf16[] %multiply.498), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.636 = bf16[1]{0} add(bf16[1]{0} %add.634, bf16[1]{0} %reshape.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.189 = bf16[16,4096]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=21, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.190 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.191 = bf16[16,4096]{1,0} broadcast(bf16[] %constant.190), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.192 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %get-tuple-element.189, bf16[16,4096]{1,0} %broadcast.191), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.475 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %multiply.192, bf16[16,4096]{1,0} %multiply.192), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.476 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.482 = bf16[] reduce(bf16[16,4096]{1,0} %multiply.475, bf16[] %constant.476), dimensions={0,1}, to_apply=%AddComputation.478, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.483 = bf16[] sqrt(bf16[] %reduce.482), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.485 = bf16[] multiply(bf16[] %sqrt.483, bf16[] %sqrt.483), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.17 = bf16[1]{0} reshape(bf16[] %multiply.485), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.638 = bf16[1]{0} add(bf16[1]{0} %add.636, bf16[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.137 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=8, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.138 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.139 = bf16[16]{0} broadcast(bf16[] %constant.138), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.140 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.137, bf16[16]{0} %broadcast.139), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.462 = bf16[16]{0} multiply(bf16[16]{0} %multiply.140, bf16[16]{0} %multiply.140), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.463 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.469 = bf16[] reduce(bf16[16]{0} %multiply.462, bf16[] %constant.463), dimensions={0}, to_apply=%AddComputation.465, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.470 = bf16[] sqrt(bf16[] %reduce.469), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.472 = bf16[] multiply(bf16[] %sqrt.470, bf16[] %sqrt.470), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.19 = bf16[1]{0} reshape(bf16[] %multiply.472), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.640 = bf16[1]{0} add(bf16[1]{0} %add.638, bf16[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.133 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=7, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.134 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.135 = bf16[16]{0} broadcast(bf16[] %constant.134), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.136 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.133, bf16[16]{0} %broadcast.135), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.449 = bf16[16]{0} multiply(bf16[16]{0} %multiply.136, bf16[16]{0} %multiply.136), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.450 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.456 = bf16[] reduce(bf16[16]{0} %multiply.449, bf16[] %constant.450), dimensions={0}, to_apply=%AddComputation.452, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.457 = bf16[] sqrt(bf16[] %reduce.456), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.459 = bf16[] multiply(bf16[] %sqrt.457, bf16[] %sqrt.457), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.20 = bf16[1]{0} reshape(bf16[] %multiply.459), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.642 = bf16[1]{0} add(bf16[1]{0} %add.640, bf16[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.129 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=6, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.130 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.131 = bf16[16]{0} broadcast(bf16[] %constant.130), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.132 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.129, bf16[16]{0} %broadcast.131), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.436 = bf16[16]{0} multiply(bf16[16]{0} %multiply.132, bf16[16]{0} %multiply.132), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.437 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.443 = bf16[] reduce(bf16[16]{0} %multiply.436, bf16[] %constant.437), dimensions={0}, to_apply=%AddComputation.439, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.444 = bf16[] sqrt(bf16[] %reduce.443), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.446 = bf16[] multiply(bf16[] %sqrt.444, bf16[] %sqrt.444), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.21 = bf16[1]{0} reshape(bf16[] %multiply.446), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.644 = bf16[1]{0} add(bf16[1]{0} %add.642, bf16[1]{0} %reshape.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.185 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=20, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.186 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.187 = bf16[16,16]{1,0} broadcast(bf16[] %constant.186), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.188 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.185, bf16[16,16]{1,0} %broadcast.187), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.423 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.188, bf16[16,16]{1,0} %multiply.188), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.424 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.430 = bf16[] reduce(bf16[16,16]{1,0} %multiply.423, bf16[] %constant.424), dimensions={0,1}, to_apply=%AddComputation.426, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.431 = bf16[] sqrt(bf16[] %reduce.430), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.433 = bf16[] multiply(bf16[] %sqrt.431, bf16[] %sqrt.431), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.22 = bf16[1]{0} reshape(bf16[] %multiply.433), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.646 = bf16[1]{0} add(bf16[1]{0} %add.644, bf16[1]{0} %reshape.22), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.125 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=5, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.126 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.127 = bf16[16]{0} broadcast(bf16[] %constant.126), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.128 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.125, bf16[16]{0} %broadcast.127), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.410 = bf16[16]{0} multiply(bf16[16]{0} %multiply.128, bf16[16]{0} %multiply.128), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.411 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.417 = bf16[] reduce(bf16[16]{0} %multiply.410, bf16[] %constant.411), dimensions={0}, to_apply=%AddComputation.413, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.418 = bf16[] sqrt(bf16[] %reduce.417), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.420 = bf16[] multiply(bf16[] %sqrt.418, bf16[] %sqrt.418), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.23 = bf16[1]{0} reshape(bf16[] %multiply.420), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.648 = bf16[1]{0} add(bf16[1]{0} %add.646, bf16[1]{0} %reshape.23), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.121 = bf16[30522]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=4, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.122 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.123 = bf16[30522]{0} broadcast(bf16[] %constant.122), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.124 = bf16[30522]{0} multiply(bf16[30522]{0} %get-tuple-element.121, bf16[30522]{0} %broadcast.123), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.397 = bf16[30522]{0} multiply(bf16[30522]{0} %multiply.124, bf16[30522]{0} %multiply.124), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.398 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.404 = bf16[] reduce(bf16[30522]{0} %multiply.397, bf16[] %constant.398), dimensions={0}, to_apply=%AddComputation.400, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.405 = bf16[] sqrt(bf16[] %reduce.404), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.407 = bf16[] multiply(bf16[] %sqrt.405, bf16[] %sqrt.405), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.24 = bf16[1]{0} reshape(bf16[] %multiply.407), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.650 = bf16[1]{0} add(bf16[1]{0} %add.648, bf16[1]{0} %reshape.24), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.181 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=19, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.182 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.183 = bf16[16,16]{1,0} broadcast(bf16[] %constant.182), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.184 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.181, bf16[16,16]{1,0} %broadcast.183), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.384 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.184, bf16[16,16]{1,0} %multiply.184), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.385 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.391 = bf16[] reduce(bf16[16,16]{1,0} %multiply.384, bf16[] %constant.385), dimensions={0,1}, to_apply=%AddComputation.387, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.392 = bf16[] sqrt(bf16[] %reduce.391), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.394 = bf16[] multiply(bf16[] %sqrt.392, bf16[] %sqrt.392), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.25 = bf16[1]{0} reshape(bf16[] %multiply.394), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.652 = bf16[1]{0} add(bf16[1]{0} %add.650, bf16[1]{0} %reshape.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.117 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=3, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.118 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.119 = bf16[16]{0} broadcast(bf16[] %constant.118), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.120 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.117, bf16[16]{0} %broadcast.119), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.371 = bf16[16]{0} multiply(bf16[16]{0} %multiply.120, bf16[16]{0} %multiply.120), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.372 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.378 = bf16[] reduce(bf16[16]{0} %multiply.371, bf16[] %constant.372), dimensions={0}, to_apply=%AddComputation.374, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.379 = bf16[] sqrt(bf16[] %reduce.378), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.381 = bf16[] multiply(bf16[] %sqrt.379, bf16[] %sqrt.379), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.26 = bf16[1]{0} reshape(bf16[] %multiply.381), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.654 = bf16[1]{0} add(bf16[1]{0} %add.652, bf16[1]{0} %reshape.26), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.113 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.114 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.115 = bf16[16]{0} broadcast(bf16[] %constant.114), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.116 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.113, bf16[16]{0} %broadcast.115), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.358 = bf16[16]{0} multiply(bf16[16]{0} %multiply.116, bf16[16]{0} %multiply.116), metadata={op_type="aten__mul" op_name="aten__norm.20/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.359 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.365 = bf16[] reduce(bf16[16]{0} %multiply.358, bf16[] %constant.359), dimensions={0}, to_apply=%AddComputation.361, metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.366 = bf16[] sqrt(bf16[] %reduce.365), metadata={op_type="aten__sqrt" op_name="aten__norm.20/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.368 = bf16[] multiply(bf16[] %sqrt.366, bf16[] %sqrt.366), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.27 = bf16[1]{0} reshape(bf16[] %multiply.368), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.656 = bf16[1]{0} add(bf16[1]{0} %add.654, bf16[1]{0} %reshape.27), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.109 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.110 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.111 = bf16[16]{0} broadcast(bf16[] %constant.110), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.112 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.109, bf16[16]{0} %broadcast.111), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.345 = bf16[16]{0} multiply(bf16[16]{0} %multiply.112, bf16[16]{0} %multiply.112), metadata={op_type="aten__mul" op_name="aten__norm.21/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.346 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.352 = bf16[] reduce(bf16[16]{0} %multiply.345, bf16[] %constant.346), dimensions={0}, to_apply=%AddComputation.348, metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.353 = bf16[] sqrt(bf16[] %reduce.352), metadata={op_type="aten__sqrt" op_name="aten__norm.21/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.355 = bf16[] multiply(bf16[] %sqrt.353, bf16[] %sqrt.353), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.28 = bf16[1]{0} reshape(bf16[] %multiply.355), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.658 = bf16[1]{0} add(bf16[1]{0} %add.656, bf16[1]{0} %reshape.28), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.177 = bf16[2,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=18, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.178 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.179 = bf16[2,16]{1,0} broadcast(bf16[] %constant.178), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.180 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %get-tuple-element.177, bf16[2,16]{1,0} %broadcast.179), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.332 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.180, bf16[2,16]{1,0} %multiply.180), metadata={op_type="aten__mul" op_name="aten__norm.22/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.333 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.339 = bf16[] reduce(bf16[2,16]{1,0} %multiply.332, bf16[] %constant.333), dimensions={0,1}, to_apply=%AddComputation.335, metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.340 = bf16[] sqrt(bf16[] %reduce.339), metadata={op_type="aten__sqrt" op_name="aten__norm.22/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.342 = bf16[] multiply(bf16[] %sqrt.340, bf16[] %sqrt.340), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.29 = bf16[1]{0} reshape(bf16[] %multiply.342), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.660 = bf16[1]{0} add(bf16[1]{0} %add.658, bf16[1]{0} %reshape.29), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.105 = bf16[2]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.106 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.107 = bf16[2]{0} broadcast(bf16[] %constant.106), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.108 = bf16[2]{0} multiply(bf16[2]{0} %get-tuple-element.105, bf16[2]{0} %broadcast.107), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.319 = bf16[2]{0} multiply(bf16[2]{0} %multiply.108, bf16[2]{0} %multiply.108), metadata={op_type="aten__mul" op_name="aten__norm.23/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.320 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.326 = bf16[] reduce(bf16[2]{0} %multiply.319, bf16[] %constant.320), dimensions={0}, to_apply=%AddComputation.322, metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.327 = bf16[] sqrt(bf16[] %reduce.326), metadata={op_type="aten__sqrt" op_name="aten__norm.23/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.329 = bf16[] multiply(bf16[] %sqrt.327, bf16[] %sqrt.327), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.30 = bf16[1]{0} reshape(bf16[] %multiply.329), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.662 = bf16[1]{0} add(bf16[1]{0} %add.660, bf16[1]{0} %reshape.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.209 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=26, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.210 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.211 = bf16[16,16]{1,0} broadcast(bf16[] %constant.210), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.212 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.209, bf16[16,16]{1,0} %broadcast.211), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.305 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.212, bf16[16,16]{1,0} %multiply.212), metadata={op_type="aten__mul" op_name="aten__norm.24/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.306 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.312 = bf16[] reduce(bf16[16,16]{1,0} %multiply.305, bf16[] %constant.306), dimensions={0,1}, to_apply=%AddComputation.308, metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.313 = bf16[] sqrt(bf16[] %reduce.312), metadata={op_type="aten__sqrt" op_name="aten__norm.24/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.315 = bf16[] multiply(bf16[] %sqrt.313, bf16[] %sqrt.313), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.32 = bf16[1]{0} reshape(bf16[] %multiply.315), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.666 = bf16[1]{0} add(bf16[1]{0} %add.662, bf16[1]{0} %reshape.32), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.165 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=15, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.166 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.167 = bf16[16]{0} broadcast(bf16[] %constant.166), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.168 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.165, bf16[16]{0} %broadcast.167), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.292 = bf16[16]{0} multiply(bf16[16]{0} %multiply.168, bf16[16]{0} %multiply.168), metadata={op_type="aten__mul" op_name="aten__norm.25/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.293 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.299 = bf16[] reduce(bf16[16]{0} %multiply.292, bf16[] %constant.293), dimensions={0}, to_apply=%AddComputation.295, metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.300 = bf16[] sqrt(bf16[] %reduce.299), metadata={op_type="aten__sqrt" op_name="aten__norm.25/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.302 = bf16[] multiply(bf16[] %sqrt.300, bf16[] %sqrt.300), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.33 = bf16[1]{0} reshape(bf16[] %multiply.302), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.668 = bf16[1]{0} add(bf16[1]{0} %add.666, bf16[1]{0} %reshape.33), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.205 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.206 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.207 = bf16[16,16]{1,0} broadcast(bf16[] %constant.206), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.208 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.205, bf16[16,16]{1,0} %broadcast.207), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.279 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.208, bf16[16,16]{1,0} %multiply.208), metadata={op_type="aten__mul" op_name="aten__norm.26/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.280 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.286 = bf16[] reduce(bf16[16,16]{1,0} %multiply.279, bf16[] %constant.280), dimensions={0,1}, to_apply=%AddComputation.282, metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.287 = bf16[] sqrt(bf16[] %reduce.286), metadata={op_type="aten__sqrt" op_name="aten__norm.26/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.289 = bf16[] multiply(bf16[] %sqrt.287, bf16[] %sqrt.287), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.34 = bf16[1]{0} reshape(bf16[] %multiply.289), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.670 = bf16[1]{0} add(bf16[1]{0} %add.668, bf16[1]{0} %reshape.34), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.161 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=14, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.162 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.163 = bf16[16]{0} broadcast(bf16[] %constant.162), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.164 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.161, bf16[16]{0} %broadcast.163), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.266 = bf16[16]{0} multiply(bf16[16]{0} %multiply.164, bf16[16]{0} %multiply.164), metadata={op_type="aten__mul" op_name="aten__norm.27/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.267 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.273 = bf16[] reduce(bf16[16]{0} %multiply.266, bf16[] %constant.267), dimensions={0}, to_apply=%AddComputation.269, metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.274 = bf16[] sqrt(bf16[] %reduce.273), metadata={op_type="aten__sqrt" op_name="aten__norm.27/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.276 = bf16[] multiply(bf16[] %sqrt.274, bf16[] %sqrt.274), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.35 = bf16[1]{0} reshape(bf16[] %multiply.276), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.672 = bf16[1]{0} add(bf16[1]{0} %add.670, bf16[1]{0} %reshape.35), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.201 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=24, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.202 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.203 = bf16[16,16]{1,0} broadcast(bf16[] %constant.202), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.204 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.201, bf16[16,16]{1,0} %broadcast.203), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.253 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.204, bf16[16,16]{1,0} %multiply.204), metadata={op_type="aten__mul" op_name="aten__norm.28/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.254 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.260 = bf16[] reduce(bf16[16,16]{1,0} %multiply.253, bf16[] %constant.254), dimensions={0,1}, to_apply=%AddComputation.256, metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.261 = bf16[] sqrt(bf16[] %reduce.260), metadata={op_type="aten__sqrt" op_name="aten__norm.28/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.263 = bf16[] multiply(bf16[] %sqrt.261, bf16[] %sqrt.261), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.36 = bf16[1]{0} reshape(bf16[] %multiply.263), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.674 = bf16[1]{0} add(bf16[1]{0} %add.672, bf16[1]{0} %reshape.36), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.157 = bf16[16]{0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=13, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.158 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.159 = bf16[16]{0} broadcast(bf16[] %constant.158), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.160 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.157, bf16[16]{0} %broadcast.159), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.240 = bf16[16]{0} multiply(bf16[16]{0} %multiply.160, bf16[16]{0} %multiply.160), metadata={op_type="aten__mul" op_name="aten__norm.29/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.241 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.247 = bf16[] reduce(bf16[16]{0} %multiply.240, bf16[] %constant.241), dimensions={0}, to_apply=%AddComputation.243, metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.248 = bf16[] sqrt(bf16[] %reduce.247), metadata={op_type="aten__sqrt" op_name="aten__norm.29/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.250 = bf16[] multiply(bf16[] %sqrt.248, bf16[] %sqrt.248), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.37 = bf16[1]{0} reshape(bf16[] %multiply.250), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.676 = bf16[1]{0} add(bf16[1]{0} %add.674, bf16[1]{0} %reshape.37), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.197 = bf16[16,16]{1,0} get-tuple-element((bf16[2]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, /*index=5*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, /*index=10*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=20*/bf16[16,16]{1,0}, bf16[16,4096]{1,0}, bf16[4096,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=25*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[2,16]{1,0}, bf16[512,16]{1,0}, bf16[30522,16]{1,0}, /*index=30*/bf16[]) %all-reduce.104), index=23, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.198 = bf16[] constant(0.5), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.199 = bf16[16,16]{1,0} broadcast(bf16[] %constant.198), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.200 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.197, bf16[16,16]{1,0} %broadcast.199), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.227 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.200, bf16[16,16]{1,0} %multiply.200), metadata={op_type="aten__mul" op_name="aten__norm.30/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.228 = bf16[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.234 = bf16[] reduce(bf16[16,16]{1,0} %multiply.227, bf16[] %constant.228), dimensions={0,1}, to_apply=%AddComputation.230, metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.235 = bf16[] sqrt(bf16[] %reduce.234), metadata={op_type="aten__sqrt" op_name="aten__norm.30/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.237 = bf16[] multiply(bf16[] %sqrt.235, bf16[] %sqrt.235), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.38 = bf16[1]{0} reshape(bf16[] %multiply.237), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.678 = bf16[1]{0} add(bf16[1]{0} %add.676, bf16[1]{0} %reshape.38), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %constant.4 = bf16[1]{0} constant({0.5})
  %power.679 = bf16[1]{0} power(bf16[1]{0} %add.678, bf16[1]{0} %constant.4), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=137}
  %p0.8 = bf16[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %reshape.40 = bf16[1]{0} reshape(bf16[] %p0.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %add.681 = bf16[1]{0} add(bf16[1]{0} %power.679, bf16[1]{0} %reshape.40), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %divide.684 = bf16[1]{0} divide(bf16[1]{0} %constant.2, bf16[1]{0} %add.681), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=913}
  %constant.9 = bf16[1]{0} constant({1})
  %compare.691 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.9), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.10 = bf16[1]{0} constant({1})
  %select.693 = bf16[1]{0} select(pred[1]{0} %compare.691, bf16[1]{0} %divide.684, bf16[1]{0} %constant.10), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.225 = bf16[1]{0} constant({0.5})
  %multiply.167 = bf16[1]{0} multiply(bf16[1]{0} %select.693, bf16[1]{0} %constant.225), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.650 = bf16[] reshape(bf16[1]{0} %multiply.167), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.6 = bf16[30522,16]{1,0} broadcast(bf16[] %reshape.650), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.698 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %get-tuple-element.221, bf16[30522,16]{1,0} %broadcast.6), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %p37.715 = bf16[] parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.719 = bf16[30522,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.720 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %multiply.698, bf16[30522,16]{1,0} %broadcast.719), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.729 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %broadcast.2, bf16[30522,16]{1,0} %multiply.720), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.12 = bf16[] constant(0)
  %p36.699 = bf16[] parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.35 = bf16[] multiply(bf16[] %constant.12, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.9 = bf16[30522,16]{1,0} broadcast(bf16[] %multiply.35), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.708 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %multiply.698, bf16[30522,16]{1,0} %multiply.698), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %p1.10 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.707 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.709 = bf16[30522,16]{1,0} broadcast(bf16[] %convert.707), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.710 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %multiply.708, bf16[30522,16]{1,0} %broadcast.709), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.711 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %broadcast.9, bf16[30522,16]{1,0} %multiply.710), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.712 = bf16[30522,16]{1,0} sqrt(bf16[30522,16]{1,0} %add.711), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.713 = bf16[30522,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.714 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %sqrt.712, bf16[30522,16]{1,0} %broadcast.713), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.732 = bf16[30522,16]{1,0} divide(bf16[30522,16]{1,0} %add.729, bf16[30522,16]{1,0} %add.714), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.13 = bf16[] constant(-0)
  %broadcast.733 = bf16[30522,16]{1,0} broadcast(bf16[] %constant.13), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.734 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %divide.732, bf16[30522,16]{1,0} %broadcast.733), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.735 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %p39.730, bf16[30522,16]{1,0} %multiply.734), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.5 = bf16[30522,16]{1,0} broadcast(bf16[] %constant.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.736 = bf16[30522,16]{1,0} multiply(bf16[30522,16]{1,0} %add.735, bf16[30522,16]{1,0} %broadcast.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.737 = bf16[30522,16]{1,0} add(bf16[30522,16]{1,0} %add.735, bf16[30522,16]{1,0} %multiply.736), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p40.789 = bf16[512,16]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.16 = bf16[] constant(0)
  %multiply.36 = bf16[] multiply(bf16[] %constant.16, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.12 = bf16[512,16]{1,0} broadcast(bf16[] %multiply.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.19 = bf16[1]{0} constant({1})
  %compare.753 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.19), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.22 = bf16[1]{0} constant({1})
  %select.755 = bf16[1]{0} select(pred[1]{0} %compare.753, bf16[1]{0} %divide.684, bf16[1]{0} %constant.22), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.226 = bf16[1]{0} constant({0.5})
  %multiply.169 = bf16[1]{0} multiply(bf16[1]{0} %select.755, bf16[1]{0} %constant.226), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.653 = bf16[] reshape(bf16[1]{0} %multiply.169), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.15 = bf16[512,16]{1,0} broadcast(bf16[] %reshape.653), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.760 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %get-tuple-element.217, bf16[512,16]{1,0} %broadcast.15), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.779 = bf16[512,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.780 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %multiply.760, bf16[512,16]{1,0} %broadcast.779), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.788 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %broadcast.12, bf16[512,16]{1,0} %multiply.780), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.23 = bf16[] constant(0)
  %multiply.39 = bf16[] multiply(bf16[] %constant.23, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.18 = bf16[512,16]{1,0} broadcast(bf16[] %multiply.39), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.769 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %multiply.760, bf16[512,16]{1,0} %multiply.760), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.768 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.770 = bf16[512,16]{1,0} broadcast(bf16[] %convert.768), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.771 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %multiply.769, bf16[512,16]{1,0} %broadcast.770), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.772 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %broadcast.18, bf16[512,16]{1,0} %multiply.771), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.773 = bf16[512,16]{1,0} sqrt(bf16[512,16]{1,0} %add.772), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.774 = bf16[512,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.775 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %sqrt.773, bf16[512,16]{1,0} %broadcast.774), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.791 = bf16[512,16]{1,0} divide(bf16[512,16]{1,0} %add.788, bf16[512,16]{1,0} %add.775), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.24 = bf16[] constant(-0)
  %broadcast.792 = bf16[512,16]{1,0} broadcast(bf16[] %constant.24), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.793 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %divide.791, bf16[512,16]{1,0} %broadcast.792), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.794 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %p40.789, bf16[512,16]{1,0} %multiply.793), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.738 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.742 = bf16[512,16]{1,0} broadcast(bf16[] %constant.738), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.795 = bf16[512,16]{1,0} multiply(bf16[512,16]{1,0} %add.794, bf16[512,16]{1,0} %broadcast.742), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.796 = bf16[512,16]{1,0} add(bf16[512,16]{1,0} %add.794, bf16[512,16]{1,0} %multiply.795), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p41.848 = bf16[2,16]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.25 = bf16[] constant(0)
  %multiply.40 = bf16[] multiply(bf16[] %constant.25, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.22 = bf16[2,16]{1,0} broadcast(bf16[] %multiply.40), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.27 = bf16[1]{0} constant({1})
  %compare.812 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.27), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.28 = bf16[1]{0} constant({1})
  %select.814 = bf16[1]{0} select(pred[1]{0} %compare.812, bf16[1]{0} %divide.684, bf16[1]{0} %constant.28), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.227 = bf16[1]{0} constant({0.5})
  %multiply.170 = bf16[1]{0} multiply(bf16[1]{0} %select.814, bf16[1]{0} %constant.227), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.656 = bf16[] reshape(bf16[1]{0} %multiply.170), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.24 = bf16[2,16]{1,0} broadcast(bf16[] %reshape.656), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.819 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %get-tuple-element.213, bf16[2,16]{1,0} %broadcast.24), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.838 = bf16[2,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.839 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.819, bf16[2,16]{1,0} %broadcast.838), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.847 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %broadcast.22, bf16[2,16]{1,0} %multiply.839), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.29 = bf16[] constant(0)
  %multiply.43 = bf16[] multiply(bf16[] %constant.29, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.28 = bf16[2,16]{1,0} broadcast(bf16[] %multiply.43), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.828 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.819, bf16[2,16]{1,0} %multiply.819), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.827 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.829 = bf16[2,16]{1,0} broadcast(bf16[] %convert.827), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.830 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.828, bf16[2,16]{1,0} %broadcast.829), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.831 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %broadcast.28, bf16[2,16]{1,0} %multiply.830), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.832 = bf16[2,16]{1,0} sqrt(bf16[2,16]{1,0} %add.831), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.833 = bf16[2,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.834 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %sqrt.832, bf16[2,16]{1,0} %broadcast.833), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.850 = bf16[2,16]{1,0} divide(bf16[2,16]{1,0} %add.847, bf16[2,16]{1,0} %add.834), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.30 = bf16[] constant(-0)
  %broadcast.851 = bf16[2,16]{1,0} broadcast(bf16[] %constant.30), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.852 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %divide.850, bf16[2,16]{1,0} %broadcast.851), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.853 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %p41.848, bf16[2,16]{1,0} %multiply.852), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.797 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.801 = bf16[2,16]{1,0} broadcast(bf16[] %constant.797), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.854 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %add.853, bf16[2,16]{1,0} %broadcast.801), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.855 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %add.853, bf16[2,16]{1,0} %multiply.854), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p42.901 = bf16[16]{0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.31 = bf16[] constant(0)
  %multiply.44 = bf16[] multiply(bf16[] %constant.31, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.31 = bf16[16]{0} broadcast(bf16[] %multiply.44), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.33 = bf16[1]{0} constant({1})
  %compare.866 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.33), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.34 = bf16[1]{0} constant({1})
  %select.868 = bf16[1]{0} select(pred[1]{0} %compare.866, bf16[1]{0} %divide.684, bf16[1]{0} %constant.34), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.230 = bf16[1]{0} constant({0.5})
  %multiply.171 = bf16[1]{0} multiply(bf16[1]{0} %select.868, bf16[1]{0} %constant.230), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.659 = bf16[] reshape(bf16[1]{0} %multiply.171), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.32 = bf16[16]{0} broadcast(bf16[] %reshape.659), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.872 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.173, bf16[16]{0} %broadcast.32), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.891 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.892 = bf16[16]{0} multiply(bf16[16]{0} %multiply.872, bf16[16]{0} %broadcast.891), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.900 = bf16[16]{0} add(bf16[16]{0} %broadcast.31, bf16[16]{0} %multiply.892), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.35 = bf16[] constant(0)
  %multiply.47 = bf16[] multiply(bf16[] %constant.35, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.35 = bf16[16]{0} broadcast(bf16[] %multiply.47), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.881 = bf16[16]{0} multiply(bf16[16]{0} %multiply.872, bf16[16]{0} %multiply.872), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.880 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.882 = bf16[16]{0} broadcast(bf16[] %convert.880), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.883 = bf16[16]{0} multiply(bf16[16]{0} %multiply.881, bf16[16]{0} %broadcast.882), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.884 = bf16[16]{0} add(bf16[16]{0} %broadcast.35, bf16[16]{0} %multiply.883), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.885 = bf16[16]{0} sqrt(bf16[16]{0} %add.884), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.886 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.887 = bf16[16]{0} add(bf16[16]{0} %sqrt.885, bf16[16]{0} %broadcast.886), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.903 = bf16[16]{0} divide(bf16[16]{0} %add.900, bf16[16]{0} %add.887), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.36 = bf16[] constant(-0)
  %broadcast.904 = bf16[16]{0} broadcast(bf16[] %constant.36), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.905 = bf16[16]{0} multiply(bf16[16]{0} %divide.903, bf16[16]{0} %broadcast.904), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.906 = bf16[16]{0} add(bf16[16]{0} %p42.901, bf16[16]{0} %multiply.905), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p43.952 = bf16[16]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.37 = bf16[] constant(0)
  %multiply.48 = bf16[] multiply(bf16[] %constant.37, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.38 = bf16[16]{0} broadcast(bf16[] %multiply.48), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.39 = bf16[1]{0} constant({1})
  %compare.917 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.39), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.40 = bf16[1]{0} constant({1})
  %select.919 = bf16[1]{0} select(pred[1]{0} %compare.917, bf16[1]{0} %divide.684, bf16[1]{0} %constant.40), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.231 = bf16[1]{0} constant({0.5})
  %multiply.173 = bf16[1]{0} multiply(bf16[1]{0} %select.919, bf16[1]{0} %constant.231), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.662 = bf16[] reshape(bf16[1]{0} %multiply.173), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.39 = bf16[16]{0} broadcast(bf16[] %reshape.662), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.923 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.169, bf16[16]{0} %broadcast.39), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.942 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.943 = bf16[16]{0} multiply(bf16[16]{0} %multiply.923, bf16[16]{0} %broadcast.942), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.951 = bf16[16]{0} add(bf16[16]{0} %broadcast.38, bf16[16]{0} %multiply.943), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.41 = bf16[] constant(0)
  %multiply.51 = bf16[] multiply(bf16[] %constant.41, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.42 = bf16[16]{0} broadcast(bf16[] %multiply.51), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.932 = bf16[16]{0} multiply(bf16[16]{0} %multiply.923, bf16[16]{0} %multiply.923), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.931 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.933 = bf16[16]{0} broadcast(bf16[] %convert.931), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.934 = bf16[16]{0} multiply(bf16[16]{0} %multiply.932, bf16[16]{0} %broadcast.933), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.935 = bf16[16]{0} add(bf16[16]{0} %broadcast.42, bf16[16]{0} %multiply.934), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.936 = bf16[16]{0} sqrt(bf16[16]{0} %add.935), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.937 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.938 = bf16[16]{0} add(bf16[16]{0} %sqrt.936, bf16[16]{0} %broadcast.937), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.954 = bf16[16]{0} divide(bf16[16]{0} %add.951, bf16[16]{0} %add.938), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.42 = bf16[] constant(-0)
  %broadcast.955 = bf16[16]{0} broadcast(bf16[] %constant.42), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.956 = bf16[16]{0} multiply(bf16[16]{0} %divide.954, bf16[16]{0} %broadcast.955), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.957 = bf16[16]{0} add(bf16[16]{0} %p43.952, bf16[16]{0} %multiply.956), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p44.1009 = bf16[16,16]{1,0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.43 = bf16[] constant(0)
  %multiply.52 = bf16[] multiply(bf16[] %constant.43, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.45 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.52), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.45 = bf16[1]{0} constant({1})
  %compare.973 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.45), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.46 = bf16[1]{0} constant({1})
  %select.975 = bf16[1]{0} select(pred[1]{0} %compare.973, bf16[1]{0} %divide.684, bf16[1]{0} %constant.46), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.232 = bf16[1]{0} constant({0.5})
  %multiply.174 = bf16[1]{0} multiply(bf16[1]{0} %select.975, bf16[1]{0} %constant.232), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.665 = bf16[] reshape(bf16[1]{0} %multiply.174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.47 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.665), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.980 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.209, bf16[16,16]{1,0} %broadcast.47), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.999 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1000 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.980, bf16[16,16]{1,0} %broadcast.999), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1008 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.45, bf16[16,16]{1,0} %multiply.1000), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.47 = bf16[] constant(0)
  %multiply.55 = bf16[] multiply(bf16[] %constant.47, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.50 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.55), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.989 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.980, bf16[16,16]{1,0} %multiply.980), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.988 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.990 = bf16[16,16]{1,0} broadcast(bf16[] %convert.988), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.991 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.989, bf16[16,16]{1,0} %broadcast.990), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.992 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.50, bf16[16,16]{1,0} %multiply.991), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.993 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.992), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.994 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.995 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.993, bf16[16,16]{1,0} %broadcast.994), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1011 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1008, bf16[16,16]{1,0} %add.995), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.48 = bf16[] constant(-0)
  %broadcast.1012 = bf16[16,16]{1,0} broadcast(bf16[] %constant.48), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1013 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1011, bf16[16,16]{1,0} %broadcast.1012), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1014 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p44.1009, bf16[16,16]{1,0} %multiply.1013), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.958 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.962 = bf16[16,16]{1,0} broadcast(bf16[] %constant.958), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1015 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1014, bf16[16,16]{1,0} %broadcast.962), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1016 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1014, bf16[16,16]{1,0} %multiply.1015), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p45.1062 = bf16[16]{0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.49 = bf16[] constant(0)
  %multiply.56 = bf16[] multiply(bf16[] %constant.49, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.53 = bf16[16]{0} broadcast(bf16[] %multiply.56), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.51 = bf16[1]{0} constant({1})
  %compare.1027 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.51), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.52 = bf16[1]{0} constant({1})
  %select.1029 = bf16[1]{0} select(pred[1]{0} %compare.1027, bf16[1]{0} %divide.684, bf16[1]{0} %constant.52), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.233 = bf16[1]{0} constant({0.5})
  %multiply.175 = bf16[1]{0} multiply(bf16[1]{0} %select.1029, bf16[1]{0} %constant.233), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.668 = bf16[] reshape(bf16[1]{0} %multiply.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.54 = bf16[16]{0} broadcast(bf16[] %reshape.668), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1033 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.165, bf16[16]{0} %broadcast.54), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1052 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1053 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1033, bf16[16]{0} %broadcast.1052), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1061 = bf16[16]{0} add(bf16[16]{0} %broadcast.53, bf16[16]{0} %multiply.1053), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.53 = bf16[] constant(0)
  %multiply.59 = bf16[] multiply(bf16[] %constant.53, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.57 = bf16[16]{0} broadcast(bf16[] %multiply.59), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1042 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1033, bf16[16]{0} %multiply.1033), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1041 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1043 = bf16[16]{0} broadcast(bf16[] %convert.1041), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1044 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1042, bf16[16]{0} %broadcast.1043), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1045 = bf16[16]{0} add(bf16[16]{0} %broadcast.57, bf16[16]{0} %multiply.1044), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1046 = bf16[16]{0} sqrt(bf16[16]{0} %add.1045), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1047 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1048 = bf16[16]{0} add(bf16[16]{0} %sqrt.1046, bf16[16]{0} %broadcast.1047), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1064 = bf16[16]{0} divide(bf16[16]{0} %add.1061, bf16[16]{0} %add.1048), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.54 = bf16[] constant(-0)
  %broadcast.1065 = bf16[16]{0} broadcast(bf16[] %constant.54), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1066 = bf16[16]{0} multiply(bf16[16]{0} %divide.1064, bf16[16]{0} %broadcast.1065), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1067 = bf16[16]{0} add(bf16[16]{0} %p45.1062, bf16[16]{0} %multiply.1066), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p46.1119 = bf16[16,16]{1,0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.55 = bf16[] constant(0)
  %multiply.60 = bf16[] multiply(bf16[] %constant.55, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.60 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.60), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.57 = bf16[1]{0} constant({1})
  %compare.1083 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.57), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.58 = bf16[1]{0} constant({1})
  %select.1085 = bf16[1]{0} select(pred[1]{0} %compare.1083, bf16[1]{0} %divide.684, bf16[1]{0} %constant.58), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.234 = bf16[1]{0} constant({0.5})
  %multiply.177 = bf16[1]{0} multiply(bf16[1]{0} %select.1085, bf16[1]{0} %constant.234), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.671 = bf16[] reshape(bf16[1]{0} %multiply.177), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.62 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.671), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1090 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.205, bf16[16,16]{1,0} %broadcast.62), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1109 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1110 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1090, bf16[16,16]{1,0} %broadcast.1109), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1118 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.60, bf16[16,16]{1,0} %multiply.1110), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.59 = bf16[] constant(0)
  %multiply.63 = bf16[] multiply(bf16[] %constant.59, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.65 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.63), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1099 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1090, bf16[16,16]{1,0} %multiply.1090), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1098 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1100 = bf16[16,16]{1,0} broadcast(bf16[] %convert.1098), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1101 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1099, bf16[16,16]{1,0} %broadcast.1100), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1102 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.65, bf16[16,16]{1,0} %multiply.1101), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1103 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.1102), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1104 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1105 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.1103, bf16[16,16]{1,0} %broadcast.1104), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1121 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1118, bf16[16,16]{1,0} %add.1105), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.60 = bf16[] constant(-0)
  %broadcast.1122 = bf16[16,16]{1,0} broadcast(bf16[] %constant.60), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1123 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1121, bf16[16,16]{1,0} %broadcast.1122), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1124 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p46.1119, bf16[16,16]{1,0} %multiply.1123), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1068 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1072 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1068), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1125 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1124, bf16[16,16]{1,0} %broadcast.1072), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1126 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1124, bf16[16,16]{1,0} %multiply.1125), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p47.1172 = bf16[16]{0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.61 = bf16[] constant(0)
  %multiply.64 = bf16[] multiply(bf16[] %constant.61, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.68 = bf16[16]{0} broadcast(bf16[] %multiply.64), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.63 = bf16[1]{0} constant({1})
  %compare.1137 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.63), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.64 = bf16[1]{0} constant({1})
  %select.1139 = bf16[1]{0} select(pred[1]{0} %compare.1137, bf16[1]{0} %divide.684, bf16[1]{0} %constant.64), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.235 = bf16[1]{0} constant({0.5})
  %multiply.178 = bf16[1]{0} multiply(bf16[1]{0} %select.1139, bf16[1]{0} %constant.235), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.674 = bf16[] reshape(bf16[1]{0} %multiply.178), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.69 = bf16[16]{0} broadcast(bf16[] %reshape.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1143 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.161, bf16[16]{0} %broadcast.69), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1162 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1163 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1143, bf16[16]{0} %broadcast.1162), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1171 = bf16[16]{0} add(bf16[16]{0} %broadcast.68, bf16[16]{0} %multiply.1163), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.65 = bf16[] constant(0)
  %multiply.67 = bf16[] multiply(bf16[] %constant.65, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.72 = bf16[16]{0} broadcast(bf16[] %multiply.67), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1152 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1143, bf16[16]{0} %multiply.1143), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1151 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1153 = bf16[16]{0} broadcast(bf16[] %convert.1151), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1154 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1152, bf16[16]{0} %broadcast.1153), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1155 = bf16[16]{0} add(bf16[16]{0} %broadcast.72, bf16[16]{0} %multiply.1154), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1156 = bf16[16]{0} sqrt(bf16[16]{0} %add.1155), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1157 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1158 = bf16[16]{0} add(bf16[16]{0} %sqrt.1156, bf16[16]{0} %broadcast.1157), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1174 = bf16[16]{0} divide(bf16[16]{0} %add.1171, bf16[16]{0} %add.1158), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.66 = bf16[] constant(-0)
  %broadcast.1175 = bf16[16]{0} broadcast(bf16[] %constant.66), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1176 = bf16[16]{0} multiply(bf16[16]{0} %divide.1174, bf16[16]{0} %broadcast.1175), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1177 = bf16[16]{0} add(bf16[16]{0} %p47.1172, bf16[16]{0} %multiply.1176), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p48.1229 = bf16[16,16]{1,0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.67 = bf16[] constant(0)
  %multiply.68 = bf16[] multiply(bf16[] %constant.67, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.75 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.68), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.69 = bf16[1]{0} constant({1})
  %compare.1193 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.69), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.70 = bf16[1]{0} constant({1})
  %select.1195 = bf16[1]{0} select(pred[1]{0} %compare.1193, bf16[1]{0} %divide.684, bf16[1]{0} %constant.70), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.236 = bf16[1]{0} constant({0.5})
  %multiply.179 = bf16[1]{0} multiply(bf16[1]{0} %select.1195, bf16[1]{0} %constant.236), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.677 = bf16[] reshape(bf16[1]{0} %multiply.179), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.77 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.677), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1200 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.201, bf16[16,16]{1,0} %broadcast.77), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1219 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1220 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1200, bf16[16,16]{1,0} %broadcast.1219), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1228 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.75, bf16[16,16]{1,0} %multiply.1220), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.71 = bf16[] constant(0)
  %multiply.71 = bf16[] multiply(bf16[] %constant.71, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.80 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.71), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1209 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1200, bf16[16,16]{1,0} %multiply.1200), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1208 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1210 = bf16[16,16]{1,0} broadcast(bf16[] %convert.1208), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1211 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1209, bf16[16,16]{1,0} %broadcast.1210), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1212 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.80, bf16[16,16]{1,0} %multiply.1211), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1213 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.1212), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1214 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1215 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.1213, bf16[16,16]{1,0} %broadcast.1214), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1231 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1228, bf16[16,16]{1,0} %add.1215), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.72 = bf16[] constant(-0)
  %broadcast.1232 = bf16[16,16]{1,0} broadcast(bf16[] %constant.72), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1233 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1231, bf16[16,16]{1,0} %broadcast.1232), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1234 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p48.1229, bf16[16,16]{1,0} %multiply.1233), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1178 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1182 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1178), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1235 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1234, bf16[16,16]{1,0} %broadcast.1182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1236 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1234, bf16[16,16]{1,0} %multiply.1235), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p49.1282 = bf16[16]{0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.73 = bf16[] constant(0)
  %multiply.72 = bf16[] multiply(bf16[] %constant.73, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.83 = bf16[16]{0} broadcast(bf16[] %multiply.72), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.75 = bf16[1]{0} constant({1})
  %compare.1247 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.75), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.76 = bf16[1]{0} constant({1})
  %select.1249 = bf16[1]{0} select(pred[1]{0} %compare.1247, bf16[1]{0} %divide.684, bf16[1]{0} %constant.76), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.237 = bf16[1]{0} constant({0.5})
  %multiply.181 = bf16[1]{0} multiply(bf16[1]{0} %select.1249, bf16[1]{0} %constant.237), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.680 = bf16[] reshape(bf16[1]{0} %multiply.181), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.84 = bf16[16]{0} broadcast(bf16[] %reshape.680), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1253 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.157, bf16[16]{0} %broadcast.84), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1272 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1273 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1253, bf16[16]{0} %broadcast.1272), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1281 = bf16[16]{0} add(bf16[16]{0} %broadcast.83, bf16[16]{0} %multiply.1273), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.77 = bf16[] constant(0)
  %multiply.75 = bf16[] multiply(bf16[] %constant.77, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.87 = bf16[16]{0} broadcast(bf16[] %multiply.75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1262 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1253, bf16[16]{0} %multiply.1253), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1261 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1263 = bf16[16]{0} broadcast(bf16[] %convert.1261), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1264 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1262, bf16[16]{0} %broadcast.1263), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1265 = bf16[16]{0} add(bf16[16]{0} %broadcast.87, bf16[16]{0} %multiply.1264), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1266 = bf16[16]{0} sqrt(bf16[16]{0} %add.1265), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1267 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1268 = bf16[16]{0} add(bf16[16]{0} %sqrt.1266, bf16[16]{0} %broadcast.1267), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1284 = bf16[16]{0} divide(bf16[16]{0} %add.1281, bf16[16]{0} %add.1268), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.78 = bf16[] constant(-0)
  %broadcast.1285 = bf16[16]{0} broadcast(bf16[] %constant.78), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1286 = bf16[16]{0} multiply(bf16[16]{0} %divide.1284, bf16[16]{0} %broadcast.1285), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1287 = bf16[16]{0} add(bf16[16]{0} %p49.1282, bf16[16]{0} %multiply.1286), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p50.1339 = bf16[16,16]{1,0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.79 = bf16[] constant(0)
  %multiply.76 = bf16[] multiply(bf16[] %constant.79, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.90 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.76), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.81 = bf16[1]{0} constant({1})
  %compare.1303 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.81), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.82 = bf16[1]{0} constant({1})
  %select.1305 = bf16[1]{0} select(pred[1]{0} %compare.1303, bf16[1]{0} %divide.684, bf16[1]{0} %constant.82), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.240 = bf16[1]{0} constant({0.5})
  %multiply.182 = bf16[1]{0} multiply(bf16[1]{0} %select.1305, bf16[1]{0} %constant.240), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.683 = bf16[] reshape(bf16[1]{0} %multiply.182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.92 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.683), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1310 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.197, bf16[16,16]{1,0} %broadcast.92), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1329 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1330 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1310, bf16[16,16]{1,0} %broadcast.1329), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1338 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.90, bf16[16,16]{1,0} %multiply.1330), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.83 = bf16[] constant(0)
  %multiply.79 = bf16[] multiply(bf16[] %constant.83, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.95 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.79), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1319 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1310, bf16[16,16]{1,0} %multiply.1310), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1318 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1320 = bf16[16,16]{1,0} broadcast(bf16[] %convert.1318), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1321 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1319, bf16[16,16]{1,0} %broadcast.1320), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1322 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.95, bf16[16,16]{1,0} %multiply.1321), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1323 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.1322), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1324 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1325 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.1323, bf16[16,16]{1,0} %broadcast.1324), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1341 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1338, bf16[16,16]{1,0} %add.1325), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.84 = bf16[] constant(-0)
  %broadcast.1342 = bf16[16,16]{1,0} broadcast(bf16[] %constant.84), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1343 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1341, bf16[16,16]{1,0} %broadcast.1342), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1344 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p50.1339, bf16[16,16]{1,0} %multiply.1343), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1288 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1292 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1288), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1345 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1344, bf16[16,16]{1,0} %broadcast.1292), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1346 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1344, bf16[16,16]{1,0} %multiply.1345), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p51.1392 = bf16[16]{0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=800}
  %constant.85 = bf16[] constant(0)
  %multiply.80 = bf16[] multiply(bf16[] %constant.85, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.98 = bf16[16]{0} broadcast(bf16[] %multiply.80), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.87 = bf16[1]{0} constant({1})
  %compare.1357 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.87), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.88 = bf16[1]{0} constant({1})
  %select.1359 = bf16[1]{0} select(pred[1]{0} %compare.1357, bf16[1]{0} %divide.684, bf16[1]{0} %constant.88), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.243 = bf16[1]{0} constant({0.5})
  %multiply.183 = bf16[1]{0} multiply(bf16[1]{0} %select.1359, bf16[1]{0} %constant.243), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.686 = bf16[] reshape(bf16[1]{0} %multiply.183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.99 = bf16[16]{0} broadcast(bf16[] %reshape.686), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1363 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.153, bf16[16]{0} %broadcast.99), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1382 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1383 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1363, bf16[16]{0} %broadcast.1382), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1391 = bf16[16]{0} add(bf16[16]{0} %broadcast.98, bf16[16]{0} %multiply.1383), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.89 = bf16[] constant(0)
  %multiply.83 = bf16[] multiply(bf16[] %constant.89, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.102 = bf16[16]{0} broadcast(bf16[] %multiply.83), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1372 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1363, bf16[16]{0} %multiply.1363), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1371 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1373 = bf16[16]{0} broadcast(bf16[] %convert.1371), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1374 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1372, bf16[16]{0} %broadcast.1373), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1375 = bf16[16]{0} add(bf16[16]{0} %broadcast.102, bf16[16]{0} %multiply.1374), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1376 = bf16[16]{0} sqrt(bf16[16]{0} %add.1375), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1377 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1378 = bf16[16]{0} add(bf16[16]{0} %sqrt.1376, bf16[16]{0} %broadcast.1377), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1394 = bf16[16]{0} divide(bf16[16]{0} %add.1391, bf16[16]{0} %add.1378), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.90 = bf16[] constant(-0)
  %broadcast.1395 = bf16[16]{0} broadcast(bf16[] %constant.90), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1396 = bf16[16]{0} multiply(bf16[16]{0} %divide.1394, bf16[16]{0} %broadcast.1395), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1397 = bf16[16]{0} add(bf16[16]{0} %p51.1392, bf16[16]{0} %multiply.1396), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p52.1443 = bf16[16]{0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.91 = bf16[] constant(0)
  %multiply.84 = bf16[] multiply(bf16[] %constant.91, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.105 = bf16[16]{0} broadcast(bf16[] %multiply.84), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.93 = bf16[1]{0} constant({1})
  %compare.1408 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.93), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.94 = bf16[1]{0} constant({1})
  %select.1410 = bf16[1]{0} select(pred[1]{0} %compare.1408, bf16[1]{0} %divide.684, bf16[1]{0} %constant.94), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.244 = bf16[1]{0} constant({0.5})
  %multiply.185 = bf16[1]{0} multiply(bf16[1]{0} %select.1410, bf16[1]{0} %constant.244), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.689 = bf16[] reshape(bf16[1]{0} %multiply.185), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.106 = bf16[16]{0} broadcast(bf16[] %reshape.689), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1414 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.149, bf16[16]{0} %broadcast.106), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1433 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1434 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1414, bf16[16]{0} %broadcast.1433), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1442 = bf16[16]{0} add(bf16[16]{0} %broadcast.105, bf16[16]{0} %multiply.1434), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.95 = bf16[] constant(0)
  %multiply.87 = bf16[] multiply(bf16[] %constant.95, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.110 = bf16[16]{0} broadcast(bf16[] %multiply.87), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1423 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1414, bf16[16]{0} %multiply.1414), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1422 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1424 = bf16[16]{0} broadcast(bf16[] %convert.1422), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1425 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1423, bf16[16]{0} %broadcast.1424), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1426 = bf16[16]{0} add(bf16[16]{0} %broadcast.110, bf16[16]{0} %multiply.1425), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1427 = bf16[16]{0} sqrt(bf16[16]{0} %add.1426), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1428 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1429 = bf16[16]{0} add(bf16[16]{0} %sqrt.1427, bf16[16]{0} %broadcast.1428), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1445 = bf16[16]{0} divide(bf16[16]{0} %add.1442, bf16[16]{0} %add.1429), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.96 = bf16[] constant(-0)
  %broadcast.1446 = bf16[16]{0} broadcast(bf16[] %constant.96), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1447 = bf16[16]{0} multiply(bf16[16]{0} %divide.1445, bf16[16]{0} %broadcast.1446), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1448 = bf16[16]{0} add(bf16[16]{0} %p52.1443, bf16[16]{0} %multiply.1447), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p53.1494 = bf16[16]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.97 = bf16[] constant(0)
  %multiply.88 = bf16[] multiply(bf16[] %constant.97, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.114 = bf16[16]{0} broadcast(bf16[] %multiply.88), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.99 = bf16[1]{0} constant({1})
  %compare.1459 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.99), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.100 = bf16[1]{0} constant({1})
  %select.1461 = bf16[1]{0} select(pred[1]{0} %compare.1459, bf16[1]{0} %divide.684, bf16[1]{0} %constant.100), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.245 = bf16[1]{0} constant({0.5})
  %multiply.186 = bf16[1]{0} multiply(bf16[1]{0} %select.1461, bf16[1]{0} %constant.245), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.692 = bf16[] reshape(bf16[1]{0} %multiply.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.116 = bf16[16]{0} broadcast(bf16[] %reshape.692), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1465 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.145, bf16[16]{0} %broadcast.116), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1484 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1485 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1465, bf16[16]{0} %broadcast.1484), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1493 = bf16[16]{0} add(bf16[16]{0} %broadcast.114, bf16[16]{0} %multiply.1485), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.101 = bf16[] constant(0)
  %multiply.91 = bf16[] multiply(bf16[] %constant.101, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.120 = bf16[16]{0} broadcast(bf16[] %multiply.91), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1474 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1465, bf16[16]{0} %multiply.1465), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1473 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1475 = bf16[16]{0} broadcast(bf16[] %convert.1473), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1476 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1474, bf16[16]{0} %broadcast.1475), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1477 = bf16[16]{0} add(bf16[16]{0} %broadcast.120, bf16[16]{0} %multiply.1476), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1478 = bf16[16]{0} sqrt(bf16[16]{0} %add.1477), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1479 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1480 = bf16[16]{0} add(bf16[16]{0} %sqrt.1478, bf16[16]{0} %broadcast.1479), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1496 = bf16[16]{0} divide(bf16[16]{0} %add.1493, bf16[16]{0} %add.1480), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.102 = bf16[] constant(-0)
  %broadcast.1497 = bf16[16]{0} broadcast(bf16[] %constant.102), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1498 = bf16[16]{0} multiply(bf16[16]{0} %divide.1496, bf16[16]{0} %broadcast.1497), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1499 = bf16[16]{0} add(bf16[16]{0} %p53.1494, bf16[16]{0} %multiply.1498), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p54.1551 = bf16[4096,16]{1,0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.103 = bf16[] constant(0)
  %multiply.92 = bf16[] multiply(bf16[] %constant.103, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.124 = bf16[4096,16]{1,0} broadcast(bf16[] %multiply.92), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.105 = bf16[1]{0} constant({1})
  %compare.1515 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.105), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.107 = bf16[1]{0} constant({1})
  %select.1517 = bf16[1]{0} select(pred[1]{0} %compare.1515, bf16[1]{0} %divide.684, bf16[1]{0} %constant.107), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.246 = bf16[1]{0} constant({0.5})
  %multiply.187 = bf16[1]{0} multiply(bf16[1]{0} %select.1517, bf16[1]{0} %constant.246), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.696 = bf16[] reshape(bf16[1]{0} %multiply.187), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.126 = bf16[4096,16]{1,0} broadcast(bf16[] %reshape.696), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1522 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %get-tuple-element.193, bf16[4096,16]{1,0} %broadcast.126), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1541 = bf16[4096,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1542 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %multiply.1522, bf16[4096,16]{1,0} %broadcast.1541), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1550 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %broadcast.124, bf16[4096,16]{1,0} %multiply.1542), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.108 = bf16[] constant(0)
  %multiply.95 = bf16[] multiply(bf16[] %constant.108, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.130 = bf16[4096,16]{1,0} broadcast(bf16[] %multiply.95), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1531 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %multiply.1522, bf16[4096,16]{1,0} %multiply.1522), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1530 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1532 = bf16[4096,16]{1,0} broadcast(bf16[] %convert.1530), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1533 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %multiply.1531, bf16[4096,16]{1,0} %broadcast.1532), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1534 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %broadcast.130, bf16[4096,16]{1,0} %multiply.1533), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1535 = bf16[4096,16]{1,0} sqrt(bf16[4096,16]{1,0} %add.1534), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1536 = bf16[4096,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1537 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %sqrt.1535, bf16[4096,16]{1,0} %broadcast.1536), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1553 = bf16[4096,16]{1,0} divide(bf16[4096,16]{1,0} %add.1550, bf16[4096,16]{1,0} %add.1537), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.109 = bf16[] constant(-0)
  %broadcast.1554 = bf16[4096,16]{1,0} broadcast(bf16[] %constant.109), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1555 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %divide.1553, bf16[4096,16]{1,0} %broadcast.1554), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1556 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %p54.1551, bf16[4096,16]{1,0} %multiply.1555), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1500 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1504 = bf16[4096,16]{1,0} broadcast(bf16[] %constant.1500), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1557 = bf16[4096,16]{1,0} multiply(bf16[4096,16]{1,0} %add.1556, bf16[4096,16]{1,0} %broadcast.1504), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1558 = bf16[4096,16]{1,0} add(bf16[4096,16]{1,0} %add.1556, bf16[4096,16]{1,0} %multiply.1557), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p55.1604 = bf16[4096]{0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.111 = bf16[] constant(0)
  %multiply.96 = bf16[] multiply(bf16[] %constant.111, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.134 = bf16[4096]{0} broadcast(bf16[] %multiply.96), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.113 = bf16[1]{0} constant({1})
  %compare.1569 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.113), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.115 = bf16[1]{0} constant({1})
  %select.1571 = bf16[1]{0} select(pred[1]{0} %compare.1569, bf16[1]{0} %divide.684, bf16[1]{0} %constant.115), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.247 = bf16[1]{0} constant({0.5})
  %multiply.189 = bf16[1]{0} multiply(bf16[1]{0} %select.1571, bf16[1]{0} %constant.247), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.699 = bf16[] reshape(bf16[1]{0} %multiply.189), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.136 = bf16[4096]{0} broadcast(bf16[] %reshape.699), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1575 = bf16[4096]{0} multiply(bf16[4096]{0} %get-tuple-element.141, bf16[4096]{0} %broadcast.136), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1594 = bf16[4096]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1595 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1575, bf16[4096]{0} %broadcast.1594), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1603 = bf16[4096]{0} add(bf16[4096]{0} %broadcast.134, bf16[4096]{0} %multiply.1595), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.116 = bf16[] constant(0)
  %multiply.99 = bf16[] multiply(bf16[] %constant.116, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.140 = bf16[4096]{0} broadcast(bf16[] %multiply.99), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1584 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1575, bf16[4096]{0} %multiply.1575), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1583 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1585 = bf16[4096]{0} broadcast(bf16[] %convert.1583), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1586 = bf16[4096]{0} multiply(bf16[4096]{0} %multiply.1584, bf16[4096]{0} %broadcast.1585), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1587 = bf16[4096]{0} add(bf16[4096]{0} %broadcast.140, bf16[4096]{0} %multiply.1586), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1588 = bf16[4096]{0} sqrt(bf16[4096]{0} %add.1587), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1589 = bf16[4096]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1590 = bf16[4096]{0} add(bf16[4096]{0} %sqrt.1588, bf16[4096]{0} %broadcast.1589), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1606 = bf16[4096]{0} divide(bf16[4096]{0} %add.1603, bf16[4096]{0} %add.1590), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.117 = bf16[] constant(-0)
  %broadcast.1607 = bf16[4096]{0} broadcast(bf16[] %constant.117), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1608 = bf16[4096]{0} multiply(bf16[4096]{0} %divide.1606, bf16[4096]{0} %broadcast.1607), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1609 = bf16[4096]{0} add(bf16[4096]{0} %p55.1604, bf16[4096]{0} %multiply.1608), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p56.1661 = bf16[16,4096]{1,0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.119 = bf16[] constant(0)
  %multiply.100 = bf16[] multiply(bf16[] %constant.119, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.144 = bf16[16,4096]{1,0} broadcast(bf16[] %multiply.100), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.121 = bf16[1]{0} constant({1})
  %compare.1625 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.121), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.123 = bf16[1]{0} constant({1})
  %select.1627 = bf16[1]{0} select(pred[1]{0} %compare.1625, bf16[1]{0} %divide.684, bf16[1]{0} %constant.123), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.248 = bf16[1]{0} constant({0.5})
  %multiply.190 = bf16[1]{0} multiply(bf16[1]{0} %select.1627, bf16[1]{0} %constant.248), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.704 = bf16[] reshape(bf16[1]{0} %multiply.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.146 = bf16[16,4096]{1,0} broadcast(bf16[] %reshape.704), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1632 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %get-tuple-element.189, bf16[16,4096]{1,0} %broadcast.146), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1651 = bf16[16,4096]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1652 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %multiply.1632, bf16[16,4096]{1,0} %broadcast.1651), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1660 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %broadcast.144, bf16[16,4096]{1,0} %multiply.1652), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.124 = bf16[] constant(0)
  %multiply.103 = bf16[] multiply(bf16[] %constant.124, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.150 = bf16[16,4096]{1,0} broadcast(bf16[] %multiply.103), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1641 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %multiply.1632, bf16[16,4096]{1,0} %multiply.1632), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1640 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1642 = bf16[16,4096]{1,0} broadcast(bf16[] %convert.1640), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1643 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %multiply.1641, bf16[16,4096]{1,0} %broadcast.1642), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1644 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %broadcast.150, bf16[16,4096]{1,0} %multiply.1643), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1645 = bf16[16,4096]{1,0} sqrt(bf16[16,4096]{1,0} %add.1644), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1646 = bf16[16,4096]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1647 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %sqrt.1645, bf16[16,4096]{1,0} %broadcast.1646), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1663 = bf16[16,4096]{1,0} divide(bf16[16,4096]{1,0} %add.1660, bf16[16,4096]{1,0} %add.1647), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.125 = bf16[] constant(-0)
  %broadcast.1664 = bf16[16,4096]{1,0} broadcast(bf16[] %constant.125), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1665 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %divide.1663, bf16[16,4096]{1,0} %broadcast.1664), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1666 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %p56.1661, bf16[16,4096]{1,0} %multiply.1665), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1610 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1614 = bf16[16,4096]{1,0} broadcast(bf16[] %constant.1610), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1667 = bf16[16,4096]{1,0} multiply(bf16[16,4096]{1,0} %add.1666, bf16[16,4096]{1,0} %broadcast.1614), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1668 = bf16[16,4096]{1,0} add(bf16[16,4096]{1,0} %add.1666, bf16[16,4096]{1,0} %multiply.1667), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p57.1714 = bf16[16]{0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.127 = bf16[] constant(0)
  %multiply.104 = bf16[] multiply(bf16[] %constant.127, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.154 = bf16[16]{0} broadcast(bf16[] %multiply.104), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.129 = bf16[1]{0} constant({1})
  %compare.1679 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.129), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.131 = bf16[1]{0} constant({1})
  %select.1681 = bf16[1]{0} select(pred[1]{0} %compare.1679, bf16[1]{0} %divide.684, bf16[1]{0} %constant.131), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.249 = bf16[1]{0} constant({0.5})
  %multiply.191 = bf16[1]{0} multiply(bf16[1]{0} %select.1681, bf16[1]{0} %constant.249), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.707 = bf16[] reshape(bf16[1]{0} %multiply.191), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.156 = bf16[16]{0} broadcast(bf16[] %reshape.707), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1685 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.137, bf16[16]{0} %broadcast.156), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1704 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1705 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1685, bf16[16]{0} %broadcast.1704), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1713 = bf16[16]{0} add(bf16[16]{0} %broadcast.154, bf16[16]{0} %multiply.1705), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.132 = bf16[] constant(0)
  %multiply.107 = bf16[] multiply(bf16[] %constant.132, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.160 = bf16[16]{0} broadcast(bf16[] %multiply.107), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1694 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1685, bf16[16]{0} %multiply.1685), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1693 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1695 = bf16[16]{0} broadcast(bf16[] %convert.1693), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1696 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1694, bf16[16]{0} %broadcast.1695), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1697 = bf16[16]{0} add(bf16[16]{0} %broadcast.160, bf16[16]{0} %multiply.1696), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1698 = bf16[16]{0} sqrt(bf16[16]{0} %add.1697), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1699 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1700 = bf16[16]{0} add(bf16[16]{0} %sqrt.1698, bf16[16]{0} %broadcast.1699), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1716 = bf16[16]{0} divide(bf16[16]{0} %add.1713, bf16[16]{0} %add.1700), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.133 = bf16[] constant(-0)
  %broadcast.1717 = bf16[16]{0} broadcast(bf16[] %constant.133), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1718 = bf16[16]{0} multiply(bf16[16]{0} %divide.1716, bf16[16]{0} %broadcast.1717), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1719 = bf16[16]{0} add(bf16[16]{0} %p57.1714, bf16[16]{0} %multiply.1718), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p58.1765 = bf16[16]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.135 = bf16[] constant(0)
  %multiply.109 = bf16[] multiply(bf16[] %constant.135, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.164 = bf16[16]{0} broadcast(bf16[] %multiply.109), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.137 = bf16[1]{0} constant({1})
  %compare.1730 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.137), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.139 = bf16[1]{0} constant({1})
  %select.1732 = bf16[1]{0} select(pred[1]{0} %compare.1730, bf16[1]{0} %divide.684, bf16[1]{0} %constant.139), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.250 = bf16[1]{0} constant({0.5})
  %multiply.193 = bf16[1]{0} multiply(bf16[1]{0} %select.1732, bf16[1]{0} %constant.250), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.710 = bf16[] reshape(bf16[1]{0} %multiply.193), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.165 = bf16[16]{0} broadcast(bf16[] %reshape.710), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1736 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.133, bf16[16]{0} %broadcast.165), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1755 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1756 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1736, bf16[16]{0} %broadcast.1755), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1764 = bf16[16]{0} add(bf16[16]{0} %broadcast.164, bf16[16]{0} %multiply.1756), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.140 = bf16[] constant(0)
  %multiply.113 = bf16[] multiply(bf16[] %constant.140, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.169 = bf16[16]{0} broadcast(bf16[] %multiply.113), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1745 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1736, bf16[16]{0} %multiply.1736), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1744 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1746 = bf16[16]{0} broadcast(bf16[] %convert.1744), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1747 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1745, bf16[16]{0} %broadcast.1746), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1748 = bf16[16]{0} add(bf16[16]{0} %broadcast.169, bf16[16]{0} %multiply.1747), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1749 = bf16[16]{0} sqrt(bf16[16]{0} %add.1748), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1750 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1751 = bf16[16]{0} add(bf16[16]{0} %sqrt.1749, bf16[16]{0} %broadcast.1750), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1767 = bf16[16]{0} divide(bf16[16]{0} %add.1764, bf16[16]{0} %add.1751), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.141 = bf16[] constant(-0)
  %broadcast.1768 = bf16[16]{0} broadcast(bf16[] %constant.141), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1769 = bf16[16]{0} multiply(bf16[16]{0} %divide.1767, bf16[16]{0} %broadcast.1768), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1770 = bf16[16]{0} add(bf16[16]{0} %p58.1765, bf16[16]{0} %multiply.1769), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p59.1816 = bf16[16]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.143 = bf16[] constant(0)
  %multiply.114 = bf16[] multiply(bf16[] %constant.143, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.173 = bf16[16]{0} broadcast(bf16[] %multiply.114), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.145 = bf16[1]{0} constant({1})
  %compare.1781 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.145), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.147 = bf16[1]{0} constant({1})
  %select.1783 = bf16[1]{0} select(pred[1]{0} %compare.1781, bf16[1]{0} %divide.684, bf16[1]{0} %constant.147), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.253 = bf16[1]{0} constant({0.5})
  %multiply.194 = bf16[1]{0} multiply(bf16[1]{0} %select.1783, bf16[1]{0} %constant.253), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.713 = bf16[] reshape(bf16[1]{0} %multiply.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.174 = bf16[16]{0} broadcast(bf16[] %reshape.713), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1787 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.129, bf16[16]{0} %broadcast.174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1806 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1807 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1787, bf16[16]{0} %broadcast.1806), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1815 = bf16[16]{0} add(bf16[16]{0} %broadcast.173, bf16[16]{0} %multiply.1807), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.148 = bf16[] constant(0)
  %multiply.118 = bf16[] multiply(bf16[] %constant.148, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.178 = bf16[16]{0} broadcast(bf16[] %multiply.118), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1796 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1787, bf16[16]{0} %multiply.1787), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1795 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1797 = bf16[16]{0} broadcast(bf16[] %convert.1795), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1798 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1796, bf16[16]{0} %broadcast.1797), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1799 = bf16[16]{0} add(bf16[16]{0} %broadcast.178, bf16[16]{0} %multiply.1798), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1800 = bf16[16]{0} sqrt(bf16[16]{0} %add.1799), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1801 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1802 = bf16[16]{0} add(bf16[16]{0} %sqrt.1800, bf16[16]{0} %broadcast.1801), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1818 = bf16[16]{0} divide(bf16[16]{0} %add.1815, bf16[16]{0} %add.1802), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.149 = bf16[] constant(-0)
  %broadcast.1819 = bf16[16]{0} broadcast(bf16[] %constant.149), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1820 = bf16[16]{0} multiply(bf16[16]{0} %divide.1818, bf16[16]{0} %broadcast.1819), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1821 = bf16[16]{0} add(bf16[16]{0} %p59.1816, bf16[16]{0} %multiply.1820), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p60.1873 = bf16[16,16]{1,0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.151 = bf16[] constant(0)
  %multiply.119 = bf16[] multiply(bf16[] %constant.151, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.182 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.119), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.153 = bf16[1]{0} constant({1})
  %compare.1837 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.153), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.155 = bf16[1]{0} constant({1})
  %select.1839 = bf16[1]{0} select(pred[1]{0} %compare.1837, bf16[1]{0} %divide.684, bf16[1]{0} %constant.155), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.256 = bf16[1]{0} constant({0.5})
  %multiply.195 = bf16[1]{0} multiply(bf16[1]{0} %select.1839, bf16[1]{0} %constant.256), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.717 = bf16[] reshape(bf16[1]{0} %multiply.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.185 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.717), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1844 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.185, bf16[16,16]{1,0} %broadcast.185), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1863 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1864 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1844, bf16[16,16]{1,0} %broadcast.1863), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1872 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.182, bf16[16,16]{1,0} %multiply.1864), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.156 = bf16[] constant(0)
  %multiply.123 = bf16[] multiply(bf16[] %constant.156, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.189 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.123), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1853 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1844, bf16[16,16]{1,0} %multiply.1844), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1852 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1854 = bf16[16,16]{1,0} broadcast(bf16[] %convert.1852), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1855 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1853, bf16[16,16]{1,0} %broadcast.1854), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1856 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.189, bf16[16,16]{1,0} %multiply.1855), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1857 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.1856), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1858 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1859 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.1857, bf16[16,16]{1,0} %broadcast.1858), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1875 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1872, bf16[16,16]{1,0} %add.1859), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.157 = bf16[] constant(-0)
  %broadcast.1876 = bf16[16,16]{1,0} broadcast(bf16[] %constant.157), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1877 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1875, bf16[16,16]{1,0} %broadcast.1876), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1878 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p60.1873, bf16[16,16]{1,0} %multiply.1877), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1822 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1826 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1822), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1879 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1878, bf16[16,16]{1,0} %broadcast.1826), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1880 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1878, bf16[16,16]{1,0} %multiply.1879), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p61.1926 = bf16[16]{0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.159 = bf16[] constant(0)
  %multiply.125 = bf16[] multiply(bf16[] %constant.159, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.193 = bf16[16]{0} broadcast(bf16[] %multiply.125), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.161 = bf16[1]{0} constant({1})
  %compare.1891 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.161), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.163 = bf16[1]{0} constant({1})
  %select.1893 = bf16[1]{0} select(pred[1]{0} %compare.1891, bf16[1]{0} %divide.684, bf16[1]{0} %constant.163), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.257 = bf16[1]{0} constant({0.5})
  %multiply.197 = bf16[1]{0} multiply(bf16[1]{0} %select.1893, bf16[1]{0} %constant.257), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.721 = bf16[] reshape(bf16[1]{0} %multiply.197), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.194 = bf16[16]{0} broadcast(bf16[] %reshape.721), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1897 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.125, bf16[16]{0} %broadcast.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1916 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1917 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1897, bf16[16]{0} %broadcast.1916), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1925 = bf16[16]{0} add(bf16[16]{0} %broadcast.193, bf16[16]{0} %multiply.1917), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.164 = bf16[] constant(0)
  %multiply.129 = bf16[] multiply(bf16[] %constant.164, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.198 = bf16[16]{0} broadcast(bf16[] %multiply.129), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1906 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1897, bf16[16]{0} %multiply.1897), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1905 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1907 = bf16[16]{0} broadcast(bf16[] %convert.1905), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1908 = bf16[16]{0} multiply(bf16[16]{0} %multiply.1906, bf16[16]{0} %broadcast.1907), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1909 = bf16[16]{0} add(bf16[16]{0} %broadcast.198, bf16[16]{0} %multiply.1908), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1910 = bf16[16]{0} sqrt(bf16[16]{0} %add.1909), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1911 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1912 = bf16[16]{0} add(bf16[16]{0} %sqrt.1910, bf16[16]{0} %broadcast.1911), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1928 = bf16[16]{0} divide(bf16[16]{0} %add.1925, bf16[16]{0} %add.1912), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.165 = bf16[] constant(-0)
  %broadcast.1929 = bf16[16]{0} broadcast(bf16[] %constant.165), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1930 = bf16[16]{0} multiply(bf16[16]{0} %divide.1928, bf16[16]{0} %broadcast.1929), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1931 = bf16[16]{0} add(bf16[16]{0} %p61.1926, bf16[16]{0} %multiply.1930), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p62.1983 = bf16[16,16]{1,0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.167 = bf16[] constant(0)
  %multiply.130 = bf16[] multiply(bf16[] %constant.167, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.202 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.130), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.169 = bf16[1]{0} constant({1})
  %compare.1947 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.169), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.171 = bf16[1]{0} constant({1})
  %select.1949 = bf16[1]{0} select(pred[1]{0} %compare.1947, bf16[1]{0} %divide.684, bf16[1]{0} %constant.171), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.258 = bf16[1]{0} constant({0.5})
  %multiply.198 = bf16[1]{0} multiply(bf16[1]{0} %select.1949, bf16[1]{0} %constant.258), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.726 = bf16[] reshape(bf16[1]{0} %multiply.198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.205 = bf16[16,16]{1,0} broadcast(bf16[] %reshape.726), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1954 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %get-tuple-element.181, bf16[16,16]{1,0} %broadcast.205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1973 = bf16[16,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1974 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1954, bf16[16,16]{1,0} %broadcast.1973), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1982 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.202, bf16[16,16]{1,0} %multiply.1974), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.172 = bf16[] constant(0)
  %multiply.134 = bf16[] multiply(bf16[] %constant.172, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.209 = bf16[16,16]{1,0} broadcast(bf16[] %multiply.134), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1963 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1954, bf16[16,16]{1,0} %multiply.1954), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.1962 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1964 = bf16[16,16]{1,0} broadcast(bf16[] %convert.1962), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1965 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %multiply.1963, bf16[16,16]{1,0} %broadcast.1964), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1966 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %broadcast.209, bf16[16,16]{1,0} %multiply.1965), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1967 = bf16[16,16]{1,0} sqrt(bf16[16,16]{1,0} %add.1966), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1968 = bf16[16,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1969 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %sqrt.1967, bf16[16,16]{1,0} %broadcast.1968), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1985 = bf16[16,16]{1,0} divide(bf16[16,16]{1,0} %add.1982, bf16[16,16]{1,0} %add.1969), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.173 = bf16[] constant(-0)
  %broadcast.1986 = bf16[16,16]{1,0} broadcast(bf16[] %constant.173), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1987 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %divide.1985, bf16[16,16]{1,0} %broadcast.1986), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1988 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %p62.1983, bf16[16,16]{1,0} %multiply.1987), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1932 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1936 = bf16[16,16]{1,0} broadcast(bf16[] %constant.1932), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1989 = bf16[16,16]{1,0} multiply(bf16[16,16]{1,0} %add.1988, bf16[16,16]{1,0} %broadcast.1936), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1990 = bf16[16,16]{1,0} add(bf16[16,16]{1,0} %add.1988, bf16[16,16]{1,0} %multiply.1989), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p63.2036 = bf16[16]{0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.175 = bf16[] constant(0)
  %multiply.135 = bf16[] multiply(bf16[] %constant.175, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.213 = bf16[16]{0} broadcast(bf16[] %multiply.135), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.177 = bf16[1]{0} constant({1})
  %compare.2001 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.177), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.179 = bf16[1]{0} constant({1})
  %select.2003 = bf16[1]{0} select(pred[1]{0} %compare.2001, bf16[1]{0} %divide.684, bf16[1]{0} %constant.179), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.259 = bf16[1]{0} constant({0.5})
  %multiply.199 = bf16[1]{0} multiply(bf16[1]{0} %select.2003, bf16[1]{0} %constant.259), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.729 = bf16[] reshape(bf16[1]{0} %multiply.199), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.214 = bf16[16]{0} broadcast(bf16[] %reshape.729), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2007 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.117, bf16[16]{0} %broadcast.214), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2026 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2027 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2007, bf16[16]{0} %broadcast.2026), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2035 = bf16[16]{0} add(bf16[16]{0} %broadcast.213, bf16[16]{0} %multiply.2027), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.180 = bf16[] constant(0)
  %multiply.139 = bf16[] multiply(bf16[] %constant.180, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.218 = bf16[16]{0} broadcast(bf16[] %multiply.139), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2016 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2007, bf16[16]{0} %multiply.2007), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2015 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2017 = bf16[16]{0} broadcast(bf16[] %convert.2015), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2018 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2016, bf16[16]{0} %broadcast.2017), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2019 = bf16[16]{0} add(bf16[16]{0} %broadcast.218, bf16[16]{0} %multiply.2018), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2020 = bf16[16]{0} sqrt(bf16[16]{0} %add.2019), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2021 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2022 = bf16[16]{0} add(bf16[16]{0} %sqrt.2020, bf16[16]{0} %broadcast.2021), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2038 = bf16[16]{0} divide(bf16[16]{0} %add.2035, bf16[16]{0} %add.2022), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.181 = bf16[] constant(-0)
  %broadcast.2039 = bf16[16]{0} broadcast(bf16[] %constant.181), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2040 = bf16[16]{0} multiply(bf16[16]{0} %divide.2038, bf16[16]{0} %broadcast.2039), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2041 = bf16[16]{0} add(bf16[16]{0} %p63.2036, bf16[16]{0} %multiply.2040), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p64.2087 = bf16[16]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.183 = bf16[] constant(0)
  %multiply.141 = bf16[] multiply(bf16[] %constant.183, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.222 = bf16[16]{0} broadcast(bf16[] %multiply.141), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.185 = bf16[1]{0} constant({1})
  %compare.2052 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.185), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.187 = bf16[1]{0} constant({1})
  %select.2054 = bf16[1]{0} select(pred[1]{0} %compare.2052, bf16[1]{0} %divide.684, bf16[1]{0} %constant.187), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.260 = bf16[1]{0} constant({0.5})
  %multiply.201 = bf16[1]{0} multiply(bf16[1]{0} %select.2054, bf16[1]{0} %constant.260), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.732 = bf16[] reshape(bf16[1]{0} %multiply.201), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.224 = bf16[16]{0} broadcast(bf16[] %reshape.732), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2058 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.113, bf16[16]{0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2077 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2078 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2058, bf16[16]{0} %broadcast.2077), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2086 = bf16[16]{0} add(bf16[16]{0} %broadcast.222, bf16[16]{0} %multiply.2078), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.188 = bf16[] constant(0)
  %multiply.145 = bf16[] multiply(bf16[] %constant.188, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.227 = bf16[16]{0} broadcast(bf16[] %multiply.145), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2067 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2058, bf16[16]{0} %multiply.2058), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2066 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2068 = bf16[16]{0} broadcast(bf16[] %convert.2066), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2069 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2067, bf16[16]{0} %broadcast.2068), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2070 = bf16[16]{0} add(bf16[16]{0} %broadcast.227, bf16[16]{0} %multiply.2069), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2071 = bf16[16]{0} sqrt(bf16[16]{0} %add.2070), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2072 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2073 = bf16[16]{0} add(bf16[16]{0} %sqrt.2071, bf16[16]{0} %broadcast.2072), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2089 = bf16[16]{0} divide(bf16[16]{0} %add.2086, bf16[16]{0} %add.2073), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.189 = bf16[] constant(-0)
  %broadcast.2090 = bf16[16]{0} broadcast(bf16[] %constant.189), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2091 = bf16[16]{0} multiply(bf16[16]{0} %divide.2089, bf16[16]{0} %broadcast.2090), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2092 = bf16[16]{0} add(bf16[16]{0} %p64.2087, bf16[16]{0} %multiply.2091), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p65.2138 = bf16[16]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.191 = bf16[] constant(0)
  %multiply.146 = bf16[] multiply(bf16[] %constant.191, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.230 = bf16[16]{0} broadcast(bf16[] %multiply.146), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.193 = bf16[1]{0} constant({1})
  %compare.2103 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.193), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.195 = bf16[1]{0} constant({1})
  %select.2105 = bf16[1]{0} select(pred[1]{0} %compare.2103, bf16[1]{0} %divide.684, bf16[1]{0} %constant.195), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.261 = bf16[1]{0} constant({0.5})
  %multiply.202 = bf16[1]{0} multiply(bf16[1]{0} %select.2105, bf16[1]{0} %constant.261), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.735 = bf16[] reshape(bf16[1]{0} %multiply.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.231 = bf16[16]{0} broadcast(bf16[] %reshape.735), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2109 = bf16[16]{0} multiply(bf16[16]{0} %get-tuple-element.109, bf16[16]{0} %broadcast.231), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2128 = bf16[16]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2129 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2109, bf16[16]{0} %broadcast.2128), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2137 = bf16[16]{0} add(bf16[16]{0} %broadcast.230, bf16[16]{0} %multiply.2129), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.196 = bf16[] constant(0)
  %multiply.150 = bf16[] multiply(bf16[] %constant.196, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.234 = bf16[16]{0} broadcast(bf16[] %multiply.150), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2118 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2109, bf16[16]{0} %multiply.2109), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2117 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2119 = bf16[16]{0} broadcast(bf16[] %convert.2117), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2120 = bf16[16]{0} multiply(bf16[16]{0} %multiply.2118, bf16[16]{0} %broadcast.2119), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2121 = bf16[16]{0} add(bf16[16]{0} %broadcast.234, bf16[16]{0} %multiply.2120), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2122 = bf16[16]{0} sqrt(bf16[16]{0} %add.2121), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2123 = bf16[16]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2124 = bf16[16]{0} add(bf16[16]{0} %sqrt.2122, bf16[16]{0} %broadcast.2123), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2140 = bf16[16]{0} divide(bf16[16]{0} %add.2137, bf16[16]{0} %add.2124), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.197 = bf16[] constant(-0)
  %broadcast.2141 = bf16[16]{0} broadcast(bf16[] %constant.197), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2142 = bf16[16]{0} multiply(bf16[16]{0} %divide.2140, bf16[16]{0} %broadcast.2141), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2143 = bf16[16]{0} add(bf16[16]{0} %p65.2138, bf16[16]{0} %multiply.2142), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p66.2189 = bf16[30522]{0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.199 = bf16[] constant(0)
  %multiply.151 = bf16[] multiply(bf16[] %constant.199, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.237 = bf16[30522]{0} broadcast(bf16[] %multiply.151), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.201 = bf16[1]{0} constant({1})
  %compare.2154 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.201), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.203 = bf16[1]{0} constant({1})
  %select.2156 = bf16[1]{0} select(pred[1]{0} %compare.2154, bf16[1]{0} %divide.684, bf16[1]{0} %constant.203), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.262 = bf16[1]{0} constant({0.5})
  %multiply.203 = bf16[1]{0} multiply(bf16[1]{0} %select.2156, bf16[1]{0} %constant.262), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.738 = bf16[] reshape(bf16[1]{0} %multiply.203), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.238 = bf16[30522]{0} broadcast(bf16[] %reshape.738), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2160 = bf16[30522]{0} multiply(bf16[30522]{0} %get-tuple-element.121, bf16[30522]{0} %broadcast.238), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2179 = bf16[30522]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2180 = bf16[30522]{0} multiply(bf16[30522]{0} %multiply.2160, bf16[30522]{0} %broadcast.2179), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2188 = bf16[30522]{0} add(bf16[30522]{0} %broadcast.237, bf16[30522]{0} %multiply.2180), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.204 = bf16[] constant(0)
  %multiply.155 = bf16[] multiply(bf16[] %constant.204, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.241 = bf16[30522]{0} broadcast(bf16[] %multiply.155), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2169 = bf16[30522]{0} multiply(bf16[30522]{0} %multiply.2160, bf16[30522]{0} %multiply.2160), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2168 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2170 = bf16[30522]{0} broadcast(bf16[] %convert.2168), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2171 = bf16[30522]{0} multiply(bf16[30522]{0} %multiply.2169, bf16[30522]{0} %broadcast.2170), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2172 = bf16[30522]{0} add(bf16[30522]{0} %broadcast.241, bf16[30522]{0} %multiply.2171), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2173 = bf16[30522]{0} sqrt(bf16[30522]{0} %add.2172), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2174 = bf16[30522]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2175 = bf16[30522]{0} add(bf16[30522]{0} %sqrt.2173, bf16[30522]{0} %broadcast.2174), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2191 = bf16[30522]{0} divide(bf16[30522]{0} %add.2188, bf16[30522]{0} %add.2175), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.205 = bf16[] constant(-0)
  %broadcast.2192 = bf16[30522]{0} broadcast(bf16[] %constant.205), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2193 = bf16[30522]{0} multiply(bf16[30522]{0} %divide.2191, bf16[30522]{0} %broadcast.2192), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2194 = bf16[30522]{0} add(bf16[30522]{0} %p66.2189, bf16[30522]{0} %multiply.2193), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p67.2246 = bf16[2,16]{1,0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.207 = bf16[] constant(0)
  %multiply.157 = bf16[] multiply(bf16[] %constant.207, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.244 = bf16[2,16]{1,0} broadcast(bf16[] %multiply.157), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.209 = bf16[1]{0} constant({1})
  %compare.2210 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.209), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.211 = bf16[1]{0} constant({1})
  %select.2212 = bf16[1]{0} select(pred[1]{0} %compare.2210, bf16[1]{0} %divide.684, bf16[1]{0} %constant.211), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.263 = bf16[1]{0} constant({0.5})
  %multiply.205 = bf16[1]{0} multiply(bf16[1]{0} %select.2212, bf16[1]{0} %constant.263), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.743 = bf16[] reshape(bf16[1]{0} %multiply.205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.246 = bf16[2,16]{1,0} broadcast(bf16[] %reshape.743), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2217 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %get-tuple-element.177, bf16[2,16]{1,0} %broadcast.246), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2236 = bf16[2,16]{1,0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2237 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.2217, bf16[2,16]{1,0} %broadcast.2236), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2245 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %broadcast.244, bf16[2,16]{1,0} %multiply.2237), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.212 = bf16[] constant(0)
  %multiply.161 = bf16[] multiply(bf16[] %constant.212, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.249 = bf16[2,16]{1,0} broadcast(bf16[] %multiply.161), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2226 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.2217, bf16[2,16]{1,0} %multiply.2217), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2225 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2227 = bf16[2,16]{1,0} broadcast(bf16[] %convert.2225), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2228 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %multiply.2226, bf16[2,16]{1,0} %broadcast.2227), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2229 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %broadcast.249, bf16[2,16]{1,0} %multiply.2228), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2230 = bf16[2,16]{1,0} sqrt(bf16[2,16]{1,0} %add.2229), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2231 = bf16[2,16]{1,0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2232 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %sqrt.2230, bf16[2,16]{1,0} %broadcast.2231), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2248 = bf16[2,16]{1,0} divide(bf16[2,16]{1,0} %add.2245, bf16[2,16]{1,0} %add.2232), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.213 = bf16[] constant(-0)
  %broadcast.2249 = bf16[2,16]{1,0} broadcast(bf16[] %constant.213), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2250 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %divide.2248, bf16[2,16]{1,0} %broadcast.2249), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2251 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %p67.2246, bf16[2,16]{1,0} %multiply.2250), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2195 = bf16[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.2199 = bf16[2,16]{1,0} broadcast(bf16[] %constant.2195), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.2252 = bf16[2,16]{1,0} multiply(bf16[2,16]{1,0} %add.2251, bf16[2,16]{1,0} %broadcast.2199), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.2253 = bf16[2,16]{1,0} add(bf16[2,16]{1,0} %add.2251, bf16[2,16]{1,0} %multiply.2252), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p68.2299 = bf16[2]{0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.215 = bf16[] constant(0)
  %multiply.162 = bf16[] multiply(bf16[] %constant.215, bf16[] %p38.721), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.252 = bf16[2]{0} broadcast(bf16[] %multiply.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.217 = bf16[1]{0} constant({1})
  %compare.2264 = pred[1]{0} compare(bf16[1]{0} %divide.684, bf16[1]{0} %constant.217), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.219 = bf16[1]{0} constant({1})
  %select.2266 = bf16[1]{0} select(pred[1]{0} %compare.2264, bf16[1]{0} %divide.684, bf16[1]{0} %constant.219), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.266 = bf16[1]{0} constant({0.5})
  %multiply.206 = bf16[1]{0} multiply(bf16[1]{0} %select.2266, bf16[1]{0} %constant.266), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.746 = bf16[] reshape(bf16[1]{0} %multiply.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.253 = bf16[2]{0} broadcast(bf16[] %reshape.746), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2270 = bf16[2]{0} multiply(bf16[2]{0} %get-tuple-element.105, bf16[2]{0} %broadcast.253), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2289 = bf16[2]{0} broadcast(bf16[] %p37.715), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2290 = bf16[2]{0} multiply(bf16[2]{0} %multiply.2270, bf16[2]{0} %broadcast.2289), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2298 = bf16[2]{0} add(bf16[2]{0} %broadcast.252, bf16[2]{0} %multiply.2290), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.220 = bf16[] constant(0)
  %multiply.166 = bf16[] multiply(bf16[] %constant.220, bf16[] %p36.699), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.256 = bf16[2]{0} broadcast(bf16[] %multiply.166), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2279 = bf16[2]{0} multiply(bf16[2]{0} %multiply.2270, bf16[2]{0} %multiply.2270), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %convert.2278 = bf16[] convert(f32[] %p1.10), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2280 = bf16[2]{0} broadcast(bf16[] %convert.2278), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2281 = bf16[2]{0} multiply(bf16[2]{0} %multiply.2279, bf16[2]{0} %broadcast.2280), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2282 = bf16[2]{0} add(bf16[2]{0} %broadcast.256, bf16[2]{0} %multiply.2281), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2283 = bf16[2]{0} sqrt(bf16[2]{0} %add.2282), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2284 = bf16[2]{0} broadcast(bf16[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2285 = bf16[2]{0} add(bf16[2]{0} %sqrt.2283, bf16[2]{0} %broadcast.2284), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2301 = bf16[2]{0} divide(bf16[2]{0} %add.2298, bf16[2]{0} %add.2285), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.221 = bf16[] constant(-0)
  %broadcast.2302 = bf16[2]{0} broadcast(bf16[] %constant.221), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2303 = bf16[2]{0} multiply(bf16[2]{0} %divide.2301, bf16[2]{0} %broadcast.2302), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2304 = bf16[2]{0} add(bf16[2]{0} %p68.2299, bf16[2]{0} %multiply.2303), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.223 = f32[1]{0} constant({0})
  %get-tuple-element.35 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.34), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %constant.224 = bf16[1]{0} constant({0})
  ROOT %tuple.2311 = (bf16[30522,16]{1,0}, bf16[512,16]{1,0}, bf16[2,16]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=5*/bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, /*index=10*/bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=15*/bf16[4096,16]{1,0}, bf16[4096]{0}, bf16[16,4096]{1,0}, bf16[16]{0}, bf16[16]{0}, /*index=20*/bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, bf16[16,16]{1,0}, bf16[16]{0}, /*index=25*/bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, bf16[2,16]{1,0}, bf16[2]{0}, /*index=30*/f32[1]{0}, f32[1]{0}, f32[1]{0}, bf16[30522,16]{1,0}, bf16[30522,16]{1,0}, /*index=35*/bf16[512,16]{1,0}, bf16[512,16]{1,0}, bf16[2,16]{1,0}, bf16[2,16]{1,0}, bf16[16,16]{1,0}, /*index=40*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=45*/bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[4096,16]{1,0}, bf16[4096,16]{1,0}, bf16[16,4096]{1,0}, /*index=50*/bf16[16,4096]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, bf16[16,16]{1,0}, /*index=55*/bf16[2,16]{1,0}, bf16[2,16]{1,0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=60*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=65*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=70*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[4096]{0}, bf16[4096]{0}, /*index=75*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=80*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[30522]{0}, bf16[30522]{0}, /*index=85*/bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, bf16[16]{0}, /*index=90*/bf16[16]{0}, bf16[2]{0}, bf16[2]{0}, bf16[1]{0}) tuple(bf16[30522,16]{1,0} %add.737, bf16[512,16]{1,0} %add.796, bf16[2,16]{1,0} %add.855, bf16[16]{0} %add.906, bf16[16]{0} %add.957, /*index=5*/bf16[16,16]{1,0} %add.1016, bf16[16]{0} %add.1067, bf16[16,16]{1,0} %add.1126, bf16[16]{0} %add.1177, bf16[16,16]{1,0} %add.1236, /*index=10*/bf16[16]{0} %add.1287, bf16[16,16]{1,0} %add.1346, bf16[16]{0} %add.1397, bf16[16]{0} %add.1448, bf16[16]{0} %add.1499, /*index=15*/bf16[4096,16]{1,0} %add.1558, bf16[4096]{0} %add.1609, bf16[16,4096]{1,0} %add.1668, bf16[16]{0} %add.1719, bf16[16]{0} %add.1770, /*index=20*/bf16[16]{0} %add.1821, bf16[16,16]{1,0} %add.1880, bf16[16]{0} %add.1931, bf16[16,16]{1,0} %add.1990, bf16[16]{0} %add.2041, /*index=25*/bf16[16]{0} %add.2092, bf16[16]{0} %add.2143, bf16[30522]{0} %add.2194, bf16[2,16]{1,0} %add.2253, bf16[2]{0} %add.2304, /*index=30*/f32[1]{0} %constant.223, f32[1]{0} %divide.26, f32[1]{0} %get-tuple-element.35, bf16[30522,16]{1,0} %add.729, bf16[30522,16]{1,0} %add.711, /*index=35*/bf16[512,16]{1,0} %add.788, bf16[512,16]{1,0} %add.772, bf16[2,16]{1,0} %add.847, bf16[2,16]{1,0} %add.831, bf16[16,16]{1,0} %add.1008, /*index=40*/bf16[16,16]{1,0} %add.992, bf16[16,16]{1,0} %add.1118, bf16[16,16]{1,0} %add.1102, bf16[16,16]{1,0} %add.1228, bf16[16,16]{1,0} %add.1212, /*index=45*/bf16[16,16]{1,0} %add.1338, bf16[16,16]{1,0} %add.1322, bf16[4096,16]{1,0} %add.1550, bf16[4096,16]{1,0} %add.1534, bf16[16,4096]{1,0} %add.1660, /*index=50*/bf16[16,4096]{1,0} %add.1644, bf16[16,16]{1,0} %add.1872, bf16[16,16]{1,0} %add.1856, bf16[16,16]{1,0} %add.1982, bf16[16,16]{1,0} %add.1966, /*index=55*/bf16[2,16]{1,0} %add.2245, bf16[2,16]{1,0} %add.2229, bf16[16]{0} %add.900, bf16[16]{0} %add.884, bf16[16]{0} %add.951, /*index=60*/bf16[16]{0} %add.935, bf16[16]{0} %add.1061, bf16[16]{0} %add.1045, bf16[16]{0} %add.1171, bf16[16]{0} %add.1155, /*index=65*/bf16[16]{0} %add.1281, bf16[16]{0} %add.1265, bf16[16]{0} %add.1391, bf16[16]{0} %add.1375, bf16[16]{0} %add.1442, /*index=70*/bf16[16]{0} %add.1426, bf16[16]{0} %add.1493, bf16[16]{0} %add.1477, bf16[4096]{0} %add.1603, bf16[4096]{0} %add.1587, /*index=75*/bf16[16]{0} %add.1713, bf16[16]{0} %add.1697, bf16[16]{0} %add.1764, bf16[16]{0} %add.1748, bf16[16]{0} %add.1815, /*index=80*/bf16[16]{0} %add.1799, bf16[16]{0} %add.1925, bf16[16]{0} %add.1909, bf16[30522]{0} %add.2188, bf16[30522]{0} %add.2172, /*index=85*/bf16[16]{0} %add.2035, bf16[16]{0} %add.2019, bf16[16]{0} %add.2086, bf16[16]{0} %add.2070, bf16[16]{0} %add.2137, /*index=90*/bf16[16]{0} %add.2121, bf16[2]{0} %add.2298, bf16[2]{0} %add.2282, bf16[1]{0} %constant.224), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93"}
}

`

export default text;
