const text = `
    HloModule SyncTensorsGraph.2260, input_output_alias={ {0}: (40, {}, must-alias), {1}: (41, {}, must-alias), {2}: (42, {}, must-alias), {3}: (43, {}, must-alias), {4}: (44, {}, must-alias), {5}: (45, {}, must-alias), {6}: (46, {}, must-alias), {7}: (47, {}, must-alias), {8}: (48, {}, must-alias), {9}: (49, {}, must-alias), {10}: (50, {}, must-alias), {11}: (51, {}, must-alias), {12}: (52, {}, must-alias), {13}: (53, {}, must-alias), {14}: (54, {}, must-alias), {15}: (55, {}, must-alias), {16}: (56, {}, must-alias), {17}: (57, {}, must-alias), {18}: (58, {}, must-alias), {19}: (59, {}, must-alias), {20}: (60, {}, must-alias), {21}: (61, {}, must-alias), {22}: (62, {}, must-alias), {23}: (63, {}, must-alias), {24}: (64, {}, must-alias), {25}: (65, {}, must-alias), {26}: (66, {}, must-alias), {27}: (67, {}, must-alias), {28}: (68, {}, must-alias), {29}: (69, {}, must-alias), {30}: (4, {}, must-alias) }

%AddComputation.28 (x.29: f32[], y.30: f32[]) -> f32[] {
  %x.29 = f32[] parameter(0)
  %y.30 = f32[] parameter(1)
  ROOT %add.31 = f32[] add(f32[] %x.29, f32[] %y.30)
}

%AddComputation.97 (x.98: f32[], y.99: f32[]) -> f32[] {
  %x.98 = f32[] parameter(0)
  %y.99 = f32[] parameter(1)
  ROOT %add.100 = f32[] add(f32[] %x.98, f32[] %y.99)
}

%AddComputation.228 (x.229: f32[], y.230: f32[]) -> f32[] {
  %x.229 = f32[] parameter(0)
  %y.230 = f32[] parameter(1)
  ROOT %add.231 = f32[] add(f32[] %x.229, f32[] %y.230)
}

%AddComputation.241 (x.242: f32[], y.243: f32[]) -> f32[] {
  %x.242 = f32[] parameter(0)
  %y.243 = f32[] parameter(1)
  ROOT %add.244 = f32[] add(f32[] %x.242, f32[] %y.243)
}

%AddComputation.254 (x.255: f32[], y.256: f32[]) -> f32[] {
  %x.255 = f32[] parameter(0)
  %y.256 = f32[] parameter(1)
  ROOT %add.257 = f32[] add(f32[] %x.255, f32[] %y.256)
}

%AddComputation.267 (x.268: f32[], y.269: f32[]) -> f32[] {
  %x.268 = f32[] parameter(0)
  %y.269 = f32[] parameter(1)
  ROOT %add.270 = f32[] add(f32[] %x.268, f32[] %y.269)
}

%AddComputation.280 (x.281: f32[], y.282: f32[]) -> f32[] {
  %x.281 = f32[] parameter(0)
  %y.282 = f32[] parameter(1)
  ROOT %add.283 = f32[] add(f32[] %x.281, f32[] %y.282)
}

%AddComputation.293 (x.294: f32[], y.295: f32[]) -> f32[] {
  %x.294 = f32[] parameter(0)
  %y.295 = f32[] parameter(1)
  ROOT %add.296 = f32[] add(f32[] %x.294, f32[] %y.295)
}

%AddComputation.306 (x.307: f32[], y.308: f32[]) -> f32[] {
  %x.307 = f32[] parameter(0)
  %y.308 = f32[] parameter(1)
  ROOT %add.309 = f32[] add(f32[] %x.307, f32[] %y.308)
}

%AddComputation.320 (x.321: f32[], y.322: f32[]) -> f32[] {
  %x.321 = f32[] parameter(0)
  %y.322 = f32[] parameter(1)
  ROOT %add.323 = f32[] add(f32[] %x.321, f32[] %y.322)
}

%AddComputation.333 (x.334: f32[], y.335: f32[]) -> f32[] {
  %x.334 = f32[] parameter(0)
  %y.335 = f32[] parameter(1)
  ROOT %add.336 = f32[] add(f32[] %x.334, f32[] %y.335)
}

%AddComputation.346 (x.347: f32[], y.348: f32[]) -> f32[] {
  %x.347 = f32[] parameter(0)
  %y.348 = f32[] parameter(1)
  ROOT %add.349 = f32[] add(f32[] %x.347, f32[] %y.348)
}

%AddComputation.359 (x.360: f32[], y.361: f32[]) -> f32[] {
  %x.360 = f32[] parameter(0)
  %y.361 = f32[] parameter(1)
  ROOT %add.362 = f32[] add(f32[] %x.360, f32[] %y.361)
}

%AddComputation.372 (x.373: f32[], y.374: f32[]) -> f32[] {
  %x.373 = f32[] parameter(0)
  %y.374 = f32[] parameter(1)
  ROOT %add.375 = f32[] add(f32[] %x.373, f32[] %y.374)
}

%AddComputation.385 (x.386: f32[], y.387: f32[]) -> f32[] {
  %x.386 = f32[] parameter(0)
  %y.387 = f32[] parameter(1)
  ROOT %add.388 = f32[] add(f32[] %x.386, f32[] %y.387)
}

%AddComputation.398 (x.399: f32[], y.400: f32[]) -> f32[] {
  %x.399 = f32[] parameter(0)
  %y.400 = f32[] parameter(1)
  ROOT %add.401 = f32[] add(f32[] %x.399, f32[] %y.400)
}

%AddComputation.411 (x.412: f32[], y.413: f32[]) -> f32[] {
  %x.412 = f32[] parameter(0)
  %y.413 = f32[] parameter(1)
  ROOT %add.414 = f32[] add(f32[] %x.412, f32[] %y.413)
}

%AddComputation.424 (x.425: f32[], y.426: f32[]) -> f32[] {
  %x.425 = f32[] parameter(0)
  %y.426 = f32[] parameter(1)
  ROOT %add.427 = f32[] add(f32[] %x.425, f32[] %y.426)
}

%AddComputation.437 (x.438: f32[], y.439: f32[]) -> f32[] {
  %x.438 = f32[] parameter(0)
  %y.439 = f32[] parameter(1)
  ROOT %add.440 = f32[] add(f32[] %x.438, f32[] %y.439)
}

%AddComputation.450 (x.451: f32[], y.452: f32[]) -> f32[] {
  %x.451 = f32[] parameter(0)
  %y.452 = f32[] parameter(1)
  ROOT %add.453 = f32[] add(f32[] %x.451, f32[] %y.452)
}

%AddComputation.463 (x.464: f32[], y.465: f32[]) -> f32[] {
  %x.464 = f32[] parameter(0)
  %y.465 = f32[] parameter(1)
  ROOT %add.466 = f32[] add(f32[] %x.464, f32[] %y.465)
}

%AddComputation.476 (x.477: f32[], y.478: f32[]) -> f32[] {
  %x.477 = f32[] parameter(0)
  %y.478 = f32[] parameter(1)
  ROOT %add.479 = f32[] add(f32[] %x.477, f32[] %y.478)
}

%AddComputation.489 (x.490: f32[], y.491: f32[]) -> f32[] {
  %x.490 = f32[] parameter(0)
  %y.491 = f32[] parameter(1)
  ROOT %add.492 = f32[] add(f32[] %x.490, f32[] %y.491)
}

%AddComputation.502 (x.503: f32[], y.504: f32[]) -> f32[] {
  %x.503 = f32[] parameter(0)
  %y.504 = f32[] parameter(1)
  ROOT %add.505 = f32[] add(f32[] %x.503, f32[] %y.504)
}

%AddComputation.515 (x.516: f32[], y.517: f32[]) -> f32[] {
  %x.516 = f32[] parameter(0)
  %y.517 = f32[] parameter(1)
  ROOT %add.518 = f32[] add(f32[] %x.516, f32[] %y.517)
}

%AddComputation.528 (x.529: f32[], y.530: f32[]) -> f32[] {
  %x.529 = f32[] parameter(0)
  %y.530 = f32[] parameter(1)
  ROOT %add.531 = f32[] add(f32[] %x.529, f32[] %y.530)
}

%AddComputation.541 (x.542: f32[], y.543: f32[]) -> f32[] {
  %x.542 = f32[] parameter(0)
  %y.543 = f32[] parameter(1)
  ROOT %add.544 = f32[] add(f32[] %x.542, f32[] %y.543)
}

%AddComputation.554 (x.555: f32[], y.556: f32[]) -> f32[] {
  %x.555 = f32[] parameter(0)
  %y.556 = f32[] parameter(1)
  ROOT %add.557 = f32[] add(f32[] %x.555, f32[] %y.556)
}

%AddComputation.567 (x.568: f32[], y.569: f32[]) -> f32[] {
  %x.568 = f32[] parameter(0)
  %y.569 = f32[] parameter(1)
  ROOT %add.570 = f32[] add(f32[] %x.568, f32[] %y.569)
}

%AddComputation.580 (x.581: f32[], y.582: f32[]) -> f32[] {
  %x.581 = f32[] parameter(0)
  %y.582 = f32[] parameter(1)
  ROOT %add.583 = f32[] add(f32[] %x.581, f32[] %y.582)
}

%AddComputation.593 (x.594: f32[], y.595: f32[]) -> f32[] {
  %x.594 = f32[] parameter(0)
  %y.595 = f32[] parameter(1)
  ROOT %add.596 = f32[] add(f32[] %x.594, f32[] %y.595)
}

%AddComputation.606 (x.607: f32[], y.608: f32[]) -> f32[] {
  %x.607 = f32[] parameter(0)
  %y.608 = f32[] parameter(1)
  ROOT %add.609 = f32[] add(f32[] %x.607, f32[] %y.608)
}

%AddComputation.680 (x.681: f32[], y.682: f32[]) -> f32[] {
  %x.681 = f32[] parameter(0)
  %y.682 = f32[] parameter(1)
  ROOT %add.683 = f32[] add(f32[] %x.681, f32[] %y.682)
}

ENTRY %SyncTensorsGraph.2260 (p0.8: f32[], p1.10: f32[], p2.20: f32[], p3.21: f32[], p4.22: f32[1], p5.35: f32[30522,16], p6.36: f32[512,16], p7.37: f32[2,16], p8.38: f32[8,16], p9.39: f32[8,16], p10.40: f32[8,16], p11.41: f32[16,8], p12.42: f32[4096,16], p13.43: f32[16,4096], p14.44: f32[16,16], p15.45: f32[16,16], p16.46: f32[2,16], p17.47: f32[16], p18.48: f32[16], p19.49: f32[8], p20.50: f32[8], p21.51: f32[8], p22.52: f32[16], p23.53: f32[16], p24.54: f32[16], p25.55: f32[4096], p26.56: f32[16], p27.57: f32[16], p28.58: f32[16], p29.59: f32[16], p30.60: f32[30522], p31.61: f32[16], p32.62: f32[16], p33.63: f32[16], p34.64: f32[2], p35.314: f32[], p36.614: f32[1], p37.707: f32[], p38.722: f32[], p39.728: f32[], p40.737: f32[30522,16], p41.794: f32[512,16], p42.851: f32[2,16], p43.902: f32[16], p44.951: f32[16], p45.1006: f32[8,16], p46.1057: f32[8], p47.1112: f32[8,16], p48.1163: f32[8], p49.1218: f32[8,16], p50.1269: f32[8], p51.1324: f32[16,8], p52.1375: f32[16], p53.1424: f32[16], p54.1473: f32[16], p55.1528: f32[4096,16], p56.1579: f32[4096], p57.1634: f32[16,4096], p58.1685: f32[16], p59.1734: f32[16], p60.1783: f32[16], p61.1838: f32[16,16], p62.1889: f32[16], p63.1944: f32[16,16], p64.1995: f32[16], p65.2044: f32[16], p66.2093: f32[16], p67.2142: f32[30522], p68.2197: f32[2,16], p69.2248: f32[2]) -> (f32[30522,16], f32[512,16], f32[2,16], f32[16], f32[16], /*index=5*/f32[8,16], f32[8], f32[8,16], f32[8], f32[8,16], /*index=10*/f32[8], f32[16,8], f32[16], f32[16], f32[16], /*index=15*/f32[4096,16], f32[4096], f32[16,4096], f32[16], f32[16], /*index=20*/f32[16], f32[16,16], f32[16], f32[16,16], f32[16], /*index=25*/f32[16], f32[16], f32[30522], f32[2,16], f32[2], /*index=30*/f32[1], f32[1], f32[1], f32[30522,16], f32[30522,16], /*index=35*/f32[512,16], f32[512,16], f32[2,16], f32[2,16], f32[8,16], /*index=40*/f32[8,16], f32[8,16], f32[8,16], f32[8,16], f32[8,16], /*index=45*/f32[16,8], f32[16,8], f32[4096,16], f32[4096,16], f32[16,4096], /*index=50*/f32[16,4096], f32[16,16], f32[16,16], f32[16,16], f32[16,16], /*index=55*/f32[2,16], f32[2,16], f32[16], f32[16], f32[16], /*index=60*/f32[16], f32[8], f32[8], f32[8], f32[8], /*index=65*/f32[8], f32[8], f32[16], f32[16], f32[16], /*index=70*/f32[16], f32[16], f32[16], f32[4096], f32[4096], /*index=75*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=80*/f32[16], f32[16], f32[16], f32[30522], f32[30522], /*index=85*/f32[16], f32[16], f32[16], f32[16], f32[16], /*index=90*/f32[16], f32[2], f32[2], f32[1]) {
  %p40.737 = f32[30522,16]{1,0} parameter(40), frontend_attributes={neff_input_names="input40"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant = f32[] constant(0)
  %p39.728 = f32[] parameter(39), frontend_attributes={neff_input_names="input39"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.32 = f32[] multiply(f32[] %constant, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.2 = f32[30522,16]{1,0} broadcast(f32[] %multiply.32), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %p34.64 = f32[2]{0} parameter(34), frontend_attributes={neff_input_names="input34"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p33.63 = f32[16]{0} parameter(33), frontend_attributes={neff_input_names="input33"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p32.62 = f32[16]{0} parameter(32), frontend_attributes={neff_input_names="input32"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p31.61 = f32[16]{0} parameter(31), frontend_attributes={neff_input_names="input31"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p30.60 = f32[30522]{0} parameter(30), frontend_attributes={neff_input_names="input30"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p29.59 = f32[16]{0} parameter(29), frontend_attributes={neff_input_names="input29"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p28.58 = f32[16]{0} parameter(28), frontend_attributes={neff_input_names="input28"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p27.57 = f32[16]{0} parameter(27), frontend_attributes={neff_input_names="input27"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p26.56 = f32[16]{0} parameter(26), frontend_attributes={neff_input_names="input26"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p25.55 = f32[4096]{0} parameter(25), frontend_attributes={neff_input_names="input25"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p24.54 = f32[16]{0} parameter(24), frontend_attributes={neff_input_names="input24"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p23.53 = f32[16]{0} parameter(23), frontend_attributes={neff_input_names="input23"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p22.52 = f32[16]{0} parameter(22), frontend_attributes={neff_input_names="input22"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p21.51 = f32[8]{0} parameter(21), frontend_attributes={neff_input_names="input21"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p20.50 = f32[8]{0} parameter(20), frontend_attributes={neff_input_names="input20"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p19.49 = f32[8]{0} parameter(19), frontend_attributes={neff_input_names="input19"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p18.48 = f32[16]{0} parameter(18), frontend_attributes={neff_input_names="input18"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p17.47 = f32[16]{0} parameter(17), frontend_attributes={neff_input_names="input17"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p16.46 = f32[2,16]{1,0} parameter(16), frontend_attributes={neff_input_names="input16"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p15.45 = f32[16,16]{1,0} parameter(15), frontend_attributes={neff_input_names="input15"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p14.44 = f32[16,16]{1,0} parameter(14), frontend_attributes={neff_input_names="input14"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p13.43 = f32[16,4096]{1,0} parameter(13), frontend_attributes={neff_input_names="input13"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p12.42 = f32[4096,16]{1,0} parameter(12), frontend_attributes={neff_input_names="input12"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p11.41 = f32[16,8]{1,0} parameter(11), frontend_attributes={neff_input_names="input11"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p10.40 = f32[8,16]{1,0} parameter(10), frontend_attributes={neff_input_names="input10"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p9.39 = f32[8,16]{1,0} parameter(9), frontend_attributes={neff_input_names="input9"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p8.38 = f32[8,16]{1,0} parameter(8), frontend_attributes={neff_input_names="input8"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p7.37 = f32[2,16]{1,0} parameter(7), frontend_attributes={neff_input_names="input7"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p6.36 = f32[512,16]{1,0} parameter(6), frontend_attributes={neff_input_names="input6"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p5.35 = f32[30522,16]{1,0} parameter(5), frontend_attributes={neff_input_names="input5"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %p4.22 = f32[1]{0} parameter(4), frontend_attributes={neff_input_names="input4"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=513}
  %p3.21 = f32[] parameter(3), frontend_attributes={neff_input_names="input3"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=513}
  %reshape = f32[1]{0} reshape(f32[] %p3.21), metadata={op_type="aten__div" op_name="aten__div" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=513}
  %divide.24 = f32[1]{0} divide(f32[1]{0} %p4.22, f32[1]{0} %reshape), metadata={op_type="aten__div" op_name="aten__div" source_file="tp_dp_bert_large_hf_pretrain_hdf5.py" source_line=513}
  %p2.20 = f32[] parameter(2), frontend_attributes={neff_input_names="input2"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %all-reduce.32 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %divide.24, f32[] %p2.20), replica_groups={{0,2,4,6},{1,3,5,7}}, constrain_layout=true, to_apply=%AddComputation.28, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %get-tuple-element.96 = f32[] get-tuple-element((f32[1]{0}, f32[]) %all-reduce.32), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %all-reduce.101 = (f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) all-reduce(f32[2]{0} %p34.64, f32[16]{0} %p33.63, f32[16]{0} %p32.62, f32[16]{0} %p31.61, f32[30522]{0} %p30.60, /*index=5*/f32[16]{0} %p29.59, f32[16]{0} %p28.58, f32[16]{0} %p27.57, f32[16]{0} %p26.56, f32[4096]{0} %p25.55, /*index=10*/f32[16]{0} %p24.54, f32[16]{0} %p23.53, f32[16]{0} %p22.52, f32[8]{0} %p21.51, f32[8]{0} %p20.50, /*index=15*/f32[8]{0} %p19.49, f32[16]{0} %p18.48, f32[16]{0} %p17.47, f32[2,16]{1,0} %p16.46, f32[16,16]{1,0} %p15.45, /*index=20*/f32[16,16]{1,0} %p14.44, f32[16,4096]{1,0} %p13.43, f32[4096,16]{1,0} %p12.42, f32[16,8]{1,0} %p11.41, f32[8,16]{1,0} %p10.40, /*index=25*/f32[8,16]{1,0} %p9.39, f32[8,16]{1,0} %p8.38, f32[2,16]{1,0} %p7.37, f32[512,16]{1,0} %p6.36, f32[30522,16]{1,0} %p5.35, /*index=30*/f32[] %get-tuple-element.96), replica_groups={{0,2,4,6},{1,3,5,7}}, constrain_layout=true, to_apply=%AddComputation.97, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.218 = f32[30522,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=29, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.2 = f32[1]{0} constant({1})
  %p36.614 = f32[1]{0} parameter(36), frontend_attributes={neff_input_names="input36"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=114}
  %constant.219 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.220 = f32[30522,16]{1,0} broadcast(f32[] %constant.219), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.221 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %get-tuple-element.218, f32[30522,16]{1,0} %broadcast.220), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.603 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.221, f32[30522,16]{1,0} %multiply.221), metadata={op_type="aten__mul" op_name="aten__norm.1/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.604 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.610 = f32[] reduce(f32[30522,16]{1,0} %multiply.603, f32[] %constant.604), dimensions={0,1}, to_apply=%AddComputation.606, metadata={op_type="aten__sum" op_name="aten__norm.1/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.611 = f32[] sqrt(f32[] %reduce.610), metadata={op_type="aten__sqrt" op_name="aten__norm.1/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.613 = f32[] multiply(f32[] %sqrt.611, f32[] %sqrt.611), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.1 = f32[1]{0} reshape(f32[] %multiply.613), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.616 = f32[1]{0} add(f32[1]{0} %p36.614, f32[1]{0} %reshape.1), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.214 = f32[512,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=28, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.215 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.216 = f32[512,16]{1,0} broadcast(f32[] %constant.215), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.217 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %get-tuple-element.214, f32[512,16]{1,0} %broadcast.216), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.590 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.217, f32[512,16]{1,0} %multiply.217), metadata={op_type="aten__mul" op_name="aten__norm.2/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.591 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.597 = f32[] reduce(f32[512,16]{1,0} %multiply.590, f32[] %constant.591), dimensions={0,1}, to_apply=%AddComputation.593, metadata={op_type="aten__sum" op_name="aten__norm.2/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.598 = f32[] sqrt(f32[] %reduce.597), metadata={op_type="aten__sqrt" op_name="aten__norm.2/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.600 = f32[] multiply(f32[] %sqrt.598, f32[] %sqrt.598), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.3 = f32[1]{0} reshape(f32[] %multiply.600), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.618 = f32[1]{0} add(f32[1]{0} %add.616, f32[1]{0} %reshape.3), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.210 = f32[2,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=27, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.211 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.212 = f32[2,16]{1,0} broadcast(f32[] %constant.211), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.213 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.210, f32[2,16]{1,0} %broadcast.212), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.577 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.213, f32[2,16]{1,0} %multiply.213), metadata={op_type="aten__mul" op_name="aten__norm.3/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.578 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.584 = f32[] reduce(f32[2,16]{1,0} %multiply.577, f32[] %constant.578), dimensions={0,1}, to_apply=%AddComputation.580, metadata={op_type="aten__sum" op_name="aten__norm.3/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.585 = f32[] sqrt(f32[] %reduce.584), metadata={op_type="aten__sqrt" op_name="aten__norm.3/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.587 = f32[] multiply(f32[] %sqrt.585, f32[] %sqrt.585), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.5 = f32[1]{0} reshape(f32[] %multiply.587), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.620 = f32[1]{0} add(f32[1]{0} %add.618, f32[1]{0} %reshape.5), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.170 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=17, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.171 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.172 = f32[16]{0} broadcast(f32[] %constant.171), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.173 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.170, f32[16]{0} %broadcast.172), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.564 = f32[16]{0} multiply(f32[16]{0} %multiply.173, f32[16]{0} %multiply.173), metadata={op_type="aten__mul" op_name="aten__norm.4/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.565 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.571 = f32[] reduce(f32[16]{0} %multiply.564, f32[] %constant.565), dimensions={0}, to_apply=%AddComputation.567, metadata={op_type="aten__sum" op_name="aten__norm.4/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.572 = f32[] sqrt(f32[] %reduce.571), metadata={op_type="aten__sqrt" op_name="aten__norm.4/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.574 = f32[] multiply(f32[] %sqrt.572, f32[] %sqrt.572), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.6 = f32[1]{0} reshape(f32[] %multiply.574), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.622 = f32[1]{0} add(f32[1]{0} %add.620, f32[1]{0} %reshape.6), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.166 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=16, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.167 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.168 = f32[16]{0} broadcast(f32[] %constant.167), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.169 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.166, f32[16]{0} %broadcast.168), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.551 = f32[16]{0} multiply(f32[16]{0} %multiply.169, f32[16]{0} %multiply.169), metadata={op_type="aten__mul" op_name="aten__norm.5/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.552 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.558 = f32[] reduce(f32[16]{0} %multiply.551, f32[] %constant.552), dimensions={0}, to_apply=%AddComputation.554, metadata={op_type="aten__sum" op_name="aten__norm.5/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.559 = f32[] sqrt(f32[] %reduce.558), metadata={op_type="aten__sqrt" op_name="aten__norm.5/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.561 = f32[] multiply(f32[] %sqrt.559, f32[] %sqrt.559), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.7 = f32[1]{0} reshape(f32[] %multiply.561), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.624 = f32[1]{0} add(f32[1]{0} %add.622, f32[1]{0} %reshape.7), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.150 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=12, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.151 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.152 = f32[16]{0} broadcast(f32[] %constant.151), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.153 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.150, f32[16]{0} %broadcast.152), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.538 = f32[16]{0} multiply(f32[16]{0} %multiply.153, f32[16]{0} %multiply.153), metadata={op_type="aten__mul" op_name="aten__norm.6/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.539 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.545 = f32[] reduce(f32[16]{0} %multiply.538, f32[] %constant.539), dimensions={0}, to_apply=%AddComputation.541, metadata={op_type="aten__sum" op_name="aten__norm.6/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.546 = f32[] sqrt(f32[] %reduce.545), metadata={op_type="aten__sqrt" op_name="aten__norm.6/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.548 = f32[] multiply(f32[] %sqrt.546, f32[] %sqrt.546), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.8 = f32[1]{0} reshape(f32[] %multiply.548), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.626 = f32[1]{0} add(f32[1]{0} %add.624, f32[1]{0} %reshape.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.146 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=11, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.147 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.148 = f32[16]{0} broadcast(f32[] %constant.147), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.149 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.146, f32[16]{0} %broadcast.148), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.525 = f32[16]{0} multiply(f32[16]{0} %multiply.149, f32[16]{0} %multiply.149), metadata={op_type="aten__mul" op_name="aten__norm.7/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.526 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.532 = f32[] reduce(f32[16]{0} %multiply.525, f32[] %constant.526), dimensions={0}, to_apply=%AddComputation.528, metadata={op_type="aten__sum" op_name="aten__norm.7/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.533 = f32[] sqrt(f32[] %reduce.532), metadata={op_type="aten__sqrt" op_name="aten__norm.7/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.535 = f32[] multiply(f32[] %sqrt.533, f32[] %sqrt.533), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.9 = f32[1]{0} reshape(f32[] %multiply.535), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.628 = f32[1]{0} add(f32[1]{0} %add.626, f32[1]{0} %reshape.9), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.142 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=10, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.143 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.144 = f32[16]{0} broadcast(f32[] %constant.143), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.145 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.142, f32[16]{0} %broadcast.144), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.512 = f32[16]{0} multiply(f32[16]{0} %multiply.145, f32[16]{0} %multiply.145), metadata={op_type="aten__mul" op_name="aten__norm.8/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.513 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.519 = f32[] reduce(f32[16]{0} %multiply.512, f32[] %constant.513), dimensions={0}, to_apply=%AddComputation.515, metadata={op_type="aten__sum" op_name="aten__norm.8/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.520 = f32[] sqrt(f32[] %reduce.519), metadata={op_type="aten__sqrt" op_name="aten__norm.8/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.522 = f32[] multiply(f32[] %sqrt.520, f32[] %sqrt.520), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.10 = f32[1]{0} reshape(f32[] %multiply.522), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.630 = f32[1]{0} add(f32[1]{0} %add.628, f32[1]{0} %reshape.10), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.190 = f32[4096,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=22, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.191 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.192 = f32[4096,16]{1,0} broadcast(f32[] %constant.191), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.193 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %get-tuple-element.190, f32[4096,16]{1,0} %broadcast.192), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.499 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.193, f32[4096,16]{1,0} %multiply.193), metadata={op_type="aten__mul" op_name="aten__norm.9/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.500 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.506 = f32[] reduce(f32[4096,16]{1,0} %multiply.499, f32[] %constant.500), dimensions={0,1}, to_apply=%AddComputation.502, metadata={op_type="aten__sum" op_name="aten__norm.9/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.507 = f32[] sqrt(f32[] %reduce.506), metadata={op_type="aten__sqrt" op_name="aten__norm.9/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.509 = f32[] multiply(f32[] %sqrt.507, f32[] %sqrt.507), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.11 = f32[1]{0} reshape(f32[] %multiply.509), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.632 = f32[1]{0} add(f32[1]{0} %add.630, f32[1]{0} %reshape.11), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.138 = f32[4096]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=9, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.139 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.140 = f32[4096]{0} broadcast(f32[] %constant.139), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.141 = f32[4096]{0} multiply(f32[4096]{0} %get-tuple-element.138, f32[4096]{0} %broadcast.140), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.486 = f32[4096]{0} multiply(f32[4096]{0} %multiply.141, f32[4096]{0} %multiply.141), metadata={op_type="aten__mul" op_name="aten__norm.10/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.487 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.493 = f32[] reduce(f32[4096]{0} %multiply.486, f32[] %constant.487), dimensions={0}, to_apply=%AddComputation.489, metadata={op_type="aten__sum" op_name="aten__norm.10/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.494 = f32[] sqrt(f32[] %reduce.493), metadata={op_type="aten__sqrt" op_name="aten__norm.10/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.496 = f32[] multiply(f32[] %sqrt.494, f32[] %sqrt.494), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.13 = f32[1]{0} reshape(f32[] %multiply.496), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.634 = f32[1]{0} add(f32[1]{0} %add.632, f32[1]{0} %reshape.13), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.186 = f32[16,4096]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=21, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.187 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.188 = f32[16,4096]{1,0} broadcast(f32[] %constant.187), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.189 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %get-tuple-element.186, f32[16,4096]{1,0} %broadcast.188), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.473 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.189, f32[16,4096]{1,0} %multiply.189), metadata={op_type="aten__mul" op_name="aten__norm.11/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.474 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.480 = f32[] reduce(f32[16,4096]{1,0} %multiply.473, f32[] %constant.474), dimensions={0,1}, to_apply=%AddComputation.476, metadata={op_type="aten__sum" op_name="aten__norm.11/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.481 = f32[] sqrt(f32[] %reduce.480), metadata={op_type="aten__sqrt" op_name="aten__norm.11/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.483 = f32[] multiply(f32[] %sqrt.481, f32[] %sqrt.481), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.14 = f32[1]{0} reshape(f32[] %multiply.483), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.636 = f32[1]{0} add(f32[1]{0} %add.634, f32[1]{0} %reshape.14), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.134 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=8, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.135 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.136 = f32[16]{0} broadcast(f32[] %constant.135), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.137 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.134, f32[16]{0} %broadcast.136), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.460 = f32[16]{0} multiply(f32[16]{0} %multiply.137, f32[16]{0} %multiply.137), metadata={op_type="aten__mul" op_name="aten__norm.12/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.461 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.467 = f32[] reduce(f32[16]{0} %multiply.460, f32[] %constant.461), dimensions={0}, to_apply=%AddComputation.463, metadata={op_type="aten__sum" op_name="aten__norm.12/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.468 = f32[] sqrt(f32[] %reduce.467), metadata={op_type="aten__sqrt" op_name="aten__norm.12/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.470 = f32[] multiply(f32[] %sqrt.468, f32[] %sqrt.468), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.15 = f32[1]{0} reshape(f32[] %multiply.470), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.638 = f32[1]{0} add(f32[1]{0} %add.636, f32[1]{0} %reshape.15), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.130 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=7, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.131 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.132 = f32[16]{0} broadcast(f32[] %constant.131), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.133 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.130, f32[16]{0} %broadcast.132), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.447 = f32[16]{0} multiply(f32[16]{0} %multiply.133, f32[16]{0} %multiply.133), metadata={op_type="aten__mul" op_name="aten__norm.13/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.448 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.454 = f32[] reduce(f32[16]{0} %multiply.447, f32[] %constant.448), dimensions={0}, to_apply=%AddComputation.450, metadata={op_type="aten__sum" op_name="aten__norm.13/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.455 = f32[] sqrt(f32[] %reduce.454), metadata={op_type="aten__sqrt" op_name="aten__norm.13/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.457 = f32[] multiply(f32[] %sqrt.455, f32[] %sqrt.455), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.16 = f32[1]{0} reshape(f32[] %multiply.457), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.640 = f32[1]{0} add(f32[1]{0} %add.638, f32[1]{0} %reshape.16), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.126 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=6, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.127 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.128 = f32[16]{0} broadcast(f32[] %constant.127), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.129 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.126, f32[16]{0} %broadcast.128), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.434 = f32[16]{0} multiply(f32[16]{0} %multiply.129, f32[16]{0} %multiply.129), metadata={op_type="aten__mul" op_name="aten__norm.14/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.435 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.441 = f32[] reduce(f32[16]{0} %multiply.434, f32[] %constant.435), dimensions={0}, to_apply=%AddComputation.437, metadata={op_type="aten__sum" op_name="aten__norm.14/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.442 = f32[] sqrt(f32[] %reduce.441), metadata={op_type="aten__sqrt" op_name="aten__norm.14/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.444 = f32[] multiply(f32[] %sqrt.442, f32[] %sqrt.442), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.17 = f32[1]{0} reshape(f32[] %multiply.444), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.642 = f32[1]{0} add(f32[1]{0} %add.640, f32[1]{0} %reshape.17), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.182 = f32[16,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=20, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.183 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.184 = f32[16,16]{1,0} broadcast(f32[] %constant.183), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.185 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.182, f32[16,16]{1,0} %broadcast.184), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.421 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.185, f32[16,16]{1,0} %multiply.185), metadata={op_type="aten__mul" op_name="aten__norm.15/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.422 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.428 = f32[] reduce(f32[16,16]{1,0} %multiply.421, f32[] %constant.422), dimensions={0,1}, to_apply=%AddComputation.424, metadata={op_type="aten__sum" op_name="aten__norm.15/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.429 = f32[] sqrt(f32[] %reduce.428), metadata={op_type="aten__sqrt" op_name="aten__norm.15/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.431 = f32[] multiply(f32[] %sqrt.429, f32[] %sqrt.429), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.19 = f32[1]{0} reshape(f32[] %multiply.431), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.644 = f32[1]{0} add(f32[1]{0} %add.642, f32[1]{0} %reshape.19), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.122 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=5, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.123 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.124 = f32[16]{0} broadcast(f32[] %constant.123), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.125 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.122, f32[16]{0} %broadcast.124), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.408 = f32[16]{0} multiply(f32[16]{0} %multiply.125, f32[16]{0} %multiply.125), metadata={op_type="aten__mul" op_name="aten__norm.16/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.409 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.415 = f32[] reduce(f32[16]{0} %multiply.408, f32[] %constant.409), dimensions={0}, to_apply=%AddComputation.411, metadata={op_type="aten__sum" op_name="aten__norm.16/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.416 = f32[] sqrt(f32[] %reduce.415), metadata={op_type="aten__sqrt" op_name="aten__norm.16/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.418 = f32[] multiply(f32[] %sqrt.416, f32[] %sqrt.416), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.20 = f32[1]{0} reshape(f32[] %multiply.418), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.646 = f32[1]{0} add(f32[1]{0} %add.644, f32[1]{0} %reshape.20), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.118 = f32[30522]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=4, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.119 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.120 = f32[30522]{0} broadcast(f32[] %constant.119), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.121 = f32[30522]{0} multiply(f32[30522]{0} %get-tuple-element.118, f32[30522]{0} %broadcast.120), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.395 = f32[30522]{0} multiply(f32[30522]{0} %multiply.121, f32[30522]{0} %multiply.121), metadata={op_type="aten__mul" op_name="aten__norm.17/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.396 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.402 = f32[] reduce(f32[30522]{0} %multiply.395, f32[] %constant.396), dimensions={0}, to_apply=%AddComputation.398, metadata={op_type="aten__sum" op_name="aten__norm.17/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.403 = f32[] sqrt(f32[] %reduce.402), metadata={op_type="aten__sqrt" op_name="aten__norm.17/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.405 = f32[] multiply(f32[] %sqrt.403, f32[] %sqrt.403), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.21 = f32[1]{0} reshape(f32[] %multiply.405), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.648 = f32[1]{0} add(f32[1]{0} %add.646, f32[1]{0} %reshape.21), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.178 = f32[16,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=19, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.179 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.180 = f32[16,16]{1,0} broadcast(f32[] %constant.179), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.181 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.178, f32[16,16]{1,0} %broadcast.180), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.382 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.181, f32[16,16]{1,0} %multiply.181), metadata={op_type="aten__mul" op_name="aten__norm.18/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.383 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.389 = f32[] reduce(f32[16,16]{1,0} %multiply.382, f32[] %constant.383), dimensions={0,1}, to_apply=%AddComputation.385, metadata={op_type="aten__sum" op_name="aten__norm.18/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.390 = f32[] sqrt(f32[] %reduce.389), metadata={op_type="aten__sqrt" op_name="aten__norm.18/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.392 = f32[] multiply(f32[] %sqrt.390, f32[] %sqrt.390), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.22 = f32[1]{0} reshape(f32[] %multiply.392), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.650 = f32[1]{0} add(f32[1]{0} %add.648, f32[1]{0} %reshape.22), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.114 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=3, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.115 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.116 = f32[16]{0} broadcast(f32[] %constant.115), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.117 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.114, f32[16]{0} %broadcast.116), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.369 = f32[16]{0} multiply(f32[16]{0} %multiply.117, f32[16]{0} %multiply.117), metadata={op_type="aten__mul" op_name="aten__norm.19/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.370 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.376 = f32[] reduce(f32[16]{0} %multiply.369, f32[] %constant.370), dimensions={0}, to_apply=%AddComputation.372, metadata={op_type="aten__sum" op_name="aten__norm.19/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.377 = f32[] sqrt(f32[] %reduce.376), metadata={op_type="aten__sqrt" op_name="aten__norm.19/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.379 = f32[] multiply(f32[] %sqrt.377, f32[] %sqrt.377), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.23 = f32[1]{0} reshape(f32[] %multiply.379), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.652 = f32[1]{0} add(f32[1]{0} %add.650, f32[1]{0} %reshape.23), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.110 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=2, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.111 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.112 = f32[16]{0} broadcast(f32[] %constant.111), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.113 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.110, f32[16]{0} %broadcast.112), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.356 = f32[16]{0} multiply(f32[16]{0} %multiply.113, f32[16]{0} %multiply.113), metadata={op_type="aten__mul" op_name="aten__norm.20/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.357 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.363 = f32[] reduce(f32[16]{0} %multiply.356, f32[] %constant.357), dimensions={0}, to_apply=%AddComputation.359, metadata={op_type="aten__sum" op_name="aten__norm.20/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.364 = f32[] sqrt(f32[] %reduce.363), metadata={op_type="aten__sqrt" op_name="aten__norm.20/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.366 = f32[] multiply(f32[] %sqrt.364, f32[] %sqrt.364), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.24 = f32[1]{0} reshape(f32[] %multiply.366), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.654 = f32[1]{0} add(f32[1]{0} %add.652, f32[1]{0} %reshape.24), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.106 = f32[16]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=1, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.107 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.108 = f32[16]{0} broadcast(f32[] %constant.107), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.109 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.106, f32[16]{0} %broadcast.108), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.343 = f32[16]{0} multiply(f32[16]{0} %multiply.109, f32[16]{0} %multiply.109), metadata={op_type="aten__mul" op_name="aten__norm.21/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.344 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.350 = f32[] reduce(f32[16]{0} %multiply.343, f32[] %constant.344), dimensions={0}, to_apply=%AddComputation.346, metadata={op_type="aten__sum" op_name="aten__norm.21/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.351 = f32[] sqrt(f32[] %reduce.350), metadata={op_type="aten__sqrt" op_name="aten__norm.21/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.353 = f32[] multiply(f32[] %sqrt.351, f32[] %sqrt.351), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.25 = f32[1]{0} reshape(f32[] %multiply.353), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.656 = f32[1]{0} add(f32[1]{0} %add.654, f32[1]{0} %reshape.25), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.174 = f32[2,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=18, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.175 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.176 = f32[2,16]{1,0} broadcast(f32[] %constant.175), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.177 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.174, f32[2,16]{1,0} %broadcast.176), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.330 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.177, f32[2,16]{1,0} %multiply.177), metadata={op_type="aten__mul" op_name="aten__norm.22/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.331 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.337 = f32[] reduce(f32[2,16]{1,0} %multiply.330, f32[] %constant.331), dimensions={0,1}, to_apply=%AddComputation.333, metadata={op_type="aten__sum" op_name="aten__norm.22/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.338 = f32[] sqrt(f32[] %reduce.337), metadata={op_type="aten__sqrt" op_name="aten__norm.22/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.340 = f32[] multiply(f32[] %sqrt.338, f32[] %sqrt.338), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.26 = f32[1]{0} reshape(f32[] %multiply.340), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.658 = f32[1]{0} add(f32[1]{0} %add.656, f32[1]{0} %reshape.26), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %get-tuple-element.102 = f32[2]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.103 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.104 = f32[2]{0} broadcast(f32[] %constant.103), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.105 = f32[2]{0} multiply(f32[2]{0} %get-tuple-element.102, f32[2]{0} %broadcast.104), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.317 = f32[2]{0} multiply(f32[2]{0} %multiply.105, f32[2]{0} %multiply.105), metadata={op_type="aten__mul" op_name="aten__norm.23/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.318 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.324 = f32[] reduce(f32[2]{0} %multiply.317, f32[] %constant.318), dimensions={0}, to_apply=%AddComputation.320, metadata={op_type="aten__sum" op_name="aten__norm.23/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.325 = f32[] sqrt(f32[] %reduce.324), metadata={op_type="aten__sqrt" op_name="aten__norm.23/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.327 = f32[] multiply(f32[] %sqrt.325, f32[] %sqrt.325), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.27 = f32[1]{0} reshape(f32[] %multiply.327), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %add.660 = f32[1]{0} add(f32[1]{0} %add.658, f32[1]{0} %reshape.27), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=129}
  %p35.314 = f32[] parameter(35), frontend_attributes={neff_input_names="input35"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %reshape.28 = f32[1]{0} reshape(f32[] %p35.314), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %divide.662 = f32[1]{0} divide(f32[1]{0} %add.660, f32[1]{0} %reshape.28), metadata={op_type="aten__div" op_name="aten__div" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=130}
  %get-tuple-element.206 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=26, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.207 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.208 = f32[8,16]{1,0} broadcast(f32[] %constant.207), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.209 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.206, f32[8,16]{1,0} %broadcast.208), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.303 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.209, f32[8,16]{1,0} %multiply.209), metadata={op_type="aten__mul" op_name="aten__norm.24/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.304 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.310 = f32[] reduce(f32[8,16]{1,0} %multiply.303, f32[] %constant.304), dimensions={0,1}, to_apply=%AddComputation.306, metadata={op_type="aten__sum" op_name="aten__norm.24/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.311 = f32[] sqrt(f32[] %reduce.310), metadata={op_type="aten__sqrt" op_name="aten__norm.24/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.313 = f32[] multiply(f32[] %sqrt.311, f32[] %sqrt.311), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.29 = f32[1]{0} reshape(f32[] %multiply.313), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.664 = f32[1]{0} add(f32[1]{0} %divide.662, f32[1]{0} %reshape.29), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.162 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=15, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.163 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.164 = f32[8]{0} broadcast(f32[] %constant.163), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.165 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.162, f32[8]{0} %broadcast.164), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.290 = f32[8]{0} multiply(f32[8]{0} %multiply.165, f32[8]{0} %multiply.165), metadata={op_type="aten__mul" op_name="aten__norm.25/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.291 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.297 = f32[] reduce(f32[8]{0} %multiply.290, f32[] %constant.291), dimensions={0}, to_apply=%AddComputation.293, metadata={op_type="aten__sum" op_name="aten__norm.25/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.298 = f32[] sqrt(f32[] %reduce.297), metadata={op_type="aten__sqrt" op_name="aten__norm.25/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.300 = f32[] multiply(f32[] %sqrt.298, f32[] %sqrt.298), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.30 = f32[1]{0} reshape(f32[] %multiply.300), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.666 = f32[1]{0} add(f32[1]{0} %add.664, f32[1]{0} %reshape.30), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.202 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=25, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.203 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.204 = f32[8,16]{1,0} broadcast(f32[] %constant.203), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.205 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.202, f32[8,16]{1,0} %broadcast.204), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.277 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.205, f32[8,16]{1,0} %multiply.205), metadata={op_type="aten__mul" op_name="aten__norm.26/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.278 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.284 = f32[] reduce(f32[8,16]{1,0} %multiply.277, f32[] %constant.278), dimensions={0,1}, to_apply=%AddComputation.280, metadata={op_type="aten__sum" op_name="aten__norm.26/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.285 = f32[] sqrt(f32[] %reduce.284), metadata={op_type="aten__sqrt" op_name="aten__norm.26/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.287 = f32[] multiply(f32[] %sqrt.285, f32[] %sqrt.285), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.31 = f32[1]{0} reshape(f32[] %multiply.287), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.668 = f32[1]{0} add(f32[1]{0} %add.666, f32[1]{0} %reshape.31), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.158 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=14, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.159 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.160 = f32[8]{0} broadcast(f32[] %constant.159), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.161 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.158, f32[8]{0} %broadcast.160), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.264 = f32[8]{0} multiply(f32[8]{0} %multiply.161, f32[8]{0} %multiply.161), metadata={op_type="aten__mul" op_name="aten__norm.27/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.265 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.271 = f32[] reduce(f32[8]{0} %multiply.264, f32[] %constant.265), dimensions={0}, to_apply=%AddComputation.267, metadata={op_type="aten__sum" op_name="aten__norm.27/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.272 = f32[] sqrt(f32[] %reduce.271), metadata={op_type="aten__sqrt" op_name="aten__norm.27/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.274 = f32[] multiply(f32[] %sqrt.272, f32[] %sqrt.272), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.32 = f32[1]{0} reshape(f32[] %multiply.274), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.670 = f32[1]{0} add(f32[1]{0} %add.668, f32[1]{0} %reshape.32), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.198 = f32[8,16]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=24, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.199 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.200 = f32[8,16]{1,0} broadcast(f32[] %constant.199), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.201 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.198, f32[8,16]{1,0} %broadcast.200), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.251 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.201, f32[8,16]{1,0} %multiply.201), metadata={op_type="aten__mul" op_name="aten__norm.28/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.252 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.258 = f32[] reduce(f32[8,16]{1,0} %multiply.251, f32[] %constant.252), dimensions={0,1}, to_apply=%AddComputation.254, metadata={op_type="aten__sum" op_name="aten__norm.28/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.259 = f32[] sqrt(f32[] %reduce.258), metadata={op_type="aten__sqrt" op_name="aten__norm.28/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.261 = f32[] multiply(f32[] %sqrt.259, f32[] %sqrt.259), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.33 = f32[1]{0} reshape(f32[] %multiply.261), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.672 = f32[1]{0} add(f32[1]{0} %add.670, f32[1]{0} %reshape.33), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.154 = f32[8]{0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=13, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.155 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.156 = f32[8]{0} broadcast(f32[] %constant.155), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.157 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.154, f32[8]{0} %broadcast.156), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.238 = f32[8]{0} multiply(f32[8]{0} %multiply.157, f32[8]{0} %multiply.157), metadata={op_type="aten__mul" op_name="aten__norm.29/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.239 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.245 = f32[] reduce(f32[8]{0} %multiply.238, f32[] %constant.239), dimensions={0}, to_apply=%AddComputation.241, metadata={op_type="aten__sum" op_name="aten__norm.29/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.246 = f32[] sqrt(f32[] %reduce.245), metadata={op_type="aten__sqrt" op_name="aten__norm.29/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.248 = f32[] multiply(f32[] %sqrt.246, f32[] %sqrt.246), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.34 = f32[1]{0} reshape(f32[] %multiply.248), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.674 = f32[1]{0} add(f32[1]{0} %add.672, f32[1]{0} %reshape.34), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.194 = f32[16,8]{1,0} get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=23, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.195 = f32[] constant(0.125), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %broadcast.196 = f32[16,8]{1,0} broadcast(f32[] %constant.195), dimensions={}, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.197 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %get-tuple-element.194, f32[16,8]{1,0} %broadcast.196), metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %multiply.225 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.197, f32[16,8]{1,0} %multiply.197), metadata={op_type="aten__mul" op_name="aten__norm.30/aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %constant.226 = f32[] constant(0), metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %reduce.232 = f32[] reduce(f32[16,8]{1,0} %multiply.225, f32[] %constant.226), dimensions={0,1}, to_apply=%AddComputation.228, metadata={op_type="aten__sum" op_name="aten__norm.30/aten__sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %sqrt.233 = f32[] sqrt(f32[] %reduce.232), metadata={op_type="aten__sqrt" op_name="aten__norm.30/aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/functional.py" source_line=1624}
  %multiply.235 = f32[] multiply(f32[] %sqrt.233, f32[] %sqrt.233), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=40}
  %reshape.35 = f32[1]{0} reshape(f32[] %multiply.235), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %add.676 = f32[1]{0} add(f32[1]{0} %add.674, f32[1]{0} %reshape.35), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=134}
  %get-tuple-element.679 = f32[] get-tuple-element((f32[2]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, /*index=5*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, /*index=10*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[8]{0}, f32[8]{0}, /*index=15*/f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[2,16]{1,0}, f32[16,16]{1,0}, /*index=20*/f32[16,16]{1,0}, f32[16,4096]{1,0}, f32[4096,16]{1,0}, f32[16,8]{1,0}, f32[8,16]{1,0}, /*index=25*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[2,16]{1,0}, f32[512,16]{1,0}, f32[30522,16]{1,0}, /*index=30*/f32[]) %all-reduce.101), index=30, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %all-reduce.684 = (f32[1]{0}, f32[]) all-reduce(f32[1]{0} %add.676, f32[] %get-tuple-element.679), replica_groups={{0,1},{2,3},{4,5},{6,7}}, to_apply=%AddComputation.680, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %get-tuple-element.685 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.684), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=484}
  %constant.3 = f32[1]{0} constant({0.5})
  %power.687 = f32[1]{0} power(f32[1]{0} %get-tuple-element.685, f32[1]{0} %constant.3), metadata={op_type="aten__pow" op_name="aten__pow" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=137}
  %p0.8 = f32[] parameter(0), frontend_attributes={neff_input_names="input0"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %reshape.40 = f32[1]{0} reshape(f32[] %p0.8), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %add.689 = f32[1]{0} add(f32[1]{0} %power.687, f32[1]{0} %reshape.40), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=188}
  %divide.692 = f32[1]{0} divide(f32[1]{0} %constant.2, f32[1]{0} %add.689), metadata={op_type="aten__reciprocal" op_name="aten__reciprocal" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch/_tensor.py" source_line=913}
  %constant.8 = f32[1]{0} constant({1})
  %compare.699 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.8), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.9 = f32[1]{0} constant({1})
  %select.701 = f32[1]{0} select(pred[1]{0} %compare.699, f32[1]{0} %divide.692, f32[1]{0} %constant.9), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.182 = f32[1]{0} constant({0.125})
  %multiply.168 = f32[1]{0} multiply(f32[1]{0} %select.701, f32[1]{0} %constant.182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.650 = f32[] reshape(f32[1]{0} %multiply.168), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.6 = f32[30522,16]{1,0} broadcast(f32[] %reshape.650), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.706 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %get-tuple-element.218, f32[30522,16]{1,0} %broadcast.6), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %p38.722 = f32[] parameter(38), frontend_attributes={neff_input_names="input38"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.726 = f32[30522,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.727 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.706, f32[30522,16]{1,0} %broadcast.726), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.736 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.2, f32[30522,16]{1,0} %multiply.727), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.10 = f32[] constant(0)
  %p37.707 = f32[] parameter(37), frontend_attributes={neff_input_names="input37"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.35 = f32[] multiply(f32[] %constant.10, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.9 = f32[30522,16]{1,0} broadcast(f32[] %multiply.35), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.715 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.706, f32[30522,16]{1,0} %multiply.706), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %p1.10 = f32[] parameter(1), frontend_attributes={neff_input_names="input1"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.716 = f32[30522,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.717 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %multiply.715, f32[30522,16]{1,0} %broadcast.716), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.718 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %broadcast.9, f32[30522,16]{1,0} %multiply.717), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.719 = f32[30522,16]{1,0} sqrt(f32[30522,16]{1,0} %add.718), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.720 = f32[30522,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.721 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %sqrt.719, f32[30522,16]{1,0} %broadcast.720), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.738 = f32[30522,16]{1,0} divide(f32[30522,16]{1,0} %add.736, f32[30522,16]{1,0} %add.721), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.6 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.739 = f32[30522,16]{1,0} broadcast(f32[] %constant.6), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.740 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %divide.738, f32[30522,16]{1,0} %broadcast.739), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.741 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %p40.737, f32[30522,16]{1,0} %multiply.740), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.5 = f32[30522,16]{1,0} broadcast(f32[] %constant.1), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.742 = f32[30522,16]{1,0} multiply(f32[30522,16]{1,0} %add.741, f32[30522,16]{1,0} %broadcast.5), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.743 = f32[30522,16]{1,0} add(f32[30522,16]{1,0} %add.741, f32[30522,16]{1,0} %multiply.742), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p41.794 = f32[512,16]{1,0} parameter(41), frontend_attributes={neff_input_names="input41"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.12 = f32[] constant(0)
  %multiply.36 = f32[] multiply(f32[] %constant.12, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.12 = f32[512,16]{1,0} broadcast(f32[] %multiply.36), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.16 = f32[1]{0} constant({1})
  %compare.759 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.16), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.18 = f32[1]{0} constant({1})
  %select.761 = f32[1]{0} select(pred[1]{0} %compare.759, f32[1]{0} %divide.692, f32[1]{0} %constant.18), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.184 = f32[1]{0} constant({0.125})
  %multiply.170 = f32[1]{0} multiply(f32[1]{0} %select.761, f32[1]{0} %constant.184), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.653 = f32[] reshape(f32[1]{0} %multiply.170), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.15 = f32[512,16]{1,0} broadcast(f32[] %reshape.653), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.766 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %get-tuple-element.214, f32[512,16]{1,0} %broadcast.15), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.784 = f32[512,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.785 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.766, f32[512,16]{1,0} %broadcast.784), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.793 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.12, f32[512,16]{1,0} %multiply.785), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.19 = f32[] constant(0)
  %multiply.39 = f32[] multiply(f32[] %constant.19, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.18 = f32[512,16]{1,0} broadcast(f32[] %multiply.39), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.774 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.766, f32[512,16]{1,0} %multiply.766), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.775 = f32[512,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.776 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %multiply.774, f32[512,16]{1,0} %broadcast.775), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.777 = f32[512,16]{1,0} add(f32[512,16]{1,0} %broadcast.18, f32[512,16]{1,0} %multiply.776), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.778 = f32[512,16]{1,0} sqrt(f32[512,16]{1,0} %add.777), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.779 = f32[512,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.780 = f32[512,16]{1,0} add(f32[512,16]{1,0} %sqrt.778, f32[512,16]{1,0} %broadcast.779), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.795 = f32[512,16]{1,0} divide(f32[512,16]{1,0} %add.793, f32[512,16]{1,0} %add.780), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.749 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.796 = f32[512,16]{1,0} broadcast(f32[] %constant.749), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.797 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %divide.795, f32[512,16]{1,0} %broadcast.796), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.798 = f32[512,16]{1,0} add(f32[512,16]{1,0} %p41.794, f32[512,16]{1,0} %multiply.797), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.744 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.748 = f32[512,16]{1,0} broadcast(f32[] %constant.744), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.799 = f32[512,16]{1,0} multiply(f32[512,16]{1,0} %add.798, f32[512,16]{1,0} %broadcast.748), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.800 = f32[512,16]{1,0} add(f32[512,16]{1,0} %add.798, f32[512,16]{1,0} %multiply.799), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p42.851 = f32[2,16]{1,0} parameter(42), frontend_attributes={neff_input_names="input42"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.20 = f32[] constant(0)
  %multiply.40 = f32[] multiply(f32[] %constant.20, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.22 = f32[2,16]{1,0} broadcast(f32[] %multiply.40), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.22 = f32[1]{0} constant({1})
  %compare.816 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.22), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.23 = f32[1]{0} constant({1})
  %select.818 = f32[1]{0} select(pred[1]{0} %compare.816, f32[1]{0} %divide.692, f32[1]{0} %constant.23), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.185 = f32[1]{0} constant({0.125})
  %multiply.171 = f32[1]{0} multiply(f32[1]{0} %select.818, f32[1]{0} %constant.185), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.656 = f32[] reshape(f32[1]{0} %multiply.171), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.25 = f32[2,16]{1,0} broadcast(f32[] %reshape.656), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.823 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.210, f32[2,16]{1,0} %broadcast.25), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.841 = f32[2,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.842 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.823, f32[2,16]{1,0} %broadcast.841), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.850 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.22, f32[2,16]{1,0} %multiply.842), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.24 = f32[] constant(0)
  %multiply.43 = f32[] multiply(f32[] %constant.24, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.28 = f32[2,16]{1,0} broadcast(f32[] %multiply.43), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.831 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.823, f32[2,16]{1,0} %multiply.823), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.832 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.833 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.831, f32[2,16]{1,0} %broadcast.832), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.834 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.28, f32[2,16]{1,0} %multiply.833), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.835 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.834), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.836 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.837 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.835, f32[2,16]{1,0} %broadcast.836), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.852 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.850, f32[2,16]{1,0} %add.837), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.806 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.853 = f32[2,16]{1,0} broadcast(f32[] %constant.806), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.854 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.852, f32[2,16]{1,0} %broadcast.853), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.855 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p42.851, f32[2,16]{1,0} %multiply.854), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.801 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.805 = f32[2,16]{1,0} broadcast(f32[] %constant.801), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.856 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.855, f32[2,16]{1,0} %broadcast.805), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.857 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.855, f32[2,16]{1,0} %multiply.856), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p43.902 = f32[16]{0} parameter(43), frontend_attributes={neff_input_names="input43"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.25 = f32[] constant(0)
  %multiply.44 = f32[] multiply(f32[] %constant.25, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.31 = f32[16]{0} broadcast(f32[] %multiply.44), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.27 = f32[1]{0} constant({1})
  %compare.868 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.27), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.28 = f32[1]{0} constant({1})
  %select.870 = f32[1]{0} select(pred[1]{0} %compare.868, f32[1]{0} %divide.692, f32[1]{0} %constant.28), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.186 = f32[1]{0} constant({0.125})
  %multiply.172 = f32[1]{0} multiply(f32[1]{0} %select.870, f32[1]{0} %constant.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.659 = f32[] reshape(f32[1]{0} %multiply.172), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.32 = f32[16]{0} broadcast(f32[] %reshape.659), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.874 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.170, f32[16]{0} %broadcast.32), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.892 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.893 = f32[16]{0} multiply(f32[16]{0} %multiply.874, f32[16]{0} %broadcast.892), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.901 = f32[16]{0} add(f32[16]{0} %broadcast.31, f32[16]{0} %multiply.893), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.29 = f32[] constant(0)
  %multiply.47 = f32[] multiply(f32[] %constant.29, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.35 = f32[16]{0} broadcast(f32[] %multiply.47), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.882 = f32[16]{0} multiply(f32[16]{0} %multiply.874, f32[16]{0} %multiply.874), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.883 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.884 = f32[16]{0} multiply(f32[16]{0} %multiply.882, f32[16]{0} %broadcast.883), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.885 = f32[16]{0} add(f32[16]{0} %broadcast.35, f32[16]{0} %multiply.884), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.886 = f32[16]{0} sqrt(f32[16]{0} %add.885), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.887 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.888 = f32[16]{0} add(f32[16]{0} %sqrt.886, f32[16]{0} %broadcast.887), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.903 = f32[16]{0} divide(f32[16]{0} %add.901, f32[16]{0} %add.888), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.858 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.904 = f32[16]{0} broadcast(f32[] %constant.858), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.905 = f32[16]{0} multiply(f32[16]{0} %divide.903, f32[16]{0} %broadcast.904), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.906 = f32[16]{0} add(f32[16]{0} %p43.902, f32[16]{0} %multiply.905), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p44.951 = f32[16]{0} parameter(44), frontend_attributes={neff_input_names="input44"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.30 = f32[] constant(0)
  %multiply.48 = f32[] multiply(f32[] %constant.30, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.38 = f32[16]{0} broadcast(f32[] %multiply.48), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.32 = f32[1]{0} constant({1})
  %compare.917 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.32), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.33 = f32[1]{0} constant({1})
  %select.919 = f32[1]{0} select(pred[1]{0} %compare.917, f32[1]{0} %divide.692, f32[1]{0} %constant.33), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.188 = f32[1]{0} constant({0.125})
  %multiply.174 = f32[1]{0} multiply(f32[1]{0} %select.919, f32[1]{0} %constant.188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.662 = f32[] reshape(f32[1]{0} %multiply.174), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.39 = f32[16]{0} broadcast(f32[] %reshape.662), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.923 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.166, f32[16]{0} %broadcast.39), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.941 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.942 = f32[16]{0} multiply(f32[16]{0} %multiply.923, f32[16]{0} %broadcast.941), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.950 = f32[16]{0} add(f32[16]{0} %broadcast.38, f32[16]{0} %multiply.942), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.34 = f32[] constant(0)
  %multiply.51 = f32[] multiply(f32[] %constant.34, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.42 = f32[16]{0} broadcast(f32[] %multiply.51), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.931 = f32[16]{0} multiply(f32[16]{0} %multiply.923, f32[16]{0} %multiply.923), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.932 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.933 = f32[16]{0} multiply(f32[16]{0} %multiply.931, f32[16]{0} %broadcast.932), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.934 = f32[16]{0} add(f32[16]{0} %broadcast.42, f32[16]{0} %multiply.933), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.935 = f32[16]{0} sqrt(f32[16]{0} %add.934), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.936 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.937 = f32[16]{0} add(f32[16]{0} %sqrt.935, f32[16]{0} %broadcast.936), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.952 = f32[16]{0} divide(f32[16]{0} %add.950, f32[16]{0} %add.937), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.907 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.953 = f32[16]{0} broadcast(f32[] %constant.907), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.954 = f32[16]{0} multiply(f32[16]{0} %divide.952, f32[16]{0} %broadcast.953), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.955 = f32[16]{0} add(f32[16]{0} %p44.951, f32[16]{0} %multiply.954), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p45.1006 = f32[8,16]{1,0} parameter(45), frontend_attributes={neff_input_names="input45"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.35 = f32[] constant(0)
  %multiply.52 = f32[] multiply(f32[] %constant.35, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.45 = f32[8,16]{1,0} broadcast(f32[] %multiply.52), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.37 = f32[1]{0} constant({1})
  %compare.971 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.37), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.38 = f32[1]{0} constant({1})
  %select.973 = f32[1]{0} select(pred[1]{0} %compare.971, f32[1]{0} %divide.692, f32[1]{0} %constant.38), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.189 = f32[1]{0} constant({0.125})
  %multiply.175 = f32[1]{0} multiply(f32[1]{0} %select.973, f32[1]{0} %constant.189), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.665 = f32[] reshape(f32[1]{0} %multiply.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.47 = f32[8,16]{1,0} broadcast(f32[] %reshape.665), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.978 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.206, f32[8,16]{1,0} %broadcast.47), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.996 = f32[8,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.997 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.978, f32[8,16]{1,0} %broadcast.996), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1005 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.45, f32[8,16]{1,0} %multiply.997), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.39 = f32[] constant(0)
  %multiply.55 = f32[] multiply(f32[] %constant.39, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.50 = f32[8,16]{1,0} broadcast(f32[] %multiply.55), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.986 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.978, f32[8,16]{1,0} %multiply.978), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.987 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.988 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.986, f32[8,16]{1,0} %broadcast.987), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.989 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.50, f32[8,16]{1,0} %multiply.988), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.990 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.989), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.991 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.992 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.990, f32[8,16]{1,0} %broadcast.991), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1007 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1005, f32[8,16]{1,0} %add.992), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.961 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1008 = f32[8,16]{1,0} broadcast(f32[] %constant.961), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1009 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1007, f32[8,16]{1,0} %broadcast.1008), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1010 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p45.1006, f32[8,16]{1,0} %multiply.1009), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.956 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.960 = f32[8,16]{1,0} broadcast(f32[] %constant.956), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1011 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1010, f32[8,16]{1,0} %broadcast.960), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1012 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1010, f32[8,16]{1,0} %multiply.1011), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p46.1057 = f32[8]{0} parameter(46), frontend_attributes={neff_input_names="input46"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.40 = f32[] constant(0)
  %multiply.56 = f32[] multiply(f32[] %constant.40, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.53 = f32[8]{0} broadcast(f32[] %multiply.56), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.42 = f32[1]{0} constant({1})
  %compare.1023 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.42), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.43 = f32[1]{0} constant({1})
  %select.1025 = f32[1]{0} select(pred[1]{0} %compare.1023, f32[1]{0} %divide.692, f32[1]{0} %constant.43), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.190 = f32[1]{0} constant({0.125})
  %multiply.176 = f32[1]{0} multiply(f32[1]{0} %select.1025, f32[1]{0} %constant.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.668 = f32[] reshape(f32[1]{0} %multiply.176), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.54 = f32[8]{0} broadcast(f32[] %reshape.668), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1029 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.162, f32[8]{0} %broadcast.54), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1047 = f32[8]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1048 = f32[8]{0} multiply(f32[8]{0} %multiply.1029, f32[8]{0} %broadcast.1047), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1056 = f32[8]{0} add(f32[8]{0} %broadcast.53, f32[8]{0} %multiply.1048), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.44 = f32[] constant(0)
  %multiply.59 = f32[] multiply(f32[] %constant.44, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.57 = f32[8]{0} broadcast(f32[] %multiply.59), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1037 = f32[8]{0} multiply(f32[8]{0} %multiply.1029, f32[8]{0} %multiply.1029), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1038 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1039 = f32[8]{0} multiply(f32[8]{0} %multiply.1037, f32[8]{0} %broadcast.1038), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1040 = f32[8]{0} add(f32[8]{0} %broadcast.57, f32[8]{0} %multiply.1039), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1041 = f32[8]{0} sqrt(f32[8]{0} %add.1040), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1042 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1043 = f32[8]{0} add(f32[8]{0} %sqrt.1041, f32[8]{0} %broadcast.1042), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1058 = f32[8]{0} divide(f32[8]{0} %add.1056, f32[8]{0} %add.1043), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1013 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1059 = f32[8]{0} broadcast(f32[] %constant.1013), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1060 = f32[8]{0} multiply(f32[8]{0} %divide.1058, f32[8]{0} %broadcast.1059), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1061 = f32[8]{0} add(f32[8]{0} %p46.1057, f32[8]{0} %multiply.1060), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p47.1112 = f32[8,16]{1,0} parameter(47), frontend_attributes={neff_input_names="input47"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.45 = f32[] constant(0)
  %multiply.60 = f32[] multiply(f32[] %constant.45, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.60 = f32[8,16]{1,0} broadcast(f32[] %multiply.60), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.47 = f32[1]{0} constant({1})
  %compare.1077 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.47), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.48 = f32[1]{0} constant({1})
  %select.1079 = f32[1]{0} select(pred[1]{0} %compare.1077, f32[1]{0} %divide.692, f32[1]{0} %constant.48), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.192 = f32[1]{0} constant({0.125})
  %multiply.178 = f32[1]{0} multiply(f32[1]{0} %select.1079, f32[1]{0} %constant.192), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.671 = f32[] reshape(f32[1]{0} %multiply.178), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.62 = f32[8,16]{1,0} broadcast(f32[] %reshape.671), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1084 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.202, f32[8,16]{1,0} %broadcast.62), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1102 = f32[8,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1103 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1084, f32[8,16]{1,0} %broadcast.1102), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1111 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.60, f32[8,16]{1,0} %multiply.1103), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.49 = f32[] constant(0)
  %multiply.63 = f32[] multiply(f32[] %constant.49, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.65 = f32[8,16]{1,0} broadcast(f32[] %multiply.63), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1092 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1084, f32[8,16]{1,0} %multiply.1084), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1093 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1094 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1092, f32[8,16]{1,0} %broadcast.1093), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1095 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.65, f32[8,16]{1,0} %multiply.1094), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1096 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.1095), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1097 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1098 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.1096, f32[8,16]{1,0} %broadcast.1097), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1113 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1111, f32[8,16]{1,0} %add.1098), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1067 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1114 = f32[8,16]{1,0} broadcast(f32[] %constant.1067), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1115 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1113, f32[8,16]{1,0} %broadcast.1114), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1116 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p47.1112, f32[8,16]{1,0} %multiply.1115), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1062 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1066 = f32[8,16]{1,0} broadcast(f32[] %constant.1062), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1117 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1116, f32[8,16]{1,0} %broadcast.1066), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1118 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1116, f32[8,16]{1,0} %multiply.1117), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p48.1163 = f32[8]{0} parameter(48), frontend_attributes={neff_input_names="input48"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.50 = f32[] constant(0)
  %multiply.64 = f32[] multiply(f32[] %constant.50, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.68 = f32[8]{0} broadcast(f32[] %multiply.64), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.52 = f32[1]{0} constant({1})
  %compare.1129 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.52), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.53 = f32[1]{0} constant({1})
  %select.1131 = f32[1]{0} select(pred[1]{0} %compare.1129, f32[1]{0} %divide.692, f32[1]{0} %constant.53), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.193 = f32[1]{0} constant({0.125})
  %multiply.179 = f32[1]{0} multiply(f32[1]{0} %select.1131, f32[1]{0} %constant.193), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.674 = f32[] reshape(f32[1]{0} %multiply.179), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.69 = f32[8]{0} broadcast(f32[] %reshape.674), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1135 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.158, f32[8]{0} %broadcast.69), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1153 = f32[8]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1154 = f32[8]{0} multiply(f32[8]{0} %multiply.1135, f32[8]{0} %broadcast.1153), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1162 = f32[8]{0} add(f32[8]{0} %broadcast.68, f32[8]{0} %multiply.1154), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.54 = f32[] constant(0)
  %multiply.67 = f32[] multiply(f32[] %constant.54, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.72 = f32[8]{0} broadcast(f32[] %multiply.67), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1143 = f32[8]{0} multiply(f32[8]{0} %multiply.1135, f32[8]{0} %multiply.1135), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1144 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1145 = f32[8]{0} multiply(f32[8]{0} %multiply.1143, f32[8]{0} %broadcast.1144), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1146 = f32[8]{0} add(f32[8]{0} %broadcast.72, f32[8]{0} %multiply.1145), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1147 = f32[8]{0} sqrt(f32[8]{0} %add.1146), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1148 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1149 = f32[8]{0} add(f32[8]{0} %sqrt.1147, f32[8]{0} %broadcast.1148), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1164 = f32[8]{0} divide(f32[8]{0} %add.1162, f32[8]{0} %add.1149), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1119 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1165 = f32[8]{0} broadcast(f32[] %constant.1119), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1166 = f32[8]{0} multiply(f32[8]{0} %divide.1164, f32[8]{0} %broadcast.1165), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1167 = f32[8]{0} add(f32[8]{0} %p48.1163, f32[8]{0} %multiply.1166), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p49.1218 = f32[8,16]{1,0} parameter(49), frontend_attributes={neff_input_names="input49"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.55 = f32[] constant(0)
  %multiply.68 = f32[] multiply(f32[] %constant.55, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.75 = f32[8,16]{1,0} broadcast(f32[] %multiply.68), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.57 = f32[1]{0} constant({1})
  %compare.1183 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.57), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.58 = f32[1]{0} constant({1})
  %select.1185 = f32[1]{0} select(pred[1]{0} %compare.1183, f32[1]{0} %divide.692, f32[1]{0} %constant.58), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.194 = f32[1]{0} constant({0.125})
  %multiply.180 = f32[1]{0} multiply(f32[1]{0} %select.1185, f32[1]{0} %constant.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.677 = f32[] reshape(f32[1]{0} %multiply.180), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.77 = f32[8,16]{1,0} broadcast(f32[] %reshape.677), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1190 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %get-tuple-element.198, f32[8,16]{1,0} %broadcast.77), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1208 = f32[8,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1209 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1190, f32[8,16]{1,0} %broadcast.1208), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1217 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.75, f32[8,16]{1,0} %multiply.1209), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.59 = f32[] constant(0)
  %multiply.71 = f32[] multiply(f32[] %constant.59, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.80 = f32[8,16]{1,0} broadcast(f32[] %multiply.71), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1198 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1190, f32[8,16]{1,0} %multiply.1190), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1199 = f32[8,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1200 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %multiply.1198, f32[8,16]{1,0} %broadcast.1199), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1201 = f32[8,16]{1,0} add(f32[8,16]{1,0} %broadcast.80, f32[8,16]{1,0} %multiply.1200), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1202 = f32[8,16]{1,0} sqrt(f32[8,16]{1,0} %add.1201), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1203 = f32[8,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1204 = f32[8,16]{1,0} add(f32[8,16]{1,0} %sqrt.1202, f32[8,16]{1,0} %broadcast.1203), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1219 = f32[8,16]{1,0} divide(f32[8,16]{1,0} %add.1217, f32[8,16]{1,0} %add.1204), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1173 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1220 = f32[8,16]{1,0} broadcast(f32[] %constant.1173), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1221 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %divide.1219, f32[8,16]{1,0} %broadcast.1220), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1222 = f32[8,16]{1,0} add(f32[8,16]{1,0} %p49.1218, f32[8,16]{1,0} %multiply.1221), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1168 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1172 = f32[8,16]{1,0} broadcast(f32[] %constant.1168), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1223 = f32[8,16]{1,0} multiply(f32[8,16]{1,0} %add.1222, f32[8,16]{1,0} %broadcast.1172), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1224 = f32[8,16]{1,0} add(f32[8,16]{1,0} %add.1222, f32[8,16]{1,0} %multiply.1223), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p50.1269 = f32[8]{0} parameter(50), frontend_attributes={neff_input_names="input50"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=624}
  %constant.60 = f32[] constant(0)
  %multiply.72 = f32[] multiply(f32[] %constant.60, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.83 = f32[8]{0} broadcast(f32[] %multiply.72), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.62 = f32[1]{0} constant({1})
  %compare.1235 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.62), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.63 = f32[1]{0} constant({1})
  %select.1237 = f32[1]{0} select(pred[1]{0} %compare.1235, f32[1]{0} %divide.692, f32[1]{0} %constant.63), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.196 = f32[1]{0} constant({0.125})
  %multiply.182 = f32[1]{0} multiply(f32[1]{0} %select.1237, f32[1]{0} %constant.196), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.680 = f32[] reshape(f32[1]{0} %multiply.182), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.84 = f32[8]{0} broadcast(f32[] %reshape.680), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1241 = f32[8]{0} multiply(f32[8]{0} %get-tuple-element.154, f32[8]{0} %broadcast.84), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1259 = f32[8]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1260 = f32[8]{0} multiply(f32[8]{0} %multiply.1241, f32[8]{0} %broadcast.1259), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1268 = f32[8]{0} add(f32[8]{0} %broadcast.83, f32[8]{0} %multiply.1260), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.64 = f32[] constant(0)
  %multiply.75 = f32[] multiply(f32[] %constant.64, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.87 = f32[8]{0} broadcast(f32[] %multiply.75), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1249 = f32[8]{0} multiply(f32[8]{0} %multiply.1241, f32[8]{0} %multiply.1241), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1250 = f32[8]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1251 = f32[8]{0} multiply(f32[8]{0} %multiply.1249, f32[8]{0} %broadcast.1250), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1252 = f32[8]{0} add(f32[8]{0} %broadcast.87, f32[8]{0} %multiply.1251), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1253 = f32[8]{0} sqrt(f32[8]{0} %add.1252), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1254 = f32[8]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1255 = f32[8]{0} add(f32[8]{0} %sqrt.1253, f32[8]{0} %broadcast.1254), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1270 = f32[8]{0} divide(f32[8]{0} %add.1268, f32[8]{0} %add.1255), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1225 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1271 = f32[8]{0} broadcast(f32[] %constant.1225), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1272 = f32[8]{0} multiply(f32[8]{0} %divide.1270, f32[8]{0} %broadcast.1271), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1273 = f32[8]{0} add(f32[8]{0} %p50.1269, f32[8]{0} %multiply.1272), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p51.1324 = f32[16,8]{1,0} parameter(51), frontend_attributes={neff_input_names="input51"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=322}
  %constant.65 = f32[] constant(0)
  %multiply.76 = f32[] multiply(f32[] %constant.65, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.90 = f32[16,8]{1,0} broadcast(f32[] %multiply.76), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.67 = f32[1]{0} constant({1})
  %compare.1289 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.67), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.68 = f32[1]{0} constant({1})
  %select.1291 = f32[1]{0} select(pred[1]{0} %compare.1289, f32[1]{0} %divide.692, f32[1]{0} %constant.68), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.197 = f32[1]{0} constant({0.125})
  %multiply.183 = f32[1]{0} multiply(f32[1]{0} %select.1291, f32[1]{0} %constant.197), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.683 = f32[] reshape(f32[1]{0} %multiply.183), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.92 = f32[16,8]{1,0} broadcast(f32[] %reshape.683), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1296 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %get-tuple-element.194, f32[16,8]{1,0} %broadcast.92), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1314 = f32[16,8]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1315 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1296, f32[16,8]{1,0} %broadcast.1314), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1323 = f32[16,8]{1,0} add(f32[16,8]{1,0} %broadcast.90, f32[16,8]{1,0} %multiply.1315), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.69 = f32[] constant(0)
  %multiply.79 = f32[] multiply(f32[] %constant.69, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.95 = f32[16,8]{1,0} broadcast(f32[] %multiply.79), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1304 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1296, f32[16,8]{1,0} %multiply.1296), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1305 = f32[16,8]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1306 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %multiply.1304, f32[16,8]{1,0} %broadcast.1305), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1307 = f32[16,8]{1,0} add(f32[16,8]{1,0} %broadcast.95, f32[16,8]{1,0} %multiply.1306), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1308 = f32[16,8]{1,0} sqrt(f32[16,8]{1,0} %add.1307), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1309 = f32[16,8]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1310 = f32[16,8]{1,0} add(f32[16,8]{1,0} %sqrt.1308, f32[16,8]{1,0} %broadcast.1309), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1325 = f32[16,8]{1,0} divide(f32[16,8]{1,0} %add.1323, f32[16,8]{1,0} %add.1310), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1279 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1326 = f32[16,8]{1,0} broadcast(f32[] %constant.1279), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1327 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %divide.1325, f32[16,8]{1,0} %broadcast.1326), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1328 = f32[16,8]{1,0} add(f32[16,8]{1,0} %p51.1324, f32[16,8]{1,0} %multiply.1327), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1274 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1278 = f32[16,8]{1,0} broadcast(f32[] %constant.1274), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1329 = f32[16,8]{1,0} multiply(f32[16,8]{1,0} %add.1328, f32[16,8]{1,0} %broadcast.1278), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1330 = f32[16,8]{1,0} add(f32[16,8]{1,0} %add.1328, f32[16,8]{1,0} %multiply.1329), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p52.1375 = f32[16]{0} parameter(52), frontend_attributes={neff_input_names="input52"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/layers.py" source_line=800}
  %constant.70 = f32[] constant(0)
  %multiply.80 = f32[] multiply(f32[] %constant.70, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.98 = f32[16]{0} broadcast(f32[] %multiply.80), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.72 = f32[1]{0} constant({1})
  %compare.1341 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.72), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.73 = f32[1]{0} constant({1})
  %select.1343 = f32[1]{0} select(pred[1]{0} %compare.1341, f32[1]{0} %divide.692, f32[1]{0} %constant.73), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.198 = f32[1]{0} constant({0.125})
  %multiply.184 = f32[1]{0} multiply(f32[1]{0} %select.1343, f32[1]{0} %constant.198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.686 = f32[] reshape(f32[1]{0} %multiply.184), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.99 = f32[16]{0} broadcast(f32[] %reshape.686), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1347 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.150, f32[16]{0} %broadcast.99), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1365 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1366 = f32[16]{0} multiply(f32[16]{0} %multiply.1347, f32[16]{0} %broadcast.1365), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1374 = f32[16]{0} add(f32[16]{0} %broadcast.98, f32[16]{0} %multiply.1366), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.74 = f32[] constant(0)
  %multiply.83 = f32[] multiply(f32[] %constant.74, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.102 = f32[16]{0} broadcast(f32[] %multiply.83), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1355 = f32[16]{0} multiply(f32[16]{0} %multiply.1347, f32[16]{0} %multiply.1347), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1356 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1357 = f32[16]{0} multiply(f32[16]{0} %multiply.1355, f32[16]{0} %broadcast.1356), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1358 = f32[16]{0} add(f32[16]{0} %broadcast.102, f32[16]{0} %multiply.1357), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1359 = f32[16]{0} sqrt(f32[16]{0} %add.1358), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1360 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1361 = f32[16]{0} add(f32[16]{0} %sqrt.1359, f32[16]{0} %broadcast.1360), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1376 = f32[16]{0} divide(f32[16]{0} %add.1374, f32[16]{0} %add.1361), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1331 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1377 = f32[16]{0} broadcast(f32[] %constant.1331), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1378 = f32[16]{0} multiply(f32[16]{0} %divide.1376, f32[16]{0} %broadcast.1377), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1379 = f32[16]{0} add(f32[16]{0} %p52.1375, f32[16]{0} %multiply.1378), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p53.1424 = f32[16]{0} parameter(53), frontend_attributes={neff_input_names="input53"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.75 = f32[] constant(0)
  %multiply.84 = f32[] multiply(f32[] %constant.75, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.106 = f32[16]{0} broadcast(f32[] %multiply.84), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.77 = f32[1]{0} constant({1})
  %compare.1390 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.77), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.78 = f32[1]{0} constant({1})
  %select.1392 = f32[1]{0} select(pred[1]{0} %compare.1390, f32[1]{0} %divide.692, f32[1]{0} %constant.78), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.200 = f32[1]{0} constant({0.125})
  %multiply.186 = f32[1]{0} multiply(f32[1]{0} %select.1392, f32[1]{0} %constant.200), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.689 = f32[] reshape(f32[1]{0} %multiply.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.107 = f32[16]{0} broadcast(f32[] %reshape.689), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1396 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.146, f32[16]{0} %broadcast.107), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1414 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1415 = f32[16]{0} multiply(f32[16]{0} %multiply.1396, f32[16]{0} %broadcast.1414), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1423 = f32[16]{0} add(f32[16]{0} %broadcast.106, f32[16]{0} %multiply.1415), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.79 = f32[] constant(0)
  %multiply.87 = f32[] multiply(f32[] %constant.79, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.111 = f32[16]{0} broadcast(f32[] %multiply.87), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1404 = f32[16]{0} multiply(f32[16]{0} %multiply.1396, f32[16]{0} %multiply.1396), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1405 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1406 = f32[16]{0} multiply(f32[16]{0} %multiply.1404, f32[16]{0} %broadcast.1405), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1407 = f32[16]{0} add(f32[16]{0} %broadcast.111, f32[16]{0} %multiply.1406), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1408 = f32[16]{0} sqrt(f32[16]{0} %add.1407), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1409 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1410 = f32[16]{0} add(f32[16]{0} %sqrt.1408, f32[16]{0} %broadcast.1409), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1425 = f32[16]{0} divide(f32[16]{0} %add.1423, f32[16]{0} %add.1410), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1380 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1426 = f32[16]{0} broadcast(f32[] %constant.1380), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1427 = f32[16]{0} multiply(f32[16]{0} %divide.1425, f32[16]{0} %broadcast.1426), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1428 = f32[16]{0} add(f32[16]{0} %p53.1424, f32[16]{0} %multiply.1427), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p54.1473 = f32[16]{0} parameter(54), frontend_attributes={neff_input_names="input54"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.80 = f32[] constant(0)
  %multiply.88 = f32[] multiply(f32[] %constant.80, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.115 = f32[16]{0} broadcast(f32[] %multiply.88), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.82 = f32[1]{0} constant({1})
  %compare.1439 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.82), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.83 = f32[1]{0} constant({1})
  %select.1441 = f32[1]{0} select(pred[1]{0} %compare.1439, f32[1]{0} %divide.692, f32[1]{0} %constant.83), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.201 = f32[1]{0} constant({0.125})
  %multiply.187 = f32[1]{0} multiply(f32[1]{0} %select.1441, f32[1]{0} %constant.201), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.692 = f32[] reshape(f32[1]{0} %multiply.187), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.117 = f32[16]{0} broadcast(f32[] %reshape.692), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1445 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.142, f32[16]{0} %broadcast.117), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1463 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1464 = f32[16]{0} multiply(f32[16]{0} %multiply.1445, f32[16]{0} %broadcast.1463), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1472 = f32[16]{0} add(f32[16]{0} %broadcast.115, f32[16]{0} %multiply.1464), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.84 = f32[] constant(0)
  %multiply.91 = f32[] multiply(f32[] %constant.84, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.121 = f32[16]{0} broadcast(f32[] %multiply.91), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1453 = f32[16]{0} multiply(f32[16]{0} %multiply.1445, f32[16]{0} %multiply.1445), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1454 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1455 = f32[16]{0} multiply(f32[16]{0} %multiply.1453, f32[16]{0} %broadcast.1454), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1456 = f32[16]{0} add(f32[16]{0} %broadcast.121, f32[16]{0} %multiply.1455), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1457 = f32[16]{0} sqrt(f32[16]{0} %add.1456), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1458 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1459 = f32[16]{0} add(f32[16]{0} %sqrt.1457, f32[16]{0} %broadcast.1458), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1474 = f32[16]{0} divide(f32[16]{0} %add.1472, f32[16]{0} %add.1459), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1429 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1475 = f32[16]{0} broadcast(f32[] %constant.1429), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1476 = f32[16]{0} multiply(f32[16]{0} %divide.1474, f32[16]{0} %broadcast.1475), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1477 = f32[16]{0} add(f32[16]{0} %p54.1473, f32[16]{0} %multiply.1476), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p55.1528 = f32[4096,16]{1,0} parameter(55), frontend_attributes={neff_input_names="input55"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.85 = f32[] constant(0)
  %multiply.92 = f32[] multiply(f32[] %constant.85, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.125 = f32[4096,16]{1,0} broadcast(f32[] %multiply.92), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.87 = f32[1]{0} constant({1})
  %compare.1493 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.87), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.88 = f32[1]{0} constant({1})
  %select.1495 = f32[1]{0} select(pred[1]{0} %compare.1493, f32[1]{0} %divide.692, f32[1]{0} %constant.88), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.202 = f32[1]{0} constant({0.125})
  %multiply.188 = f32[1]{0} multiply(f32[1]{0} %select.1495, f32[1]{0} %constant.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.695 = f32[] reshape(f32[1]{0} %multiply.188), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.127 = f32[4096,16]{1,0} broadcast(f32[] %reshape.695), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1500 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %get-tuple-element.190, f32[4096,16]{1,0} %broadcast.127), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1518 = f32[4096,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1519 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1500, f32[4096,16]{1,0} %broadcast.1518), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1527 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.125, f32[4096,16]{1,0} %multiply.1519), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.89 = f32[] constant(0)
  %multiply.95 = f32[] multiply(f32[] %constant.89, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.131 = f32[4096,16]{1,0} broadcast(f32[] %multiply.95), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1508 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1500, f32[4096,16]{1,0} %multiply.1500), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1509 = f32[4096,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1510 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %multiply.1508, f32[4096,16]{1,0} %broadcast.1509), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1511 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %broadcast.131, f32[4096,16]{1,0} %multiply.1510), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1512 = f32[4096,16]{1,0} sqrt(f32[4096,16]{1,0} %add.1511), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1513 = f32[4096,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1514 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %sqrt.1512, f32[4096,16]{1,0} %broadcast.1513), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1529 = f32[4096,16]{1,0} divide(f32[4096,16]{1,0} %add.1527, f32[4096,16]{1,0} %add.1514), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1483 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1530 = f32[4096,16]{1,0} broadcast(f32[] %constant.1483), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1531 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %divide.1529, f32[4096,16]{1,0} %broadcast.1530), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1532 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %p55.1528, f32[4096,16]{1,0} %multiply.1531), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1478 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1482 = f32[4096,16]{1,0} broadcast(f32[] %constant.1478), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1533 = f32[4096,16]{1,0} multiply(f32[4096,16]{1,0} %add.1532, f32[4096,16]{1,0} %broadcast.1482), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1534 = f32[4096,16]{1,0} add(f32[4096,16]{1,0} %add.1532, f32[4096,16]{1,0} %multiply.1533), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p56.1579 = f32[4096]{0} parameter(56), frontend_attributes={neff_input_names="input56"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.90 = f32[] constant(0)
  %multiply.96 = f32[] multiply(f32[] %constant.90, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.135 = f32[4096]{0} broadcast(f32[] %multiply.96), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.92 = f32[1]{0} constant({1})
  %compare.1545 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.92), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.93 = f32[1]{0} constant({1})
  %select.1547 = f32[1]{0} select(pred[1]{0} %compare.1545, f32[1]{0} %divide.692, f32[1]{0} %constant.93), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.204 = f32[1]{0} constant({0.125})
  %multiply.190 = f32[1]{0} multiply(f32[1]{0} %select.1547, f32[1]{0} %constant.204), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.698 = f32[] reshape(f32[1]{0} %multiply.190), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.137 = f32[4096]{0} broadcast(f32[] %reshape.698), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1551 = f32[4096]{0} multiply(f32[4096]{0} %get-tuple-element.138, f32[4096]{0} %broadcast.137), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1569 = f32[4096]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1570 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1551, f32[4096]{0} %broadcast.1569), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1578 = f32[4096]{0} add(f32[4096]{0} %broadcast.135, f32[4096]{0} %multiply.1570), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.94 = f32[] constant(0)
  %multiply.99 = f32[] multiply(f32[] %constant.94, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.141 = f32[4096]{0} broadcast(f32[] %multiply.99), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1559 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1551, f32[4096]{0} %multiply.1551), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1560 = f32[4096]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1561 = f32[4096]{0} multiply(f32[4096]{0} %multiply.1559, f32[4096]{0} %broadcast.1560), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1562 = f32[4096]{0} add(f32[4096]{0} %broadcast.141, f32[4096]{0} %multiply.1561), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1563 = f32[4096]{0} sqrt(f32[4096]{0} %add.1562), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1564 = f32[4096]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1565 = f32[4096]{0} add(f32[4096]{0} %sqrt.1563, f32[4096]{0} %broadcast.1564), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1580 = f32[4096]{0} divide(f32[4096]{0} %add.1578, f32[4096]{0} %add.1565), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1535 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1581 = f32[4096]{0} broadcast(f32[] %constant.1535), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1582 = f32[4096]{0} multiply(f32[4096]{0} %divide.1580, f32[4096]{0} %broadcast.1581), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1583 = f32[4096]{0} add(f32[4096]{0} %p56.1579, f32[4096]{0} %multiply.1582), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p57.1634 = f32[16,4096]{1,0} parameter(57), frontend_attributes={neff_input_names="input57"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.95 = f32[] constant(0)
  %multiply.100 = f32[] multiply(f32[] %constant.95, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.145 = f32[16,4096]{1,0} broadcast(f32[] %multiply.100), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.97 = f32[1]{0} constant({1})
  %compare.1599 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.97), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.98 = f32[1]{0} constant({1})
  %select.1601 = f32[1]{0} select(pred[1]{0} %compare.1599, f32[1]{0} %divide.692, f32[1]{0} %constant.98), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.205 = f32[1]{0} constant({0.125})
  %multiply.191 = f32[1]{0} multiply(f32[1]{0} %select.1601, f32[1]{0} %constant.205), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.701 = f32[] reshape(f32[1]{0} %multiply.191), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.147 = f32[16,4096]{1,0} broadcast(f32[] %reshape.701), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1606 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %get-tuple-element.186, f32[16,4096]{1,0} %broadcast.147), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1624 = f32[16,4096]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1625 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1606, f32[16,4096]{1,0} %broadcast.1624), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1633 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.145, f32[16,4096]{1,0} %multiply.1625), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.99 = f32[] constant(0)
  %multiply.103 = f32[] multiply(f32[] %constant.99, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.151 = f32[16,4096]{1,0} broadcast(f32[] %multiply.103), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1614 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1606, f32[16,4096]{1,0} %multiply.1606), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1615 = f32[16,4096]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1616 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %multiply.1614, f32[16,4096]{1,0} %broadcast.1615), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1617 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %broadcast.151, f32[16,4096]{1,0} %multiply.1616), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1618 = f32[16,4096]{1,0} sqrt(f32[16,4096]{1,0} %add.1617), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1619 = f32[16,4096]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1620 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %sqrt.1618, f32[16,4096]{1,0} %broadcast.1619), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1635 = f32[16,4096]{1,0} divide(f32[16,4096]{1,0} %add.1633, f32[16,4096]{1,0} %add.1620), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1589 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1636 = f32[16,4096]{1,0} broadcast(f32[] %constant.1589), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1637 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %divide.1635, f32[16,4096]{1,0} %broadcast.1636), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1638 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %p57.1634, f32[16,4096]{1,0} %multiply.1637), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1584 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1588 = f32[16,4096]{1,0} broadcast(f32[] %constant.1584), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1639 = f32[16,4096]{1,0} multiply(f32[16,4096]{1,0} %add.1638, f32[16,4096]{1,0} %broadcast.1588), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1640 = f32[16,4096]{1,0} add(f32[16,4096]{1,0} %add.1638, f32[16,4096]{1,0} %multiply.1639), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p58.1685 = f32[16]{0} parameter(58), frontend_attributes={neff_input_names="input58"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.100 = f32[] constant(0)
  %multiply.104 = f32[] multiply(f32[] %constant.100, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.155 = f32[16]{0} broadcast(f32[] %multiply.104), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.102 = f32[1]{0} constant({1})
  %compare.1651 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.102), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.104 = f32[1]{0} constant({1})
  %select.1653 = f32[1]{0} select(pred[1]{0} %compare.1651, f32[1]{0} %divide.692, f32[1]{0} %constant.104), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.206 = f32[1]{0} constant({0.125})
  %multiply.192 = f32[1]{0} multiply(f32[1]{0} %select.1653, f32[1]{0} %constant.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.705 = f32[] reshape(f32[1]{0} %multiply.192), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.157 = f32[16]{0} broadcast(f32[] %reshape.705), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1657 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.134, f32[16]{0} %broadcast.157), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1675 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1676 = f32[16]{0} multiply(f32[16]{0} %multiply.1657, f32[16]{0} %broadcast.1675), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1684 = f32[16]{0} add(f32[16]{0} %broadcast.155, f32[16]{0} %multiply.1676), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.105 = f32[] constant(0)
  %multiply.108 = f32[] multiply(f32[] %constant.105, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.161 = f32[16]{0} broadcast(f32[] %multiply.108), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1665 = f32[16]{0} multiply(f32[16]{0} %multiply.1657, f32[16]{0} %multiply.1657), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1666 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1667 = f32[16]{0} multiply(f32[16]{0} %multiply.1665, f32[16]{0} %broadcast.1666), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1668 = f32[16]{0} add(f32[16]{0} %broadcast.161, f32[16]{0} %multiply.1667), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1669 = f32[16]{0} sqrt(f32[16]{0} %add.1668), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1670 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1671 = f32[16]{0} add(f32[16]{0} %sqrt.1669, f32[16]{0} %broadcast.1670), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1686 = f32[16]{0} divide(f32[16]{0} %add.1684, f32[16]{0} %add.1671), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1641 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1687 = f32[16]{0} broadcast(f32[] %constant.1641), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1688 = f32[16]{0} multiply(f32[16]{0} %divide.1686, f32[16]{0} %broadcast.1687), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1689 = f32[16]{0} add(f32[16]{0} %p58.1685, f32[16]{0} %multiply.1688), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p59.1734 = f32[16]{0} parameter(59), frontend_attributes={neff_input_names="input59"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.106 = f32[] constant(0)
  %multiply.110 = f32[] multiply(f32[] %constant.106, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.165 = f32[16]{0} broadcast(f32[] %multiply.110), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.109 = f32[1]{0} constant({1})
  %compare.1700 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.109), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.110 = f32[1]{0} constant({1})
  %select.1702 = f32[1]{0} select(pred[1]{0} %compare.1700, f32[1]{0} %divide.692, f32[1]{0} %constant.110), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.208 = f32[1]{0} constant({0.125})
  %multiply.194 = f32[1]{0} multiply(f32[1]{0} %select.1702, f32[1]{0} %constant.208), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.708 = f32[] reshape(f32[1]{0} %multiply.194), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.166 = f32[16]{0} broadcast(f32[] %reshape.708), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1706 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.130, f32[16]{0} %broadcast.166), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1724 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1725 = f32[16]{0} multiply(f32[16]{0} %multiply.1706, f32[16]{0} %broadcast.1724), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1733 = f32[16]{0} add(f32[16]{0} %broadcast.165, f32[16]{0} %multiply.1725), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.112 = f32[] constant(0)
  %multiply.114 = f32[] multiply(f32[] %constant.112, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.170 = f32[16]{0} broadcast(f32[] %multiply.114), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1714 = f32[16]{0} multiply(f32[16]{0} %multiply.1706, f32[16]{0} %multiply.1706), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1715 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1716 = f32[16]{0} multiply(f32[16]{0} %multiply.1714, f32[16]{0} %broadcast.1715), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1717 = f32[16]{0} add(f32[16]{0} %broadcast.170, f32[16]{0} %multiply.1716), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1718 = f32[16]{0} sqrt(f32[16]{0} %add.1717), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1719 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1720 = f32[16]{0} add(f32[16]{0} %sqrt.1718, f32[16]{0} %broadcast.1719), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1735 = f32[16]{0} divide(f32[16]{0} %add.1733, f32[16]{0} %add.1720), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1690 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1736 = f32[16]{0} broadcast(f32[] %constant.1690), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1737 = f32[16]{0} multiply(f32[16]{0} %divide.1735, f32[16]{0} %broadcast.1736), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1738 = f32[16]{0} add(f32[16]{0} %p59.1734, f32[16]{0} %multiply.1737), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p60.1783 = f32[16]{0} parameter(60), frontend_attributes={neff_input_names="input60"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.113 = f32[] constant(0)
  %multiply.115 = f32[] multiply(f32[] %constant.113, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.174 = f32[16]{0} broadcast(f32[] %multiply.115), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.116 = f32[1]{0} constant({1})
  %compare.1749 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.116), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.117 = f32[1]{0} constant({1})
  %select.1751 = f32[1]{0} select(pred[1]{0} %compare.1749, f32[1]{0} %divide.692, f32[1]{0} %constant.117), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.209 = f32[1]{0} constant({0.125})
  %multiply.195 = f32[1]{0} multiply(f32[1]{0} %select.1751, f32[1]{0} %constant.209), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.713 = f32[] reshape(f32[1]{0} %multiply.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.175 = f32[16]{0} broadcast(f32[] %reshape.713), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1755 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.126, f32[16]{0} %broadcast.175), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1773 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1774 = f32[16]{0} multiply(f32[16]{0} %multiply.1755, f32[16]{0} %broadcast.1773), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1782 = f32[16]{0} add(f32[16]{0} %broadcast.174, f32[16]{0} %multiply.1774), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.118 = f32[] constant(0)
  %multiply.119 = f32[] multiply(f32[] %constant.118, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.179 = f32[16]{0} broadcast(f32[] %multiply.119), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1763 = f32[16]{0} multiply(f32[16]{0} %multiply.1755, f32[16]{0} %multiply.1755), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1764 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1765 = f32[16]{0} multiply(f32[16]{0} %multiply.1763, f32[16]{0} %broadcast.1764), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1766 = f32[16]{0} add(f32[16]{0} %broadcast.179, f32[16]{0} %multiply.1765), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1767 = f32[16]{0} sqrt(f32[16]{0} %add.1766), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1768 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1769 = f32[16]{0} add(f32[16]{0} %sqrt.1767, f32[16]{0} %broadcast.1768), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1784 = f32[16]{0} divide(f32[16]{0} %add.1782, f32[16]{0} %add.1769), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1739 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1785 = f32[16]{0} broadcast(f32[] %constant.1739), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1786 = f32[16]{0} multiply(f32[16]{0} %divide.1784, f32[16]{0} %broadcast.1785), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1787 = f32[16]{0} add(f32[16]{0} %p60.1783, f32[16]{0} %multiply.1786), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p61.1838 = f32[16,16]{1,0} parameter(61), frontend_attributes={neff_input_names="input61"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.120 = f32[] constant(0)
  %multiply.120 = f32[] multiply(f32[] %constant.120, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.183 = f32[16,16]{1,0} broadcast(f32[] %multiply.120), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.122 = f32[1]{0} constant({1})
  %compare.1803 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.122), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.124 = f32[1]{0} constant({1})
  %select.1805 = f32[1]{0} select(pred[1]{0} %compare.1803, f32[1]{0} %divide.692, f32[1]{0} %constant.124), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.210 = f32[1]{0} constant({0.125})
  %multiply.196 = f32[1]{0} multiply(f32[1]{0} %select.1805, f32[1]{0} %constant.210), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.716 = f32[] reshape(f32[1]{0} %multiply.196), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.186 = f32[16,16]{1,0} broadcast(f32[] %reshape.716), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1810 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.182, f32[16,16]{1,0} %broadcast.186), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1828 = f32[16,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1829 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1810, f32[16,16]{1,0} %broadcast.1828), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1837 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.183, f32[16,16]{1,0} %multiply.1829), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.125 = f32[] constant(0)
  %multiply.124 = f32[] multiply(f32[] %constant.125, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.190 = f32[16,16]{1,0} broadcast(f32[] %multiply.124), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1818 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1810, f32[16,16]{1,0} %multiply.1810), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1819 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1820 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1818, f32[16,16]{1,0} %broadcast.1819), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1821 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.190, f32[16,16]{1,0} %multiply.1820), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1822 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1821), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1823 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1824 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1822, f32[16,16]{1,0} %broadcast.1823), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1839 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1837, f32[16,16]{1,0} %add.1824), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1793 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1840 = f32[16,16]{1,0} broadcast(f32[] %constant.1793), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1841 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1839, f32[16,16]{1,0} %broadcast.1840), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1842 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p61.1838, f32[16,16]{1,0} %multiply.1841), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1788 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1792 = f32[16,16]{1,0} broadcast(f32[] %constant.1788), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1843 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1842, f32[16,16]{1,0} %broadcast.1792), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1844 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1842, f32[16,16]{1,0} %multiply.1843), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p62.1889 = f32[16]{0} parameter(62), frontend_attributes={neff_input_names="input62"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.126 = f32[] constant(0)
  %multiply.126 = f32[] multiply(f32[] %constant.126, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.194 = f32[16]{0} broadcast(f32[] %multiply.126), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.129 = f32[1]{0} constant({1})
  %compare.1855 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.129), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.130 = f32[1]{0} constant({1})
  %select.1857 = f32[1]{0} select(pred[1]{0} %compare.1855, f32[1]{0} %divide.692, f32[1]{0} %constant.130), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.212 = f32[1]{0} constant({0.125})
  %multiply.198 = f32[1]{0} multiply(f32[1]{0} %select.1857, f32[1]{0} %constant.212), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.719 = f32[] reshape(f32[1]{0} %multiply.198), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.195 = f32[16]{0} broadcast(f32[] %reshape.719), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1861 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.122, f32[16]{0} %broadcast.195), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1879 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1880 = f32[16]{0} multiply(f32[16]{0} %multiply.1861, f32[16]{0} %broadcast.1879), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1888 = f32[16]{0} add(f32[16]{0} %broadcast.194, f32[16]{0} %multiply.1880), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.132 = f32[] constant(0)
  %multiply.130 = f32[] multiply(f32[] %constant.132, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.199 = f32[16]{0} broadcast(f32[] %multiply.130), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1869 = f32[16]{0} multiply(f32[16]{0} %multiply.1861, f32[16]{0} %multiply.1861), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1870 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1871 = f32[16]{0} multiply(f32[16]{0} %multiply.1869, f32[16]{0} %broadcast.1870), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1872 = f32[16]{0} add(f32[16]{0} %broadcast.199, f32[16]{0} %multiply.1871), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1873 = f32[16]{0} sqrt(f32[16]{0} %add.1872), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1874 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1875 = f32[16]{0} add(f32[16]{0} %sqrt.1873, f32[16]{0} %broadcast.1874), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1890 = f32[16]{0} divide(f32[16]{0} %add.1888, f32[16]{0} %add.1875), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1845 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1891 = f32[16]{0} broadcast(f32[] %constant.1845), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1892 = f32[16]{0} multiply(f32[16]{0} %divide.1890, f32[16]{0} %broadcast.1891), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1893 = f32[16]{0} add(f32[16]{0} %p62.1889, f32[16]{0} %multiply.1892), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p63.1944 = f32[16,16]{1,0} parameter(63), frontend_attributes={neff_input_names="input63"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.133 = f32[] constant(0)
  %multiply.131 = f32[] multiply(f32[] %constant.133, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.203 = f32[16,16]{1,0} broadcast(f32[] %multiply.131), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.136 = f32[1]{0} constant({1})
  %compare.1909 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.136), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.137 = f32[1]{0} constant({1})
  %select.1911 = f32[1]{0} select(pred[1]{0} %compare.1909, f32[1]{0} %divide.692, f32[1]{0} %constant.137), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.213 = f32[1]{0} constant({0.125})
  %multiply.199 = f32[1]{0} multiply(f32[1]{0} %select.1911, f32[1]{0} %constant.213), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.722 = f32[] reshape(f32[1]{0} %multiply.199), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.206 = f32[16,16]{1,0} broadcast(f32[] %reshape.722), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1916 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %get-tuple-element.178, f32[16,16]{1,0} %broadcast.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1934 = f32[16,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1935 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1916, f32[16,16]{1,0} %broadcast.1934), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1943 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.203, f32[16,16]{1,0} %multiply.1935), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.138 = f32[] constant(0)
  %multiply.135 = f32[] multiply(f32[] %constant.138, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.210 = f32[16,16]{1,0} broadcast(f32[] %multiply.135), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1924 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1916, f32[16,16]{1,0} %multiply.1916), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1925 = f32[16,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1926 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %multiply.1924, f32[16,16]{1,0} %broadcast.1925), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1927 = f32[16,16]{1,0} add(f32[16,16]{1,0} %broadcast.210, f32[16,16]{1,0} %multiply.1926), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1928 = f32[16,16]{1,0} sqrt(f32[16,16]{1,0} %add.1927), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1929 = f32[16,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1930 = f32[16,16]{1,0} add(f32[16,16]{1,0} %sqrt.1928, f32[16,16]{1,0} %broadcast.1929), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1945 = f32[16,16]{1,0} divide(f32[16,16]{1,0} %add.1943, f32[16,16]{1,0} %add.1930), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1899 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1946 = f32[16,16]{1,0} broadcast(f32[] %constant.1899), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1947 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %divide.1945, f32[16,16]{1,0} %broadcast.1946), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1948 = f32[16,16]{1,0} add(f32[16,16]{1,0} %p63.1944, f32[16,16]{1,0} %multiply.1947), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1894 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.1898 = f32[16,16]{1,0} broadcast(f32[] %constant.1894), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.1949 = f32[16,16]{1,0} multiply(f32[16,16]{1,0} %add.1948, f32[16,16]{1,0} %broadcast.1898), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.1950 = f32[16,16]{1,0} add(f32[16,16]{1,0} %add.1948, f32[16,16]{1,0} %multiply.1949), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p64.1995 = f32[16]{0} parameter(64), frontend_attributes={neff_input_names="input64"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.140 = f32[] constant(0)
  %multiply.136 = f32[] multiply(f32[] %constant.140, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.214 = f32[16]{0} broadcast(f32[] %multiply.136), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.142 = f32[1]{0} constant({1})
  %compare.1961 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.142), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.144 = f32[1]{0} constant({1})
  %select.1963 = f32[1]{0} select(pred[1]{0} %compare.1961, f32[1]{0} %divide.692, f32[1]{0} %constant.144), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.214 = f32[1]{0} constant({0.125})
  %multiply.200 = f32[1]{0} multiply(f32[1]{0} %select.1963, f32[1]{0} %constant.214), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.727 = f32[] reshape(f32[1]{0} %multiply.200), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.215 = f32[16]{0} broadcast(f32[] %reshape.727), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.1967 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.114, f32[16]{0} %broadcast.215), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.1985 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.1986 = f32[16]{0} multiply(f32[16]{0} %multiply.1967, f32[16]{0} %broadcast.1985), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.1994 = f32[16]{0} add(f32[16]{0} %broadcast.214, f32[16]{0} %multiply.1986), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.145 = f32[] constant(0)
  %multiply.140 = f32[] multiply(f32[] %constant.145, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.219 = f32[16]{0} broadcast(f32[] %multiply.140), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.1975 = f32[16]{0} multiply(f32[16]{0} %multiply.1967, f32[16]{0} %multiply.1967), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.1976 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.1977 = f32[16]{0} multiply(f32[16]{0} %multiply.1975, f32[16]{0} %broadcast.1976), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.1978 = f32[16]{0} add(f32[16]{0} %broadcast.219, f32[16]{0} %multiply.1977), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.1979 = f32[16]{0} sqrt(f32[16]{0} %add.1978), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.1980 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.1981 = f32[16]{0} add(f32[16]{0} %sqrt.1979, f32[16]{0} %broadcast.1980), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.1996 = f32[16]{0} divide(f32[16]{0} %add.1994, f32[16]{0} %add.1981), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.1951 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.1997 = f32[16]{0} broadcast(f32[] %constant.1951), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.1998 = f32[16]{0} multiply(f32[16]{0} %divide.1996, f32[16]{0} %broadcast.1997), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.1999 = f32[16]{0} add(f32[16]{0} %p64.1995, f32[16]{0} %multiply.1998), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p65.2044 = f32[16]{0} parameter(65), frontend_attributes={neff_input_names="input65"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.146 = f32[] constant(0)
  %multiply.142 = f32[] multiply(f32[] %constant.146, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.223 = f32[16]{0} broadcast(f32[] %multiply.142), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.149 = f32[1]{0} constant({1})
  %compare.2010 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.149), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.150 = f32[1]{0} constant({1})
  %select.2012 = f32[1]{0} select(pred[1]{0} %compare.2010, f32[1]{0} %divide.692, f32[1]{0} %constant.150), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.216 = f32[1]{0} constant({0.125})
  %multiply.202 = f32[1]{0} multiply(f32[1]{0} %select.2012, f32[1]{0} %constant.216), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.731 = f32[] reshape(f32[1]{0} %multiply.202), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.224 = f32[16]{0} broadcast(f32[] %reshape.731), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2016 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.110, f32[16]{0} %broadcast.224), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2034 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2035 = f32[16]{0} multiply(f32[16]{0} %multiply.2016, f32[16]{0} %broadcast.2034), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2043 = f32[16]{0} add(f32[16]{0} %broadcast.223, f32[16]{0} %multiply.2035), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.152 = f32[] constant(0)
  %multiply.146 = f32[] multiply(f32[] %constant.152, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.227 = f32[16]{0} broadcast(f32[] %multiply.146), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2024 = f32[16]{0} multiply(f32[16]{0} %multiply.2016, f32[16]{0} %multiply.2016), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2025 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2026 = f32[16]{0} multiply(f32[16]{0} %multiply.2024, f32[16]{0} %broadcast.2025), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2027 = f32[16]{0} add(f32[16]{0} %broadcast.227, f32[16]{0} %multiply.2026), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2028 = f32[16]{0} sqrt(f32[16]{0} %add.2027), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2029 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2030 = f32[16]{0} add(f32[16]{0} %sqrt.2028, f32[16]{0} %broadcast.2029), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2045 = f32[16]{0} divide(f32[16]{0} %add.2043, f32[16]{0} %add.2030), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2000 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.2046 = f32[16]{0} broadcast(f32[] %constant.2000), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2047 = f32[16]{0} multiply(f32[16]{0} %divide.2045, f32[16]{0} %broadcast.2046), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2048 = f32[16]{0} add(f32[16]{0} %p65.2044, f32[16]{0} %multiply.2047), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p66.2093 = f32[16]{0} parameter(66), frontend_attributes={neff_input_names="input66"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.153 = f32[] constant(0)
  %multiply.147 = f32[] multiply(f32[] %constant.153, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.230 = f32[16]{0} broadcast(f32[] %multiply.147), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.156 = f32[1]{0} constant({1})
  %compare.2059 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.156), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.157 = f32[1]{0} constant({1})
  %select.2061 = f32[1]{0} select(pred[1]{0} %compare.2059, f32[1]{0} %divide.692, f32[1]{0} %constant.157), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.217 = f32[1]{0} constant({0.125})
  %multiply.203 = f32[1]{0} multiply(f32[1]{0} %select.2061, f32[1]{0} %constant.217), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.735 = f32[] reshape(f32[1]{0} %multiply.203), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.231 = f32[16]{0} broadcast(f32[] %reshape.735), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2065 = f32[16]{0} multiply(f32[16]{0} %get-tuple-element.106, f32[16]{0} %broadcast.231), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2083 = f32[16]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2084 = f32[16]{0} multiply(f32[16]{0} %multiply.2065, f32[16]{0} %broadcast.2083), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2092 = f32[16]{0} add(f32[16]{0} %broadcast.230, f32[16]{0} %multiply.2084), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.158 = f32[] constant(0)
  %multiply.151 = f32[] multiply(f32[] %constant.158, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.234 = f32[16]{0} broadcast(f32[] %multiply.151), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2073 = f32[16]{0} multiply(f32[16]{0} %multiply.2065, f32[16]{0} %multiply.2065), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2074 = f32[16]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2075 = f32[16]{0} multiply(f32[16]{0} %multiply.2073, f32[16]{0} %broadcast.2074), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2076 = f32[16]{0} add(f32[16]{0} %broadcast.234, f32[16]{0} %multiply.2075), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2077 = f32[16]{0} sqrt(f32[16]{0} %add.2076), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2078 = f32[16]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2079 = f32[16]{0} add(f32[16]{0} %sqrt.2077, f32[16]{0} %broadcast.2078), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2094 = f32[16]{0} divide(f32[16]{0} %add.2092, f32[16]{0} %add.2079), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2049 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.2095 = f32[16]{0} broadcast(f32[] %constant.2049), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2096 = f32[16]{0} multiply(f32[16]{0} %divide.2094, f32[16]{0} %broadcast.2095), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2097 = f32[16]{0} add(f32[16]{0} %p66.2093, f32[16]{0} %multiply.2096), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p67.2142 = f32[30522]{0} parameter(67), frontend_attributes={neff_input_names="input67"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.160 = f32[] constant(0)
  %multiply.152 = f32[] multiply(f32[] %constant.160, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.237 = f32[30522]{0} broadcast(f32[] %multiply.152), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.162 = f32[1]{0} constant({1})
  %compare.2108 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.162), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.164 = f32[1]{0} constant({1})
  %select.2110 = f32[1]{0} select(pred[1]{0} %compare.2108, f32[1]{0} %divide.692, f32[1]{0} %constant.164), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.218 = f32[1]{0} constant({0.125})
  %multiply.204 = f32[1]{0} multiply(f32[1]{0} %select.2110, f32[1]{0} %constant.218), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.738 = f32[] reshape(f32[1]{0} %multiply.204), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.238 = f32[30522]{0} broadcast(f32[] %reshape.738), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2114 = f32[30522]{0} multiply(f32[30522]{0} %get-tuple-element.118, f32[30522]{0} %broadcast.238), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2132 = f32[30522]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2133 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2114, f32[30522]{0} %broadcast.2132), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2141 = f32[30522]{0} add(f32[30522]{0} %broadcast.237, f32[30522]{0} %multiply.2133), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.165 = f32[] constant(0)
  %multiply.156 = f32[] multiply(f32[] %constant.165, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.241 = f32[30522]{0} broadcast(f32[] %multiply.156), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2122 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2114, f32[30522]{0} %multiply.2114), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2123 = f32[30522]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2124 = f32[30522]{0} multiply(f32[30522]{0} %multiply.2122, f32[30522]{0} %broadcast.2123), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2125 = f32[30522]{0} add(f32[30522]{0} %broadcast.241, f32[30522]{0} %multiply.2124), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2126 = f32[30522]{0} sqrt(f32[30522]{0} %add.2125), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2127 = f32[30522]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2128 = f32[30522]{0} add(f32[30522]{0} %sqrt.2126, f32[30522]{0} %broadcast.2127), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2143 = f32[30522]{0} divide(f32[30522]{0} %add.2141, f32[30522]{0} %add.2128), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2098 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.2144 = f32[30522]{0} broadcast(f32[] %constant.2098), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2145 = f32[30522]{0} multiply(f32[30522]{0} %divide.2143, f32[30522]{0} %broadcast.2144), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2146 = f32[30522]{0} add(f32[30522]{0} %p67.2142, f32[30522]{0} %multiply.2145), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %p68.2197 = f32[2,16]{1,0} parameter(68), frontend_attributes={neff_input_names="input68"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.166 = f32[] constant(0)
  %multiply.158 = f32[] multiply(f32[] %constant.166, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.244 = f32[2,16]{1,0} broadcast(f32[] %multiply.158), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.169 = f32[1]{0} constant({1})
  %compare.2162 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.169), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.170 = f32[1]{0} constant({1})
  %select.2164 = f32[1]{0} select(pred[1]{0} %compare.2162, f32[1]{0} %divide.692, f32[1]{0} %constant.170), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.220 = f32[1]{0} constant({0.125})
  %multiply.206 = f32[1]{0} multiply(f32[1]{0} %select.2164, f32[1]{0} %constant.220), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.741 = f32[] reshape(f32[1]{0} %multiply.206), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.246 = f32[2,16]{1,0} broadcast(f32[] %reshape.741), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2169 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %get-tuple-element.174, f32[2,16]{1,0} %broadcast.246), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2187 = f32[2,16]{1,0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2188 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2169, f32[2,16]{1,0} %broadcast.2187), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2196 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.244, f32[2,16]{1,0} %multiply.2188), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.172 = f32[] constant(0)
  %multiply.162 = f32[] multiply(f32[] %constant.172, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.249 = f32[2,16]{1,0} broadcast(f32[] %multiply.162), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2177 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2169, f32[2,16]{1,0} %multiply.2169), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2178 = f32[2,16]{1,0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2179 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %multiply.2177, f32[2,16]{1,0} %broadcast.2178), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2180 = f32[2,16]{1,0} add(f32[2,16]{1,0} %broadcast.249, f32[2,16]{1,0} %multiply.2179), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2181 = f32[2,16]{1,0} sqrt(f32[2,16]{1,0} %add.2180), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2182 = f32[2,16]{1,0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2183 = f32[2,16]{1,0} add(f32[2,16]{1,0} %sqrt.2181, f32[2,16]{1,0} %broadcast.2182), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2198 = f32[2,16]{1,0} divide(f32[2,16]{1,0} %add.2196, f32[2,16]{1,0} %add.2183), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2152 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.2199 = f32[2,16]{1,0} broadcast(f32[] %constant.2152), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2200 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %divide.2198, f32[2,16]{1,0} %broadcast.2199), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2201 = f32[2,16]{1,0} add(f32[2,16]{1,0} %p68.2197, f32[2,16]{1,0} %multiply.2200), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2147 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %broadcast.2151 = f32[2,16]{1,0} broadcast(f32[] %constant.2147), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %multiply.2202 = f32[2,16]{1,0} multiply(f32[2,16]{1,0} %add.2201, f32[2,16]{1,0} %broadcast.2151), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %add.2203 = f32[2,16]{1,0} add(f32[2,16]{1,0} %add.2201, f32[2,16]{1,0} %multiply.2202), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=505}
  %p69.2248 = f32[2]{0} parameter(69), frontend_attributes={neff_input_names="input69"}, metadata={op_type="xla__device_data" op_name="xla__device_data" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_op_registry.py" source_line=44}
  %constant.173 = f32[] constant(0)
  %multiply.163 = f32[] multiply(f32[] %constant.173, f32[] %p39.728), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %broadcast.252 = f32[2]{0} broadcast(f32[] %multiply.163), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=473}
  %constant.176 = f32[1]{0} constant({1})
  %compare.2214 = pred[1]{0} compare(f32[1]{0} %divide.692, f32[1]{0} %constant.176), direction=LT, metadata={op_type="aten__lt" op_name="aten__lt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=192}
  %constant.177 = f32[1]{0} constant({1})
  %select.2216 = f32[1]{0} select(pred[1]{0} %compare.2214, f32[1]{0} %divide.692, f32[1]{0} %constant.177), metadata={op_type="aten__where" op_name="aten__where" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=191}
  %constant.221 = f32[1]{0} constant({0.125})
  %multiply.207 = f32[1]{0} multiply(f32[1]{0} %select.2216, f32[1]{0} %constant.221), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %reshape.744 = f32[] reshape(f32[1]{0} %multiply.207), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.253 = f32[2]{0} broadcast(f32[] %reshape.744), dimensions={}, metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %multiply.2220 = f32[2]{0} multiply(f32[2]{0} %get-tuple-element.102, f32[2]{0} %broadcast.253), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/neuronx_distributed/parallel_layers/grads.py" source_line=190}
  %broadcast.2238 = f32[2]{0} broadcast(f32[] %p38.722), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %multiply.2239 = f32[2]{0} multiply(f32[2]{0} %multiply.2220, f32[2]{0} %broadcast.2238), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %add.2247 = f32[2]{0} add(f32[2]{0} %broadcast.252, f32[2]{0} %multiply.2239), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=484}
  %constant.178 = f32[] constant(0)
  %multiply.167 = f32[] multiply(f32[] %constant.178, f32[] %p37.707), metadata={op_type="aten__mul" op_name="aten__mul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.256 = f32[2]{0} broadcast(f32[] %multiply.167), dimensions={}, metadata={op_type="aten__expand" op_name="aten__expand" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=475}
  %multiply.2228 = f32[2]{0} multiply(f32[2]{0} %multiply.2220, f32[2]{0} %multiply.2220), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %broadcast.2229 = f32[2]{0} broadcast(f32[] %p1.10), dimensions={}, metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %multiply.2230 = f32[2]{0} multiply(f32[2]{0} %multiply.2228, f32[2]{0} %broadcast.2229), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %add.2231 = f32[2]{0} add(f32[2]{0} %broadcast.256, f32[2]{0} %multiply.2230), metadata={op_type="aten__addcmul" op_name="aten__addcmul" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=485}
  %sqrt.2232 = f32[2]{0} sqrt(f32[2]{0} %add.2231), metadata={op_type="aten__sqrt" op_name="aten__sqrt" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %broadcast.2233 = f32[2]{0} broadcast(f32[] %p0.8), dimensions={}, metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %add.2234 = f32[2]{0} add(f32[2]{0} %sqrt.2232, f32[2]{0} %broadcast.2233), metadata={op_type="aten__add" op_name="aten__add" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=486}
  %divide.2249 = f32[2]{0} divide(f32[2]{0} %add.2247, f32[2]{0} %add.2234), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.2204 = f32[] constant(-0), metadata={op_type="prim__Constant" op_name="prim__Constant" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %broadcast.2250 = f32[2]{0} broadcast(f32[] %constant.2204), dimensions={}, metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %multiply.2251 = f32[2]{0} multiply(f32[2]{0} %divide.2249, f32[2]{0} %broadcast.2250), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %add.2252 = f32[2]{0} add(f32[2]{0} %p69.2248, f32[2]{0} %multiply.2251), metadata={op_type="aten__addcdiv" op_name="aten__addcdiv" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/transformers/optimization.py" source_line=494}
  %constant.180 = f32[1]{0} constant({0})
  %get-tuple-element.33 = f32[1]{0} get-tuple-element((f32[1]{0}, f32[]) %all-reduce.32), index=0, metadata={op_type="xla__cross_replica_sum" op_name="xla__cross_replica_sum" source_file="/home/ubuntu/analyze_hlo/lib/python3.8/site-packages/torch_xla/core/xla_model.py" source_line=480}
  %constant.181 = f32[1]{0} constant({0})
  ROOT %tuple.2259 = (f32[30522,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, /*index=5*/f32[8,16]{1,0}, f32[8]{0}, f32[8,16]{1,0}, f32[8]{0}, f32[8,16]{1,0}, /*index=10*/f32[8]{0}, f32[16,8]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=15*/f32[4096,16]{1,0}, f32[4096]{0}, f32[16,4096]{1,0}, f32[16]{0}, f32[16]{0}, /*index=20*/f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, f32[16,16]{1,0}, f32[16]{0}, /*index=25*/f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[2,16]{1,0}, f32[2]{0}, /*index=30*/f32[1]{0}, f32[1]{0}, f32[1]{0}, f32[30522,16]{1,0}, f32[30522,16]{1,0}, /*index=35*/f32[512,16]{1,0}, f32[512,16]{1,0}, f32[2,16]{1,0}, f32[2,16]{1,0}, f32[8,16]{1,0}, /*index=40*/f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, f32[8,16]{1,0}, /*index=45*/f32[16,8]{1,0}, f32[16,8]{1,0}, f32[4096,16]{1,0}, f32[4096,16]{1,0}, f32[16,4096]{1,0}, /*index=50*/f32[16,4096]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, f32[16,16]{1,0}, /*index=55*/f32[2,16]{1,0}, f32[2,16]{1,0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=60*/f32[16]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, f32[8]{0}, /*index=65*/f32[8]{0}, f32[8]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=70*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[4096]{0}, f32[4096]{0}, /*index=75*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=80*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[30522]{0}, f32[30522]{0}, /*index=85*/f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, f32[16]{0}, /*index=90*/f32[16]{0}, f32[2]{0}, f32[2]{0}, f32[1]{0}) tuple(f32[30522,16]{1,0} %add.743, f32[512,16]{1,0} %add.800, f32[2,16]{1,0} %add.857, f32[16]{0} %add.906, f32[16]{0} %add.955, /*index=5*/f32[8,16]{1,0} %add.1012, f32[8]{0} %add.1061, f32[8,16]{1,0} %add.1118, f32[8]{0} %add.1167, f32[8,16]{1,0} %add.1224, /*index=10*/f32[8]{0} %add.1273, f32[16,8]{1,0} %add.1330, f32[16]{0} %add.1379, f32[16]{0} %add.1428, f32[16]{0} %add.1477, /*index=15*/f32[4096,16]{1,0} %add.1534, f32[4096]{0} %add.1583, f32[16,4096]{1,0} %add.1640, f32[16]{0} %add.1689, f32[16]{0} %add.1738, /*index=20*/f32[16]{0} %add.1787, f32[16,16]{1,0} %add.1844, f32[16]{0} %add.1893, f32[16,16]{1,0} %add.1950, f32[16]{0} %add.1999, /*index=25*/f32[16]{0} %add.2048, f32[16]{0} %add.2097, f32[30522]{0} %add.2146, f32[2,16]{1,0} %add.2203, f32[2]{0} %add.2252, /*index=30*/f32[1]{0} %constant.180, f32[1]{0} %divide.24, f32[1]{0} %get-tuple-element.33, f32[30522,16]{1,0} %add.736, f32[30522,16]{1,0} %add.718, /*index=35*/f32[512,16]{1,0} %add.793, f32[512,16]{1,0} %add.777, f32[2,16]{1,0} %add.850, f32[2,16]{1,0} %add.834, f32[8,16]{1,0} %add.1005, /*index=40*/f32[8,16]{1,0} %add.989, f32[8,16]{1,0} %add.1111, f32[8,16]{1,0} %add.1095, f32[8,16]{1,0} %add.1217, f32[8,16]{1,0} %add.1201, /*index=45*/f32[16,8]{1,0} %add.1323, f32[16,8]{1,0} %add.1307, f32[4096,16]{1,0} %add.1527, f32[4096,16]{1,0} %add.1511, f32[16,4096]{1,0} %add.1633, /*index=50*/f32[16,4096]{1,0} %add.1617, f32[16,16]{1,0} %add.1837, f32[16,16]{1,0} %add.1821, f32[16,16]{1,0} %add.1943, f32[16,16]{1,0} %add.1927, /*index=55*/f32[2,16]{1,0} %add.2196, f32[2,16]{1,0} %add.2180, f32[16]{0} %add.901, f32[16]{0} %add.885, f32[16]{0} %add.950, /*index=60*/f32[16]{0} %add.934, f32[8]{0} %add.1056, f32[8]{0} %add.1040, f32[8]{0} %add.1162, f32[8]{0} %add.1146, /*index=65*/f32[8]{0} %add.1268, f32[8]{0} %add.1252, f32[16]{0} %add.1374, f32[16]{0} %add.1358, f32[16]{0} %add.1423, /*index=70*/f32[16]{0} %add.1407, f32[16]{0} %add.1472, f32[16]{0} %add.1456, f32[4096]{0} %add.1578, f32[4096]{0} %add.1562, /*index=75*/f32[16]{0} %add.1684, f32[16]{0} %add.1668, f32[16]{0} %add.1733, f32[16]{0} %add.1717, f32[16]{0} %add.1782, /*index=80*/f32[16]{0} %add.1766, f32[16]{0} %add.1888, f32[16]{0} %add.1872, f32[30522]{0} %add.2141, f32[30522]{0} %add.2125, /*index=85*/f32[16]{0} %add.1994, f32[16]{0} %add.1978, f32[16]{0} %add.2043, f32[16]{0} %add.2027, f32[16]{0} %add.2092, /*index=90*/f32[16]{0} %add.2076, f32[2]{0} %add.2247, f32[2]{0} %add.2231, f32[1]{0} %constant.181), frontend_attributes={neff_output_names="output0,output1,output2,output3,output4,output5,output6,output7,output8,output9,output10,output11,output12,output13,output14,output15,output16,output17,output18,output19,output20,output21,output22,output23,output24,output25,output26,output27,output28,output29,output30,output31,output32,output33,output34,output35,output36,output37,output38,output39,output40,output41,output42,output43,output44,output45,output46,output47,output48,output49,output50,output51,output52,output53,output54,output55,output56,output57,output58,output59,output60,output61,output62,output63,output64,output65,output66,output67,output68,output69,output70,output71,output72,output73,output74,output75,output76,output77,output78,output79,output80,output81,output82,output83,output84,output85,output86,output87,output88,output89,output90,output91,output92,output93"}
}

`;

export default text;
